Pretrained transformers improve out-of-distribution robustness
Although pretrained Transformers such as BERT achieve high accuracy on in-distribution examples, do they generalize to new distributions? We systematically measure out-of-distribution (OOD) generalization for seven NLP datasets by constructing a new robustness benchmark with realistic distribution shifts. We measure the generalization of previous models including bag-of-words models, ConvNets, and LSTMs, and we show that pretrained Transformers’ performance declines are substantially smaller. Pretrained transformers are also more effective at detecting anomalous or OOD examples, while many previous models are frequently worse than chance. We examine which factors affect robustness, finding that larger models are not necessarily more robust, distillation can be harmful, and more diverse pretraining data can enhance robustness. Finally, we show where future work can improve OOD robustness.

When the curious abandon honesty: Federated learning is not private
In federated learning (FL), data does not leave personal devices when they are jointly training a machine learning model. Instead, these devices share gradients, parameters, or other model updates, with a central party (e.g., a company) coordinating the training. Because data never "leaves" personal devices, FL is often presented as privacy-preserving. Yet, recently it was shown that this protection is but a thin facade, as even a passive, honest-but-curious attacker observing gradients can reconstruct data of individual users contributing to the protocol.In this work, we show a novel data reconstruction attack which allows an active and dishonest central party to efficiently extract user data from the received gradients. While prior work on data reconstruction in FL relies on solving computationally expensive optimization problems or on making easily detectable modifications to the shared model’s architecture or parameters, in our attack the central party makes inconspicuous changes to the shared model’s weights before sending them out to the users. We call the modified weights of our attack trap weights.Our active attacker is able to recover user data perfectly, i.e., with zero error, even when this data stems from the same class. Recovery comes with near-zero costs: the attack requires no complex optimization objectives. Instead, our attacker exploits inherent data leakage from model gradients and simply amplifies this effect by maliciously altering the weights of the shared model through the trap weights. These specificities enable our attack to scale to fully-connected and convolutional deep neural networks trained with large mini-batches of data. For example, for the high-dimensional vision dataset ImageNet, we perfectly reconstruct more than 50% of the training data points from mini-batches as large as 100 data points. In textual tasks, such as IMDB sentiment analysis, more than 65% of data points from mini-batches containing 100 data points can be perfectly reconstructed.

Testing robustness against unforeseen adversaries
Considerable work on adversarial defense has studied robustness to a ﬁxed, known family of adversarial distortions, most frequently L p -bounded distortions. In reality, the speciﬁc form of attack will rarely be known and adversaries are free to employ distortions outside of any ﬁxed set. The present work advocates measuring robustness against this much broader range of unforeseen attacks —attacks whose precise form is not known when designing a defense. We propose a methodology for evaluating a defense against a diverse range of distortion types together with a summary metric UAR that measures the Unforeseen Attack Robustness against a distortion. We construct novel JPEG, Fog, Gabor, and Snow adversarial attacks to simulate unforeseen adversaries and perform a careful study of adversarial robustness against these and existing distortion types. We ﬁnd that evaluation against existing L p attacks yields highly correlated information that may not generalize to other attacks and identify a set of 4 attacks that yields more diverse information. We further ﬁnd that adversarial training against either one or multiple distortions, including our novel ones, does not confer robustness to unforeseen distortions. These results underscore the need to study robustness against unforeseen distortions and provide a starting point for doing so.

Demonstrating the BigDAWG Polystore System for Ocean Metagenomics Analysis.
In most Big Data applications, the data is heterogeneous. As we have been arguing in a series of papers, storage engines should be well suited to the data they hold. Therefore, a system supporting Big Data applications should be able to expose multiple storage engines through a single interface. We call such systems, polystore systems . Our reference implementation of the polystore concept is called BigDAWG (short for the Big Data Analytics Working Group). In this demonstration, we will show the BigDAWG system and a number of polystore applications built to help ocean metage-nomics researchers handle their heterogenous Big Data.

CaPC Learning: Confidential and Private Collaborative Learning
Machine learning benefits from large training datasets, which may not always be possible to collect by any single entity, especially when using privacy-sensitive data. In many contexts, such as healthcare and finance, separate parties may wish to collaborate and learn from each other's data but are prevented from doing so due to privacy regulations. Some regulations prevent explicit sharing of data between parties by joining datasets in a central location (confidentiality). Others also limit implicit sharing of data, e.g., through model predictions (privacy). There is currently no method that enables machine learning in such a setting, where both confidentiality and privacy need to be preserved, to prevent both explicit and implicit sharing of data. Federated learning only provides confidentiality, not privacy, since gradients shared still contain private information. Differentially private learning assumes unreasonably large datasets. Furthermore, both of these learning paradigms produce a central model whose architecture was previously agreed upon by all parties rather than enabling collaborative learning where each party learns and improves their own local model. We introduce Confidential and Private Collaborative (CaPC) learning, the first method provably achieving both confidentiality and privacy in a collaborative setting. We leverage secure multi-party computation (MPC), homomorphic encryption (HE), and other techniques in combination with privately aggregated teacher models. We demonstrate how CaPC allows participants to collaborate without having to explicitly join their training sets or train a central model. Each party is able to improve the accuracy and fairness of their model, even in settings where each party has a model that performs well on their own dataset or when datasets are not IID and model architectures are heterogeneous across parties.

Band-limited Training and Inference for Convolutional Neural Networks
The convolutional layers are core building blocks of neural network architectures. In general, a convolutional filter applies to the entire frequency spectrum of the input data. We explore artificially constraining the frequency spectra of these filters and data, called band-limiting, during training. The frequency domain constraints apply to both the feed-forward and back-propagation steps. Experimentally, we observe that Convolutional Neural Networks (CNNs) are resilient to this compression scheme and results suggest that CNNs learn to leverage lower-frequency components. In particular, we found: (1) band-limited training can effectively control the resource usage (GPU and memory); (2) models trained with band-limited layers retain high prediction accuracy; and (3) requires no modification to existing training algorithms or neural network architectures to use unlike other compression schemes.

September 2017. BigDAWG Version 0.1
The Emissions Database for Global Atmospheric Research (EDGAR) compiles anthropogenic emissions data for greenhouse gases (GHGs), and for multiple air pollutants, based on international statistics and emission factors. EDGAR data provide quantitative support for atmospheric modelling and for mitigation scenario and impact assessment analyses as well as for policy evaluation. The new version (v4.3.2) of the EDGAR emission inventory provides global estimates, broken down to IPCC-relevant source-sector levels, from 1970 (the year of the European Union’s first Air Quality Directive) to 2012 (the end year of the first commitment period of the Kyoto Protocol, KP). Strengths of EDGAR v4.3.2 include global geo-coverage (226 countries), continuity in time, and comprehensiveness in activities. Emissions of multiple chemical compounds, GHGs as well as air pollutants, from relevant sources (fossil fuel activities but also, for example, fermentation processes in agricultural activities) are compiled following a bottom-up (BU), transparent and IPCC-compliant methodology. This paper describes EDGAR v4.3.2 developments with respect to three major long-lived GHGs (CO2, CH4, and N2O) derived from a wide range of human activities apart from the land-use, land-use change and forestry (LULUCF) sector and apart from savannah burning; a companion paper quantifies and discusses emissions of air pollutants. Detailed information is included for each of the IPCC-relevant source sectors, leading to global totals for 2010 (in the middle of the first KP commitment period) (with a 95 % confidence interval in parentheses): 33.6(±5.9) Pg CO2 yr−1, 0.34(±0.16) Pg CH4 yr−1, and 7.2(±3.7) Tg N2O yr−1. We provide uncertainty factors in emissions data for the different GHGs and for three different groups of countries: OECD countries of 1990, countries with economies in transition in 1990, and the remaining countries in development (the UNFCCC nonAnnex I parties). We document trends for the major emitting countries together with the European Union in more Published by Copernicus Publications. 960 G. Janssens-Maenhout et al.: EDGAR greenhouse gas emissions detail, demonstrating that effects of fuel markets and financial instability have had greater impacts on GHG trends than effects of income or population. These data (https://doi.org/10.5281/zenodo.2658138, Janssens-Maenhout et al., 2019) are visualised with annual and monthly global emissions grid maps of 0.1× 0.1 for each source sector. 1 Historical evolution An essential component of the UN Framework Convention on Climate Change (UNFCCC, 1992) is the collection of nationally reported inventories and information on these greenhouse gas (GHG) emission inventory time series. At the time the UNFCCC was established, the 24 members of the OECD in 1990 and 16 other European countries and Russia were considered liable for “the largest share of historical and current global emissions of GHG” and taken up in Annex I to the UNFCCC. These Annex I countries and the European Union1 submit annually complete inventories of GHG emissions from the 1990 base year2 until the latest year for which full accounting is completed and reviewed (typically with a 2-year time lag), and these inventories are all reviewed to ensure transparency, completeness, comparability, consistency and accuracy3. This allows for most of these Annex I countries to track progress towards their reduction targets committed under the Kyoto Protocol (UNFCCC, 1997). Other (non-Annex I) countries are encouraged to submit their GHG inventories as part of their National Communications and Biennial Update Reports (BURs). The GHG inventories of nonAnnex I countries were required to cover CO2, CH4 and N2O emissions for 1 year (1990 or 1994), without specific documentation and only subject to a brief review. However, the Paris Agreement (UNFCCC, 2015) requires submission every 2 years of BURs4, which are subject to international consultation and analysis. Theoretically, UNFCCC should receive at the latest after 2 years national emissions inventories from each of the 197 countries, but as shown in Fig. 1a, not all countries did provide a national inventory and 154 countries did not provide a completed (i.e. year-2) time se1This includes the 28 Member States of the European Union (EU) as of 1 July 2013. 2For some economies in transition, another year such as 1988 or 1989 can be chosen under UNFCCC as the base year. These GHG emissions are mainly sources, but also include carbon stock sinks for which the human-induced part needs to be assessed with care (Grassi et al., 2018). 3These five principles of a good reporting practice are defined in the UNFCCC guidelines for national GHG inventory, e.g. https://pdfs.semanticscholar.org/3c30/ a1bd769dee5299746e0af825c7ab4ed55fba.pdf. EDGAR uses the term “comprehensiveness” to summarise these principles. 4The first BUR submitted should cover the inventory for the year no more than 4 years prior to the submission data, and subsequent BURs should be submitted every 2 years, but flexibility is given to the least developed countries and small island developing states. ries of inventories. In addition, many countries lack a welldeveloped statistical infrastructure, which is needed for an accurate bottom-up (BU) inventory. Figure 1b presents the latest year that is covered with a national inventory, with dates for quite a few countries more than 10 years ago: for most South-East Asian countries this is between 2004 and 2007 and for most African countries between 2000 and 2003. As such, the collection of national reports/communications does not provide a complete, consistent and comparable global dataset which can be used to understand the global budgets of the most important GHG emissions and their impact on climate. Very few bottom-up inventories of global anthropogenic emissions have been produced with continued effort for more than 2 decades. The Carbon Dioxide Information Analysis Centre (CDIAC) (Boden et al., 2017; Andres et al., 2014) and the Emissions Database for Global Atmospheric Research (EDGAR) (Olivier and Janssens-Maenhout, 2016; Olivier et al., 2016) provide global totals, whereas the IEA provides CO2 estimates from fuel combustion only and the FAO CH4 from agriculture only. While CDIAC ceased operation in September 2017, the Open-source Data Inventory for Anthropogenic CO2 (ODIAC) (Oda et al., 2018) continued to use the CDIAC data and combined these with geospatial proxies (including night light satellite maps) to provide CO2 grid maps, as EDGAR is also doing (using other geospatial proxies). In addition, the new Community Emissions Data System (CEDS) of Hoesly et al. (2018) builds upon existing inventories to provide a new gridded dataset of all emission species for the Climate Model Inter-comparison Programme CMIP6. The scientific community started to bring together these anthropogenic BU emissions with top-down estimates covering also the natural component to obtain the Global Carbon Budget (GCB) (Le Quéré et al., 2018) and the Global Methane Budget (Saunois et al., 2016). These budgets are important input for the periodic global stocktake that the Paris Agreement envisages from 2023 onwards (with the submitted inventories for 2021). Even though significant progress in inventory compilation has been made, the overall uncertainty of the global total has become larger over time because the share of emissions from non-Annex I countries (with less developed statistical infrastructure) increased from less than 40 % in 1990 to more than 60 % in 2012, as shown in Fig. 2. To support both science and policy making with the monitoring and verification of the GHG emissions, it is important Earth Syst. Sci. Data, 11, 959–1002, 2019 www.earth-syst-sci-data.net/11/959/2019/ G. Janssens-Maenhout et al.: EDGAR greenhouse gas emissions 961 Figure 1. (a) Inventory submission as received at UNFCCC (by January 2017) for all countries: expressed with the year of emission reporting in which the latest national communication to UNFCCC took place. (b) Inventory submission as received at UNFCCC (by January 2017) for all countries expressed with the latest year of emission that is covered in the inventory submitted to UNFCCC. Figure 2. Relative contribution of the Annex I and non-Annex I countries to the global total GHG emissions. The red, brown and orange dashed parts of the stack correspond to the non-Annex I share that increases from about 1/3 in 1990 to almost 2/3 in 2012. www.earth-syst-sci-data.net/11/959/2019/ Earth Syst. Sci. Data, 11, 959–1002, 2019 962 G. Janssens-Maenhout et al.: EDGAR greenhouse gas emissions that emissions are estimated by using comparable methodologies, consistent source allocation and comprehensive coverage of the globe. The EDGAR v4.3.2 global inventory illustrates the result of a bottom-up technology-based compilation of countryand sector-specific emission time series for 1970–2012. Furthermore, the monthly resolution and global grid maps at a spatial resolution of 0.1× 0.1 allow direct use in atmospheric models as well as in analyses of policy impacts. The first version of the Emissions Database for Global Atmospheric Research (EDGAR v2) answered the needs of the air quality community to map technological parameters of air pollution sources and was published by Olivier et al. (1996). Since then, several updated versions (Olivier, 2002) have been released (EDGAR-HYDE, EDGAR v3.2, EDGAR 3.2 FT2000). Driven by the development of scientific knowledge on emission generating processes and by the availability of more recent information, the EDGAR v4 datasets were constructed including new emission factors and additional end-of-pipe abatement measures. The specification of the combustion technology and its endof-pipe abatement is more important for air pollutants and aerosols than for GHGs. CO2 combustion emissions are fueldetermined and carbon capture and storage are not yet implemented at an opera

Flocks of Stochastic Parrots: Differentially Private Prompt Learning for Large Language Models
Large language models (LLMs) are excellent in-context learners. However, the sensitivity of data contained in prompts raises privacy concerns. Our work first shows that these concerns are valid: we instantiate a simple but highly effective membership inference attack against the data used to prompt LLMs. To address this vulnerability, one could forego prompting and resort to fine-tuning LLMs with known algorithms for private gradient descent. However, this comes at the expense of the practicality and efficiency offered by prompting. Therefore, we propose to privately learn to prompt. We first show that soft prompts can be obtained privately through gradient descent on downstream data. However, this is not the case for discrete prompts. Thus, we orchestrate a noisy vote among an ensemble of LLMs presented with different prompts, i.e., a flock of stochastic parrots. The vote privately transfers the flock's knowledge into a single public prompt. We show that LLMs prompted with our private algorithms closely match the non-private baselines. For example, using GPT3 as the base model, we achieve a downstream accuracy of 92.7% on the sst2 dataset with ($\epsilon=0.147, \delta=10^{-6}$)-differential privacy vs. 95.2% for the non-private baseline. Through our experiments, we also show that our prompt-based approach is easily deployed with existing commercial APIs.

Machine Learning enabled Spectrum Sharing in Dense LTE-U/Wi-Fi Coexistence Scenarios
The application of Machine Learning (ML) techniques to complex engineering problems has proved to be an attractive and efficient solution. ML has been successfully applied to several practical tasks like image recognition, automating industrial operations, etc. The promise of ML techniques in solving non-linear problems influenced this work which aims to apply known ML techniques and develop new ones for wireless spectrum sharing between Wi-Fi and LTE in the unlicensed spectrum. In this work, we focus on the LTE-Unlicensed (LTE-U) specification developed by the LTE-U Forum, which uses the duty-cycle approach for fair coexistence. The specification suggests reducing the duty cycle at the LTE-U base-station (BS) when the number of co-channel Wi-Fi basic service sets (BSSs) increases from one to two or more. However, without decoding the Wi-Fi packets, detecting the number of Wi-Fi BSSs operating on the channel in real-time is a challenging problem. In this work, we demonstrate a novel ML-based approach which solves this problem by using energy values observed during the LTE-U OFF duration. It is relatively straightforward to observe only the energy values during the LTE-U BS OFF time compared to decoding the entire Wi-Fi packet, which would require a full Wi-Fi receiver at the LTE-U base-station. We implement and validate the proposed ML-based approach by real-time experiments and demonstrate that there exist distinct patterns between the energy distributions between one and many Wi-Fi AP transmissions. The proposed ML-based approach results in a higher accuracy (close to 99% in all cases) as compared to the existing auto-correlation (AC) and energy detection (ED) approaches.

Data Transformation and Migration in Polystores
Ever increasing data size and new requirements in data processing has fostered the development of many new database systems. The result is that many data-intensive applications are underpinned by different engines. To enable data mobility there is a need to transfer data between systems easily and efficiently. We analyze the state-of-the-art of data migration and outline research opportunities for a rapid data transfer. Our experiments explore data migration between a diverse set of databases, including PostgreSQL, SciDB, S-Store and Accumulo. Each of the systems excels at specific application requirements, such as transactional processing, numerical computation, streaming data, and large scale text processing. Providing an efficient data migration tool is essential to take advantage of superior processing from that specialized databases. Our goal is to build such a data migration framework that will take advantage of recent advancement in hardware and software.

Deeplens: Towards a visual data management system
Advances in deep learning have greatly widened the scope of automatic computer vision algorithms and enable users to ask questions directly about the content in images and video. This paper explores the necessary steps towards a future Visual Data Management System (VDMS), where the predictions of such deep learning models are stored, managed, queried, and indexed. We propose a query and data model that disentangles the neural network models used, the query workload, and the data source semantics from the query processing layer. Our system, DeepLens, is based on dataflow query processing systems and this research prototype presents initial experiments to elicit important open research questions in visual analytics systems. One of our main conclusions is that any future "declarative" VDMS will have to revisit query optimization and automated physical design from a unified perspective of performance and accuracy tradeoffs. Physical design and query optimization choices can not only change performance by orders of magnitude, they can potentially affect the accuracy of results.

Integrating Real-Time and Batch Processing in a Polystore
This paper describes a stream processing engine called S-Store and its role in the BigDAWG polystore. Fundamentally, S-Store acts as a frontend processor that accepts input from multiple sources, and massages it into a form that has eliminated errors (data cleaning) and translates that input into a form that can be efficiently ingested into BigDAWG. S-Store also acts as an intelligent router that sends input tuples to the appropriate components of BigDAWG. All updates to S-Store's shared memory are done in a transactionally consistent (ACID) way, thereby eliminating new errors caused by non-synchronized reads and writes. The ability to migrate data from component to component of BigDAWG is crucial. We have described a migrator from S-Store to Postgres that we have implemented as a first proof of concept. We report some interesting results using this migrator that impact the evaluation of query plans.

Increasing the Cost of Model Extraction with Calibrated Proof of Work
In model extraction attacks, adversaries can steal a machine learning model exposed via a public API by repeatedly querying it and adjusting their own model based on obtained predictions. To prevent model stealing, existing defenses focus on detecting malicious queries, truncating, or distorting outputs, thus necessarily introducing a tradeoff between robustness and model utility for legitimate users. Instead, we propose to impede model extraction by requiring users to complete a proof-of-work before they can read the model's predictions. This deters attackers by greatly increasing (even up to 100x) the computational effort needed to leverage query access for model extraction. Since we calibrate the effort required to complete the proof-of-work to each query, this only introduces a slight overhead for regular users (up to 2x). To achieve this, our calibration applies tools from differential privacy to measure the information revealed by a query. Our method requires no modification of the victim model and can be applied by machine learning practitioners to guard their publicly exposed models against being easily stolen.

Preoperative paraspinal neck muscle characteristics predict early onset adjacent segment degeneration in anterior cervical fusion patients: A machine‐learning modeling analysis
Early onset adjacent segment degeneration (ASD) can be found within six months after anterior cervical discectomy and fusion (ACDF). Deficits in deep paraspinal neck muscles may be related to early onset ASD. This study aimed to determine whether the morphometry of preoperative deep neck muscles (multifidus and semispinalis cervicis) predicted early onset ASD in patients with ACDF. Thirty‐two cases of early onset ASD after a two‐level ACDF and 30 matched non‐ASD cases were identified from a large‐scale cohort. The preoperative total cross‐sectional area (CSA) of bilateral deep neck muscles and the lean muscle CSAs from C3 to C7 levels were measured manually on T2‐weighted magnetic resonance imaging. Paraspinal muscle CSA asymmetry at each level was calculated. A support vector machine (SVM) algorithm was used to identify demographic, radiographic, and/or muscle parameters that predicted proximal/distal ASD development. No significant between‐group differences in demographic or preoperative radiographic data were noted (mean age: 52.4 ± 10.9 years). ACDFs comprised C3 to C5 (n = 9), C4 to C6 (n = 20), and C5 to C7 (n = 32) cases. Eighteen, eight, and six patients had proximal, distal, or both ASD, respectively. The SVM model achieved high accuracy (96.7%) and an area under the curve (AUC = 0.97) for predicting early onset ASD. Asymmetry of fat at C5 (coefficient: 0.06), and standardized measures of C7 lean (coefficient: 0.05) and total CSA measures (coefficient: 0.05) were the strongest predictors of early onset ASD. This is the first study to show that preoperative deep neck muscle CSA, composition, and asymmetry at C5 to C7 independently predicted postoperative early onset ASD in patients with ACDF. Paraspinal muscle assessments are recommended to identify high‐risk patients for personalized intervention.

Columnstore and B+ tree-Are Hybrid Physical Designs Important?
Commercial DBMSs, such as Microsoft SQL Server, cater to diverse workloads including transaction processing, decision support, and operational analytics. They also support variety in physical design structures such as B+ tree and columnstore. The benefits of B+ tree for OLTP workloads and columnstore for decision support workloads are well-understood. However, the importance of hybrid physical designs, consisting of both columnstore and B+ tree indexes on the same database, is not well-studied --- a focus of this paper. We first quantify the trade-offs using carefully-crafted micro-benchmarks. This micro-benchmarking indicates that hybrid physical designs can result in orders of magnitude better performance depending on the workload. For complex real-world applications, choosing an appropriate combination of columnstore and B+ tree indexes for a database workload is challenging. We extend the Database Engine Tuning Advisor for Microsoft SQL Server to recommend a suitable combination of B+ tree and columnstore indexes for a given workload. Through extensive experiments using industry-standard benchmarks and several real-world customer workloads, we quantify how a physical design tool capable of recommending hybrid physical designs can result in orders of magnitude better execution costs compared to approaches that rely either on columnstore-only or B+ tree-only designs.

On the Difficulty of Defending Self-Supervised Learning against Model Extraction
Self-Supervised Learning (SSL) is an increasingly popular ML paradigm that trains models to transform complex inputs into representations without relying on explicit labels. These representations encode similarity structures that enable efficient learning of multiple downstream tasks. Recently, ML-as-a-Service providers have commenced offering trained SSL models over inference APIs, which transform user inputs into useful representations for a fee. However, the high cost involved to train these models and their exposure over APIs both make black-box extraction a realistic security threat. We thus explore model stealing attacks against SSL. Unlike traditional model extraction on classifiers that output labels, the victim models here output representations; these representations are of significantly higher dimensionality compared to the low-dimensional prediction scores output by classifiers. We construct several novel attacks and find that approaches that train directly on a victim's stolen representations are query efficient and enable high accuracy for downstream models. We then show that existing defenses against model extraction are inadequate and not easily retrofitted to the specificities of SSL.

DBMS Data Loading: An Analysis on Modern Hardware
Dataset Inference for Self-Supervised Models
Self-supervised models are increasingly prevalent in machine learning (ML) since they reduce the need for expensively labeled data. Because of their versatility in downstream applications, they are increasingly used as a service exposed via public APIs. At the same time, these encoder models are particularly vulnerable to model stealing attacks due to the high dimensionality of vector representations they output. Yet, encoders remain undefended: existing mitigation strategies for stealing attacks focus on supervised learning. We introduce a new dataset inference defense, which uses the private training set of the victim encoder model to attribute its ownership in the event of stealing. The intuition is that the log-likelihood of an encoder's output representations is higher on the victim's training data than on test data if it is stolen from the victim, but not if it is independently trained. We compute this log-likelihood using density estimation models. As part of our evaluation, we also propose measuring the fidelity of stolen encoders and quantifying the effectiveness of the theft detection without involving downstream tasks; instead, we leverage mutual information and distance measurements. Our extensive empirical results in the vision domain demonstrate that dataset inference is a promising direction for defending self-supervised models against model stealing.

Selective classification via neural network training dynamics
Selective classification is the task of rejecting inputs a model would predict incorrectly on through a trade-off between input space coverage and model accuracy. Current methods for selective classification impose constraints on either the model architecture or the loss function; this inhibits their usage in practice. In contrast to prior work, we show that state-of-the-art selective classification performance can be attained solely from studying the (discretized) training dynamics of a model. We propose a general framework that, for a given test input, monitors metrics capturing the disagreement with the final predicted label over intermediate models obtained during training; we then reject data points exhibiting too much disagreement at late stages in training. In particular, we instantiate a method that tracks when the label predicted during training stops disagreeing with the final predicted label. Our experimental evaluation shows that our method achieves state-of-the-art accuracy/coverage trade-offs on typical selective classification benchmarks.

On the privacy risk of in-context learning
Large language models (LLMs) are excellent few-shot learners. They can perform a wide variety of tasks purely based on natural language prompts provided to them. These prompts contain data of a specific downstream task—often the private dataset of a party, e.g., a company that wants to leverage the LLM on their purposes. We show that deploying prompted models presents a significant privacy risk for the data used within the prompt by instantiating a highly effective membership inference attack. We also observe that the privacy risk of prompted models exceeds fine-tuned models at the same utility levels. After identifying the model’s sensitivity to their prompts—in form of a significantly higher prediction confidence on the prompted data—as a cause for the increased risk, we propose ensembling as a mitigation strategy. By aggregating over multiple different versions of a prompted model, membership inference risk can be decreased.

DONE