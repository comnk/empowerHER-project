Fast Heuristic Search for RTS Game Combat Scenarios

 
 Heuristic search has been very successful in abstract game domains such as Chess and Go. In video games, however, adoption has been slow due to the fact that state and move spaces are much larger, real-time constraints are harsher, and constraints on computational resources are tighter. In this paper we present a fast search method — Alpha-Beta search for durative moves— that can defeat commonly used AI scripts in RTS game combat scenarios of up to 8 vs. 8 units running on a single core in under 5ms per search episode. This performance is achieved by using standard search enhancements such as transposition tables and iterative deepening, and novel usage of combat AI scripts for sorting moves and state evaluation via playouts. We also present evidence that commonly used combat scripts are highly exploitable — opening the door for a promising line of research on opponent combat modelling.
 


Alpha-Beta Pruning for Games with Simultaneous Moves

 
 Alpha-Beta pruning is one of the most powerful and fundamental MiniMax search improvements. It was designed for sequential two-player zero-sum perfect information games. In this paper we introduce an Alpha-Beta-like sound pruning method for the more general class of “stacked matrix games” that allow for simultaneous moves by both players. This is accomplished by maintaining upper and lower bounds for achievable payoffs in states with simultaneous actions and dominated action pruning based on the feasibility of certain linear programs. Empirical data shows considerable savings in terms of expanded nodes compared to naive depth-first move computation without pruning. 
 


Positional scoring-based allocation of indivisible goods
UCD: Upper Confidence bound for rooted Directed acyclic graphs
Condorcet winning sets
Solving breakthrough with Race Patterns and Job-Level Proof Number Search
Mechanisms for Online Organ Matching
Matching donations from deceased patients to patients on the waiting list account for over 85% of all kidney transplants performed in Australia. We propose a simple mechanisms to perform this matching and compare this new mechanism with the more complex algorithm currently under consideration by the Organ and Tissue Authority in Australia. We perform a number of experiments using real world data provided by the Organ and Tissue Authority of Australia. We find that our simple mechanism is more efficient and fairer in practice compared to the other mechanism currently under consideration.

Choosing Collectively Optimal Sets of Alternatives Based on the Condorcet Criterion
In elections, an alternative is said to be a Condorcet winner if it is preferred to any other alternative by a majority of voters. While this is a very attractive solution concept, many elections do not have a Condorcet winner. In this paper, we propose a setvalued relaxation of this concept, which we call a Condorcet winning set: such sets consist of alternatives that collectively dominate any other alternative. We also consider a more general version of this concept, where instead of domination by a majority of voters we require domination by a given fraction Θ of voters; we refer to this concept as Θ-winning set. We explore social choice-theoretic and algorithmic aspects of these solution concepts, both theoretically and empirically.

Score bounded Monte-Carlo tree search
AI surpasses humans at six-player poker
Self-learning Pluribus beats five humans in Texas hold'em showdown Superhuman performance by artificial intelligence (AI) has been demonstrated in two-player, deterministic, zero-sum, perfect-information games (1) such as chess, checkers (2), Hex, and Go (3). Research using AI has broadened to include games with challenging attributes such as randomness, multiple players, or imperfect information. Randomness is a feature of dice games, and card games include the additional complexity that each player sees some cards that are hidden from others. These aspects more closely resemble real-world situations, and this research may thus lead to algorithms with wider applicability. On page 885 of this issue, Brown and Sandholm (4) show that a new computer player called Pluribus exceeds human performance for six-player Texas hold'em poker.

Nested Monte Carlo Search for Two-Player Games

 
 The use of the Monte Carlo playouts as an evaluation function has proved to be a viable, general technique for searching intractable game spaces. This facilitate the use of statistical techniques like Monte Carlo Tree Search (MCTS), but is also known to require significant processing overhead. We seek to improve the quality of information extracted from the Monte Carlo playout in three ways. Firstly, by nesting the evaluation function inside another evaluation function; secondly, by measuring and utilising the depth of the playout; and thirdly, by incorporating pruning strategies that eliminate unnecessary searches and avoid traps. Our experimental data, obtained on a variety of two-player games from past General Game Playing (GGP) competitions and others, demonstrate the usefulness of these techniques in a Nested Player when pitted against a standard, optimised UCT player.
 


Strategic voting and the logic of knowledge
We propose a general framework for strategic voting when a voter may lack knowledge about other votes or about other voters' knowledge about her own vote. In this setting we define notions of manipulation and equilibrium. We also model action changing knowledge about votes, such as a voter revealing its preference or as a central authority performing a voting poll. Some forms of manipulation are preserved under such updates and others not. Another form of knowledge dynamics is the effect of a voter declaring its vote. We envisage Stackelberg games for uncertain profiles. The purpose of this investigation is to provide the epistemic background for the analysis and design of voting rules that incorporate uncertainty.

Foundations of Digital Arch {\ae} oludology
On the Complexity of Trick-Taking Card Games
Monte Carlo*-Minimax Search
Monte Carlo*-Minimax Search
Fairness in Deceased Organ Matching
As algorithms are given responsibility to make decisions that impact our lives, there is increasing awareness of the need to ensure the fairness of these decisions. One of the first challenges then is to decide what fairness means in a particular context. We consider here fairness in deciding how to match organs donated by deceased donors to patients. Due to the increasing age of patients on the waiting list, and of organs being donated, the current "first come, first served'' mechanism used in Australia is under review to take account of age of patients and of organs. We consider how to revise the mechanism to take account of age fairly. We identify a number of different types of fairness, such as to patients, to regions and to blood types and consider how they can be achieved.

On the Complexity of Connection Games
Utilisation de la recherche arborescente Monte-Carlo au Hex
Nous presentons YOPT, un programme qui joue au Hex en utilisant des techniques de Monte-Carlo. Nous decrivons des heuristiques pour ameliorer les simulations et les descentes d'arbre Monte-Carlo. Nous abordons aussi l'utilisation d'heuristiques pour ameliorer la parallelisation du programme. Le niveau de YOPT atteint le niveau de SIX pour les temps utilises en competition.

Safe Multi-Agent Pathfinding with Time Uncertainty
In many real-world scenarios, the time it takes for a mobile agent, e.g., a robot, to move from one location to another may vary due to exogenous events and be difficult to predict accurately. Planning in such scenarios is challenging, especially in the context of Multi-Agent Pathfinding (MAPF), where the goal is to find paths to multiple agents and temporal coordination is necessary to avoid collisions. In this work, we consider a MAPF problem with this form of time uncertainty, where we are only given upper and lower bounds on the time it takes each agent to move. The objective is to find a safe solution, which is a solution that can be executed by all agents and is guaranteed to avoid collisions. We propose two complete and optimal algorithms for finding safe solutions based on well-known MAPF algorithms, namely, A* with Operator Decomposition (A* + OD) and Conflict-Based Search (CBS). Experimentally, we observe that on several standard MAPF grids the CBS-based algorithm performs better. We also explore the option of online replanning in this context, i.e., modifying the agents' plans during execution, to reduce the overall execution cost. We consider two online settings: (a) when an agent can sense the current time and its current location, and (b) when the agents can also communicate seamlessly during execution. For each setting, we propose a replanning algorithm and analyze its behavior theoretically and empirically. Our experimental evaluation confirms that indeed online replanning in both settings can significantly reduce solution cost.

DONE