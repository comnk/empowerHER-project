Workload generation for YouTube
Cluster-discovery of Twitter messages for event detection and trending
Application of multilayer perceptron neural networks and support vector machines in classification of healthcare data
A large volume of data is steadily produced by the healthcare industry on daily basis. Data mining and machine learning approaches are two effective techniques applicable for data analysis and finding the hidden patterns which can be utilized for medical decision making. As the decisions in medical field are dealing with patient outcome, a high level of accuracy in data mining is needed. In this paper a comparison between implemented multilayer perceptron neural networks and support vector machine on heart diseases dataset is conducted. We have analyzed the effectiveness of support vector machine in classification, using a dataset of 303 patients. Our results show that support vector machine is able to classify more accurately.

Inspection interval optimization for a k-out-of-n load sharing system under a hybrid mixed redundancy strategy
Condition-based optimization of non-identical inspection intervals for a k-out-of-n load sharing system with hybrid mixed redundancy strategy
Web object-based storage management in proxy caches
A neural network approach for wireless sensor network power management
In this paper we introduce a new approach for wireless sensor network power management which is based on eural etworks. In this new approach an intelligent analysis is used to process the structure of a wireless sensor network (WS ) and produce some information which can be used to improve the performance of WS s’ management application. We applied our intelligent method to our previously proposed management approach which uses the concept of Multi-Agent systems for WS s’ management and observed the improvement of the performance. Wireless sensor networks need to be managed in different ways; e.g. power consumption of each sensor, efficient data routing without redundancy, sensing and data sending interval control, etc. The random distribution of wireless sensors, numerous variables which affect WS ’s operation and the uncertainty of different algorithms (such as sensors’ self-localization) give a fuzzy nature to WS s. Considering this fuzzy nature and numerous details, a neural network is an ideal tool to be used to cover these details which are so hard to be explicitly discovered and modeled. In this paper we introduce our eural etworkbased approach which results in a more efficient routing path discovery and sensor power management. We define a set of attributes based on sensors’ location and neighborhood and we use them as inputs of our neural network and the output of the neural network will be used as a factor in the route path discovery and power management. We designed a simulator based on our approach and observed the effect of our method on wireless sensor network lifetime and sensor power consumption which will be presented in this

Credit card fraud detection using fuzzy logic and neural network
The credit card fraud is dramatically increasing due to rise and rapid growth of E-commerce. Due to the huge number of transactions, credit card fraud detection is a big challenge for banks to minimize their losses and for customers to feel secure. In this paper fuzzy database is used to detect credit cards fraud. Fraud detection involves monitoring user's behaviour to estimate, detect or avoid undesirable behaviours. To correctly identify a transaction as legitimate or fraudulent has been considered a data mining problem. In this paper we discuss the fuzzy logic method, fuzzy rules, membership functions, fuzzification and defuzzification. Later, this method is implemented on the dataset using fuzzy logic toolbox in Matlab and the results are compared with the results of the artificial neural network method ANN. Our results indicates that the ANN method is 33% more accurate than the fuzzy logic.

Optimizing a joint reliability-redundancy allocation problem with common cause multi-state failures using immune algorithm
Redundancy-reliability allocation problem (RRAP) is a well-known problem in reliability area. In general, this problem aims to maximize a system’s reliability or minimize a system’s costs under some constraints. In this paper, we develop a RRAP for a series-parallel system with multi-state components. Thus, the subsystems’ components, the system’s subsystems, and the system have different working states with corresponding working probabilities. The RAP in the paper is a RAP with mix components (RAPMC). We consider the choice of allocating non-identical components to each sub-system. Moreover, we consider the common cause failure (CCF) for the components, which causes simultaneous failure of all identical components of a subsystem. We assume the component’s failure state probability is reduced by conducting technical activities, and the reduced probability is added to the component’s working states’ probabilities. The model’s objective function is to minimize the system’s costs under a minimum reliability level and other constraints by allocating the optimal set of components to each subsystem and determining each component’s technical activities level. Since the RRAP belongs to the Np-Hard category of problems, an immune algorithm is used to solve the developed problem. The results indicate considering the technical activities decreases the system’s costs.

A comparative study on content-based paper-to-paper recommendation approaches in scientific literature
This paper deals with analysis and comparison of two well-known content-based recommendation approaches for scientific papers in biomedical domain. Given a rich set of abstracts for thousands of articles from PUBMED, a series of efficient pre-processing techniques are proposed. Then, for the first approach, a Term-frequency Inverse-document-frequency (TF-IDF) algorithm is formulated to make recommendations for the paper-set. Alternatively, we also use word-embedding to represent papers' abstract text and employ the extracted representation for the recommendation construction. Experimental results will evaluate and compare the efficiency and suitability of any of the proposed frameworks in building a universal paper-to-paper recommendation engine.

Using unmanned aerial vehicles (UAVs) in locating wandering patients with dementia
This paper presents findings from three experiments involving the use of Unmanned Aerial Vehicles (UAVs) for the purpose of locating a wandering person whose behavior resembles the behavior of a wandering patient with dementia. Additionally, it presents research review on the use of UVs in locating wandering eprsons with dementia. The characteristics of this critical form of wandering-or eloping — are discussed. By using test subjects simulating individual lost patients with dementia, along with current Search and Rescue (SAR) operational methods, experiments were performed employing drones to find the wandering persons. The algorithm used to determine the drone paths is based on the analysis of incidents analyzed in the literature from the International Search and Rescue Incident Database (ISRID) which contains thousands of international and national police records on lost persons. The experiments revealed that UAVs, if used with the pre-determined path, could expedite the search process thus improving the survivability of the lost person. The paper considers the time needed to detect the person, duration of the complete mission, the differential longitude and latitude analysis from an Initial Planning Point (IPP), the time taken to find the test subject and the battery life of the drone. Challenges and recommendations are presented to inform future experiments.

A weighted energy efficient clustering (WEEC) for wireless sensor networks
Wireless sensor networks consist of hundreds or thousands of nodes and are broadly used for collecting data from the environment. In this type of network nodes communicate with each other and send their data to the base station. Since sensor nodes are battery limited, it is crucial to minimize the amount of energy they dissipate for communication. The LEACH protocol is an elegant clustering algorithm for sending information to base station. It uses clustering, therefore each node only communicates with their cluster head nodes and then those cluster heads communicate with base station. In this paper we improved the LEACH algorithm and proposed a weighted energy efficient clustering algorithm (WEEC) algorithm for wireless sensor networks. We take into consideration the location of each node while clusters are forming. The simulation result proves that our proposed scheme noticeably increases the life time of the network.

Fuzzy database for heart disease diagnosis
In this paper we have proposed a Fuzzy Petri Nets Expert System for heart disease diagnosis. The aim of the proposed system is simulating experience of experts in Diagnosis Heart Disease stage, based on Fuzzy Rule System and modeling reasoning operation by using Fuzzy Petri Nets. The database taken from Machine Learning Repository Center for machine learning and intelligent system. The system has 11 input fields and one output field. The accuracy of proposed system is 75%.

A new agent-based solution for wireless sensor networks management
In this paper, we introduce a new approach for wireless sensor networks management which is an improved version of previously proposed methods, using the concept of Multi-Agent Systems. From a software point of view, wireless sensor networks need to be managed in many different ways; e.g. power consumption in each sensor, efficient data routing, sensing and data sending interval, etc. Our approach gives the network a more structured model, and manages the former issues using multi-agent system concepts. In our model, we propose a new method for sensor power management which we call Neighbors Power Comparison (NPC). We defined 4 different power thresholds, and when the sensor's power meets each one of these thresholds a power reduction algorithm will try to reduce the amount of energy used by sensor. We also cover the whole life-time process of a sensor network using our model.

Scalable object detection, tracking and pattern recognition model using edge computing
The Internet of Things (IoT) devices such as sensors and video cameras have small memories and less computational power. The video analytics of traditional approaches for detection, tracking and pattern recognition of moving objects used only in the cloud. This approach suffered from high latency and more network bandwidth to transfer data into the cloud. We address this problem by using edge computing devices between IoT devices and the cloud. We propose a new framework for scalable object detection, tracking and pattern recognition of moving objects that relies on dimensionality reduction with edge computing architecture. We also propose a scalable object detection and tracking method based on You Only Look Once (YOLO) method. The experiment demonstrates that our proposed method will save network bandwidth and processing time. The performance of object detection and tracking model is greater than 96%. This shows that our method has greater performance than existing models.

Scalable grid resource discovery through distributed search
This paper proposes a simple and scalable web-based model for grid resource discovery for the Internet. The resource discovery model contains the metadata and resource finder web services. The information of resource finder web services is kept in the repositories that are distributed in the application layer of Internet. The resource finder web services will be discovered by sending queries to the repositories in a similar way as the DNS protocol. The underlying technology for implementation of the two architectures of this model is introduced. These architectures are: Direct and Centralized Web-Based Grid Resource Discovery. The resource discovery time is computed after simulating each of these models in GridSim.

Cache replacement solutions by evolutionary computing technique
As we know Internet have grown rapidly in the past few years, and one of the prevalent problems of World Wide Web is increasing network traffic. It has been shown that caching is valuable technique that reduces network traffic. However, still it has some problems such as performance problem. This paper proposes a novel way to solve those problems efficiently by introducing the evolutionary computing technique for cache replacement policy.

Content-based Node2Vec for representation of papers in the scientific literature
Cognitive and hierarchical fuzzy inference system for generating next release planning in saas applications
The next release planning is considered as a cognitive decision-making problem where many stakeholders provide their judgments and opinions about the set of features that shall be included in the next release of the software. In multi-tenant Software as a Service (SaaS) applications, planning for the next release is a significant process that plays important roles in the success of SaaS applications. SaaS providers shall fulfill the evolving needs and requirements of their tenants by continuously delivering new releases. The first step in a release development lifecycle is the release planning process. This paper proposes a novel approach for the next release planning for multi-tenant SaaS applications. This approach is a prioritization approach that employs a hierarchical fuzzy inference system (HFIS) module to deal with the uncertainty associated with human judgments. The main objectives of the proposed approach are maximizing the degree of overall tenants’ satisfaction, maximizing the degree of commonality, and minimizing the potential risk, while considering contractual, effort, and dependencies constraints. The performance of the proposed approach is validated against a one from the literature and shows better results from the perspective of overall tenants’ satisfaction and adherence to the risk.

Modeling of multimedia files on the web 2.0
In this paper we introduced a workload characterization study of the most popular video sharing service, YouTube, on the Web 2.0. For approximately a two-month period we collected the information of more than 17,000 video files and investigated the file attributes and popularity characteristics of YouTube. Since YouTube is considered as a huge video library, its access pattern has an important impact on the Internet traffic distribution. Comprehension of YouTube features and similar video sharing sites is critical to analyze network traffic and to develop novel user generated contents (UGC) services. This distribution models especially Zipf-like behavior of popular video files suggests caching may reduce network traffic and increase scalability of YouTube Web site.

DONE