Universal Decompositional Semantics on Universal Dependencies
We present a framework for augmenting data sets from the Universal Dependencies project with Universal Decompositional Semantics . Where the Universal Dependencies project aims to provide a syntactic annotation standard that can be used consistently across many languages as well as a collection of corpora that use that standard, our extension has similar aims for semantic annotation. We describe results from annotating the English Universal Dependencies treebank, dealing with word senses, semantic roles, and event properties

Collecting diverse natural language inference problems for sentence representation evaluation
We present a large-scale collection of diverse natural language inference (NLI) datasets that help provide insight into how well a sentence representation captures distinct types of reasoning. The collection results from recasting 13 existing datasets from 7 semantic phenomena into a common NLI structure, resulting in over half a million labeled context-hypothesis pairs in total. We refer to our collection as the DNC: Diverse Natural Language Inference Collection. The DNC is available online at https://www.decomp.net, and will grow over time as additional resources are recast and added from novel sources.

Neural models of factuality
We present two neural models for event factuality prediction, which yield significant performance gains over previous models on three event factuality datasets: FactBank, UW, and MEANTIME. We also present a substantial expansion of the It Happened portion of the Universal Decompositional Semantics dataset, yielding the largest event factuality dataset to date. We report model results on this extended factuality dataset as well.

Inference is everything: Recasting semantic resources into a unified evaluation framework
We propose to unify a variety of existing semantic classification tasks, such as semantic role labeling, anaphora resolution, and paraphrase detection, under the heading of Recognizing Textual Entailment (RTE). We present a general strategy to automatically generate one or more sentential hypotheses based on an input sentence and pre-existing manual semantic annotations. The resulting suite of datasets enables us to probe a statistical RTE model’s performance on different aspects of semantics. We demonstrate the value of this approach by investigating the behavior of a popular neural network RTE model.

Fine-grained temporal relation extraction
We present a novel semantic framework for modeling temporal relations and event durations that maps pairs of events to real-valued scales. We use this framework to construct the largest temporal relations dataset to date, covering the entirety of the Universal Dependencies English Web Treebank. We use this dataset to train models for jointly predicting fine-grained temporal relations and event durations. We report strong results on our data and show the efficacy of a transfer-learning approach for predicting categorical relations.

The role of veridicality and factivity in clause selection
This paper investigates the relationship between clausal selection and two lexical semantic properties that have been claimed to be important in determining such selection: factivity (Hintikka 1975) and veridicality (Egré 2008). Specifically, these properties have been suggested to be connected to responsivity: selection of both declarative and interrogative complements. Our investigation builds on the MegaAttitude dataset of White & Rawlins (2016), which contains experimentally-collected acceptability judgments for effectively every English verb that embeds clauses, in a large set of frames. Based on these acceptability judgments, we collect a new dataset of veridicality judgments for all English verbs that embed declarative clauses.1 This allows a systematic, large-scale comparison of veridicality judgments and selectional patterns. We show that factivity and veridicality do not correlate with responsivity when considering the entirety of the lexicon but that they do correlate with other selectional patterns, in particular, selection of DP direct and indirect objects. We begin in §2 by introducing specific hypotheses and assumptions about factivity, veridicality, and responsivity. We then introduce our methods and resulting dataset in §3-4, and in §5 develop both confirmatory analyses to test the hypotheses introduced in §2, and exploratory analyses to discover new relationships among the variables in our datasets.

Reading the manual: Event extraction as definition comprehension
We ask whether text understanding has progressed to where we may extract event information through incremental refinement of bleached statements derived from annotation manuals. Such a capability would allow for the trivial construction and extension of an extraction framework by intended end-users through declarations such as, “Some person was born in some location at some time.” We introduce an example of a model that employs such statements, with experiments illustrating we can extract events under closed ontologies and generalize to unseen event types simply by reading new definitions.

Lexicosyntactic inference in neural models
We investigate neural models’ ability to capture lexicosyntactic inferences: inferences triggered by the interaction of lexical and syntactic information. We take the task of event factuality prediction as a case study and build a factuality judgment dataset for all English clause-embedding verbs in various syntactic contexts. We use this dataset, which we make publicly available, to probe the behavior of current state-of-the-art neural systems, showing that these systems make certain systematic errors that are clearly visible through the lens of factuality prediction.

Semantic information and the syntax of propositional attitude verbs
Propositional attitude verbs, such as think and want, have long held interest for both theoretical linguists and language acquisitionists because their syntactic, semantic, and pragmatic properties display complex interactions that have proven difficult to fully capture from either perspective. This paper explores the granularity with which these verbs' semantic and pragmatic properties are recoverable from their syntactic distributions, using three behavioral experiments aimed at explicitly quantifying the relationship between these two sets of properties. Experiment 1 gathers a measure of 30 propositional attitude verbs' syntactic distributions using an acceptability judgment task. Experiments 2a and 2b gather measures of semantic similarity between those same verbs using a generalized semantic discrimination (triad or "odd man out") task and an ordinal (Likert) scale task, respectively. Two kinds of analyses are conducted on the data from these experiments. The first compares both the acceptability judgments and the semantic similarity judgments to previous classifications derived from the syntax and semantics literature. The second kind compares the acceptability judgments to the semantic similarity judgments directly. Through these comparisons, we show that there is quite fine-grained information about propositional attitude verbs' semantics carried in their syntactic distributions-whether one considers the sorts of discrete qualitative classifications that linguists traditionally work with or the sorts of continuous quantitative classifications that can be derived experimentally.

Temporal reasoning in natural language inference
We introduce five new natural language inference (NLI) datasets focused on temporal reasoning. We recast four existing datasets annotated for event duration—how long an event lasts—and event ordering—how events are temporally arranged—into more than one million NLI examples. We use these datasets to investigate how well neural models trained on a popular NLI corpus capture these forms of temporal reasoning.

Gradual fine-tuning for low-resource domain adaptation
Fine-tuning is known to improve NLP models by adapting an initial model trained on more plentiful but less domain-salient examples to data in a target domain. Such domain adaptation is typically done using one stage of fine-tuning. We demonstrate that gradually fine-tuning in a multi-step process can yield substantial further gains and can be applied without modifying the model or learning objective.

LOME: Large ontology multilingual extraction
We present LOME, a system for performing multilingual information extraction. Given a text document as input, our core system identifies spans of textual entity and event mentions with a FrameNet (Baker et al., 1998) parser. It subsequently performs coreference resolution, fine-grained entity typing, and temporal relation prediction between events. By doing so, the system constructs an event and entity focused knowledge graph. We can further apply third-party modules for other types of annotation, like relation extraction. Our (multilingual) first-party modules either outperform or are competitive with the (monolingual) state-of-the-art. We achieve this through the use of multilingual encoders like XLM-R (Conneau et al., 2020) and leveraging multilingual training data. LOME is available as a Docker container on Docker Hub. In addition, a lightweight version of the system is accessible as a web demo.

The role of incremental parsing in syntactically conditioned word learning
A computational model of S-selection
We develop a probabilistic model of S(emantic)-selection that encodes both the notion of systematic mappings from semantic type signature to syntactic distribution — i.e., projection rules — and the notion of selectional noise — e.g., C(ategory)-selection, L(exical)-selection, and/or other independent syntactic processes. We train this model on data from a large-scale judgment study assessing the acceptability of 1,000 English clause-taking verbs in 50 distinct syntactic frames, finding that this model infers coherent semantic type signatures. We focus in on type signatures relevant to interrogative and declarative selection, arguing that our results suggest a principled split between cognitive verbs, which select distinct proposition and question types, and communicative verbs, which select a single hybrid type.

On believing and hoping whether
Theories of clause selection that aim to explain the distribution of interrogative and declarative complement clauses often take as a starting point that predicates like think , believe , hope , and fear are incompatible with interrogative complements. After discussing experimental evidence against the generalizations on which these theories rest, I give corpus evidence that even the core data are faulty: think , believe , hope , and fear are in fact compatible with interrogative complements, suggesting that any theory predicting that they should not be must be jettisoned. 
 
EARLY ACCESS

Everything is all it takes: A multipronged strategy for zero-shot cross-lingual information extraction
Zero-shot cross-lingual information extraction (IE) describes the construction of an IE model for some target language, given existing annotations exclusively in some other language, typically English. While the advance of pretrained multilingual encoders suggests an easy optimism of “train on English, run on any language”, we find through a thorough exploration and extension of techniques that a combination of approaches, both new and old, leads to better performance than any one cross-lingual strategy in particular. We explore techniques including data projection and self-training, and how different pretrained encoders impact them. We use English-to-Arabic IE as our initial example, demonstrating strong performance in this setting for event extraction, named entity recognition, part-of-speech tagging, and dependency parsing. We then apply data projection and self-training to three tasks across eight target languages. Because no single set of techniques performs the best across all tasks, we encourage practitioners to explore various configurations of the techniques described in this work when seeking to improve on zero-shot training.

The universal decompositional semantics dataset and decomp toolkit
We present the Universal Decompositional Semantics (UDS) dataset (v1.0), which is bundled with the Decomp toolkit (v0.1). UDS1.0 unifies five high-quality, decompositional semantics-aligned annotation sets within a single semantic graph specification—with graph structures defined by the predicative patterns produced by the PredPatt tool and real-valued node and edge attributes constructed using sophisticated normalization procedures. The Decomp toolkit provides a suite of Python 3 tools for querying UDS graphs using SPARQL. Both UDS1.0 and Decomp0.1 are publicly available at http://decomp.io.

Decomposing generalization: Models of generic, habitual, and episodic statements
Abstract We present a novel semantic framework for modeling linguistic expressions of generalization— generic, habitual, and episodic statements—as combinations of simple, real-valued referential properties of predicates and their arguments. We use this framework to construct a dataset covering the entirety of the Universal Dependencies English Web Treebank. We use this dataset to probe the efficacy of type-level and token-level information—including hand-engineered features and static (GloVe) and contextual (ELMo) word embeddings—for predicting expressions of generalization.

An experimental investigation of partial control
In Partial Control, the understood subject of an obligatorily controlled complement is construed as properly containing the controlling argument (e.g., John wanted [PRO to gather at noon], where PRO = John and contextually salient others). Since this phenomenon was first systematically described by Landau (2000), many accounts of it have been offered. But some of the diversity in these accounts reflects disagreement over what the facts are. To address this, we use experimental syntax to collect and analyze sentence acceptability judgments that bear on the availability of Partial Control across a wide range of control predicates. Results indicate a substantial amount of gradability in the availability of Partial Control as a function of the choice of control predicate, in a way that depends in part on the predicate’s temporal, aspectual, and modal properties. Although these findings are not fully consistent with any existing approach to Partial Control, we suggest that Pearson’s (2013) approach lays a promising foundation for further research.

Discovering classes of attitude verbs using subcategorization frame distributions
The goal of this research was to discover what kinds of syntactic categories can be learned using distributional analysis on linear context of words, specifically in childdirected speech. The idea behind this is that the categories used by children could very well be different from adult categories. There is some evidence that distributional analysis could be used for some aspects of language acquisition, though very strong arguments exist for why it is not enough to acquire grammar. These experiments can help identify what kind of data can be learned from linear context and statistics only. This paper reports the results of three established automatic syntactic category learning algorithms on a small, edited input set of child-directed speech from the CHILDES database. Hierarchical clustering, K-Means analysis, and an implementation of a substitution algorithm are all used to assign syntactic categories to words based on their linear distributional context. Overall, open classes (nouns, verbs, adjectives) were reliably categorized, and some methods were able to distinguish prepositions, adverbs, subjects vs. objects, and verbs by subcategorization frame. The main barrier standing between these methods and human-like categorization is the inability to deal with the ambiguity that is omnipresent in natural language and poses an important problem for future models of syntactic category acquisition. Thesis Supervisor: Robert C. Berwick Title: Professor of Computational Linguistics and Computer Science and Engineering

DONE