Universal Decompositional Semantics on Universal Dependencies
We present a framework for augmenting data sets from the Universal Dependencies project with Universal Decompositional Semantics . Where the Universal Dependencies project aims to provide a syntactic annotation standard that can be used consistently across many languages as well as a collection of corpora that use that standard, our extension has similar aims for semantic annotation. We describe results from annotating the English Universal Dependencies treebank, dealing with word senses, semantic roles, and event properties

Collecting diverse natural language inference problems for sentence representation evaluation
We present a large-scale collection of diverse natural language inference (NLI) datasets that help provide insight into how well a sentence representation captures distinct types of reasoning. The collection results from recasting 13 existing datasets from 7 semantic phenomena into a common NLI structure, resulting in over half a million labeled context-hypothesis pairs in total. We refer to our collection as the DNC: Diverse Natural Language Inference Collection. The DNC is available online at https://www.decomp.net, and will grow over time as additional resources are recast and added from novel sources.

Neural models of factuality
We present two neural models for event factuality prediction, which yield significant performance gains over previous models on three event factuality datasets: FactBank, UW, and MEANTIME. We also present a substantial expansion of the It Happened portion of the Universal Decompositional Semantics dataset, yielding the largest event factuality dataset to date. We report model results on this extended factuality dataset as well.

Inference is everything: Recasting semantic resources into a unified evaluation framework
We propose to unify a variety of existing semantic classification tasks, such as semantic role labeling, anaphora resolution, and paraphrase detection, under the heading of Recognizing Textual Entailment (RTE). We present a general strategy to automatically generate one or more sentential hypotheses based on an input sentence and pre-existing manual semantic annotations. The resulting suite of datasets enables us to probe a statistical RTE model’s performance on different aspects of semantics. We demonstrate the value of this approach by investigating the behavior of a popular neural network RTE model.

Fine-grained temporal relation extraction
We present a novel semantic framework for modeling temporal relations and event durations that maps pairs of events to real-valued scales. We use this framework to construct the largest temporal relations dataset to date, covering the entirety of the Universal Dependencies English Web Treebank. We use this dataset to train models for jointly predicting fine-grained temporal relations and event durations. We report strong results on our data and show the efficacy of a transfer-learning approach for predicting categorical relations.

The role of veridicality and factivity in clause selection
This paper investigates the relationship between clausal selection and two lexical semantic properties that have been claimed to be important in determining such selection: factivity (Hintikka 1975) and veridicality (Egré 2008). Specifically, these properties have been suggested to be connected to responsivity: selection of both declarative and interrogative complements. Our investigation builds on the MegaAttitude dataset of White & Rawlins (2016), which contains experimentally-collected acceptability judgments for effectively every English verb that embeds clauses, in a large set of frames. Based on these acceptability judgments, we collect a new dataset of veridicality judgments for all English verbs that embed declarative clauses.1 This allows a systematic, large-scale comparison of veridicality judgments and selectional patterns. We show that factivity and veridicality do not correlate with responsivity when considering the entirety of the lexicon but that they do correlate with other selectional patterns, in particular, selection of DP direct and indirect objects. We begin in §2 by introducing specific hypotheses and assumptions about factivity, veridicality, and responsivity. We then introduce our methods and resulting dataset in §3-4, and in §5 develop both confirmatory analyses to test the hypotheses introduced in §2, and exploratory analyses to discover new relationships among the variables in our datasets.

Reading the manual: Event extraction as definition comprehension
We ask whether text understanding has progressed to where we may extract event information through incremental refinement of bleached statements derived from annotation manuals. Such a capability would allow for the trivial construction and extension of an extraction framework by intended end-users through declarations such as, “Some person was born in some location at some time.” We introduce an example of a model that employs such statements, with experiments illustrating we can extract events under closed ontologies and generalize to unseen event types simply by reading new definitions.

Lexicosyntactic inference in neural models
We investigate neural models’ ability to capture lexicosyntactic inferences: inferences triggered by the interaction of lexical and syntactic information. We take the task of event factuality prediction as a case study and build a factuality judgment dataset for all English clause-embedding verbs in various syntactic contexts. We use this dataset, which we make publicly available, to probe the behavior of current state-of-the-art neural systems, showing that these systems make certain systematic errors that are clearly visible through the lens of factuality prediction.

Semantic information and the syntax of propositional attitude verbs
Propositional attitude verbs, such as think and want, have long held interest for both theoretical linguists and language acquisitionists because their syntactic, semantic, and pragmatic properties display complex interactions that have proven difficult to fully capture from either perspective. This paper explores the granularity with which these verbs' semantic and pragmatic properties are recoverable from their syntactic distributions, using three behavioral experiments aimed at explicitly quantifying the relationship between these two sets of properties. Experiment 1 gathers a measure of 30 propositional attitude verbs' syntactic distributions using an acceptability judgment task. Experiments 2a and 2b gather measures of semantic similarity between those same verbs using a generalized semantic discrimination (triad or "odd man out") task and an ordinal (Likert) scale task, respectively. Two kinds of analyses are conducted on the data from these experiments. The first compares both the acceptability judgments and the semantic similarity judgments to previous classifications derived from the syntax and semantics literature. The second kind compares the acceptability judgments to the semantic similarity judgments directly. Through these comparisons, we show that there is quite fine-grained information about propositional attitude verbs' semantics carried in their syntactic distributions-whether one considers the sorts of discrete qualitative classifications that linguists traditionally work with or the sorts of continuous quantitative classifications that can be derived experimentally.

Temporal reasoning in natural language inference
We introduce five new natural language inference (NLI) datasets focused on temporal reasoning. We recast four existing datasets annotated for event duration—how long an event lasts—and event ordering—how events are temporally arranged—into more than one million NLI examples. We use these datasets to investigate how well neural models trained on a popular NLI corpus capture these forms of temporal reasoning.

Gradual fine-tuning for low-resource domain adaptation
