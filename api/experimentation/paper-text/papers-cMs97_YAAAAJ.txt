How do users like this feature? a fine grained sentiment analysis of app reviews
App stores allow users to submit feedback for downloaded apps in form of star ratings and text reviews. Recent studies analyzed this feedback and found that it includes information useful for app developers, such as user requirements, ideas for improvements, user sentiments about specific features, and descriptions of experiences with these features. However, for many apps, the amount of reviews is too large to be processed manually and their quality varies largely. The star ratings are given to the whole app and developers do not have a mean to analyze the feedback for the single features. In this paper we propose an automated approach that helps developers filter, aggregate, and analyze user reviews. We use natural language processing techniques to identify fine-grained app features in the reviews. We then extract the user sentiments about the identified features and give them a general score across all reviews. Finally, we use topic modeling techniques to group fine-grained features into more meaningful high-level features. We evaluated our approach with 7 apps from the Apple App Store and Google Play Store and compared its results with a manually, peer-conducted analysis of the reviews. On average, our approach has a precision of 0.59 and a recall of 0.51. The extracted features were coherent and relevant to requirements evolution tasks. Our approach can help app developers to systematically analyze user opinions about single features and filter irrelevant reviews.

How can i improve my app? classifying user reviews for software maintenance and evolution
App Stores, such as Google Play or the Apple Store, allow users to provide feedback on apps by posting review comments and giving star ratings. These platforms constitute a useful electronic mean in which application developers and users can productively exchange information about apps. Previous research showed that users feedback contains usage scenarios, bug reports and feature requests, that can help app developers to accomplish software maintenance and evolution tasks. However, in the case of the most popular apps, the large amount of received feedback, its unstructured nature and varying quality can make the identification of useful user feedback a very challenging task. In this paper we present a taxonomy to classify app reviews into categories relevant to software maintenance and evolution, as well as an approach that merges three techniques: (1) Natural Language Processing, (2) Text Analysis and (3) Sentiment Analysis to automatically classify app reviews into the proposed categories. We show that the combined use of these techniques allows to achieve better results (a precision of 75% and a recall of 74%) than results obtained using each technique individually (precision of 70% and a recall of 67%).

Sentiment analysis of commit comments in GitHub: an empirical study
Emotions have a high impact in productivity, task quality, creativity, group rapport and job satisfaction. In this work we use lexical sentiment analysis to study emotions expressed in commit comments of different open source projects and analyze their relationship with different factors such as used programming language, time and day of the week in which the commit was made, team distribution and project approval. Our results show that projects developed in Java tend to have more negative commit comments, and that projects that have more distributed teams tend to have a higher positive polarity in their emotional content. Additionally, we found that commit comments written on Mondays tend to a more negative emotion. While our results need to be confirmed by a more representative sample they are an initial step into the study of emotions and related factors in open source projects.

The crowd in requirements engineering: The landscape and challenges
Crowd-based requirements engineering (CrowdRE) could significantly change RE. Performing RE activities such as elicitation with the crowd of stakeholders turns RE into a participatory effort, leads to more accurate requirements, and ultimately boosts software quality. Although any stakeholder in the crowd can contribute, CrowdRE emphasizes one stakeholder group whose role is often trivialized: users. CrowdRE empowers the management of requirements, such as their prioritization and segmentation, in a dynamic, evolved style through collecting and harnessing a continuous flow of user feedback and monitoring data on the usage context. To analyze the large amount of data obtained from the crowd, automated approaches are key. This article presents current research topics in CrowdRE; discusses the benefits, challenges, and lessons learned from projects and experiments; and assesses how to apply the methods and tools in industrial contexts. This article is part of a special issue on Crowdsourcing for Software Engineering.

Ensemble methods for app review classification: An approach for software evolution (n)
App marketplaces are distribution platforms for mobile applications that serve as a communication channel between users and developers. These platforms allow users to write reviews about downloaded apps. Recent studies found that such reviews include information that is useful for software evolution. However, the manual analysis of a large amount of user reviews is a tedious and time consuming task. In this work we propose a taxonomy for classifying app reviews into categories relevant for software evolution. Additionally, we describe an experiment that investigates the performance of individual machine learning algorithms and its ensembles for automatically classifying the app reviews. We evaluated the performance of the machine learning techniques on 4550 reviews that were systematically labeled using content analysis methods. Overall, the ensembles had a better performance than the individual classifiers, with an average precision of 0.74 and 0.59 recall.

Towards emotional awareness in software development teams
Emotions play an important role in determining work results and how team members collaborate within a project. When working in large, distributed teams, members can lose awareness of the emotional state of the project. We propose an approach to improve emotional awareness in software development teams by means of quantitative emotion summaries. Our approach automatically extracts and summarizes emotions expressed in collaboration artifacts by combining probabilistic topic modeling with lexical sentiment analysis techniques. We applied the approach to 1000 collaboration artifacts produced by three development teams in a three month period. Interviews with the teams' project leaders suggest that the proposed emotion summaries have a good correlation with the emotional state of the project, and could be useful for improving emotional awareness. However, the interviews also indicate that the current state of the summaries is not detailed enough and further improvements are needed.

A needle in a haystack: What do twitter users say about software?
Users of the Twitter microblogging platform share a vast amount of information about various topics through short messages on a daily basis. Some of these so called tweets include information that is relevant for software companies and could, for example, help requirements engineers to identify user needs. Therefore, tweets have the potential to aid in the continuous evolution of software applications. Despite the existence of such relevant tweets, little is known about their number and content. In this paper we report on the results of an exploratory study in which we analyzed the usage characteristics, content and automatic classification potential of tweets about software applications by using descriptive statistics, content analysis and machine learning techniques. Although the manual search of relevant information within the vast stream of tweets can be compared to looking for a needle in a haystack, our analysis shows that tweets provide a valuable input for software companies. Furthermore, our results demonstrate that machine learning techniques have the capacity to identify and harvest relevant information automatically.

A little bird told me: Mining tweets for requirements and software evolution
Twitter is one of the most popular social networks. Previous research found that users employ Twitter to communicate about software applications via short messages, commonly referred to as tweets, and that these tweets can be useful for requirements engineering and software evolution. However, due to their large number---in the range of thousands per day for popular applications---a manual analysis is unfeasible.In this work we present ALERTme, an approach to automatically classify, group and rank tweets about software applications. We apply machine learning techniques for automatically classifying tweets requesting improvements, topic modeling for grouping semantically related tweets and a weighted function for ranking tweets according to specific attributes, such as content category, sentiment and number of retweets. We ran our approach on 68,108 collected tweets from three software applications and compared its results against software practitioners' judgement. Our results show that ALERTme is an effective approach for filtering, summarizing and ranking tweets about software applications. ALERTme enables the exploitation of Twitter as a feedback channel for information relevant to software evolution, including end-user requirements.

Ardoc: App reviews development oriented classifier
Google Play, Apple App Store and Windows Phone Store are well known distribution platforms where users can download mobile apps, rate them and write review comments about the apps they are using. Previous research studies demonstrated that these reviews contain important information to help developers improve their apps. However, analyzing reviews is challenging due to the large amount of reviews posted every day, the unstructured nature of reviews and its varying quality. In this demo we present ARdoc, a tool which combines three techniques: (1) Natural Language Parsing, (2) Text Analysis and (3) Sentiment Analysis to automatically classify useful feedback contained in app reviews important for performing software maintenance and evolution tasks. Our quantitative and qualitative analysis (involving mobile professional developers) demonstrates that ARdoc correctly classifies feedback useful for maintenance perspectives in user reviews with high precision (ranging between 84% and 89%), recall (ranging between 84% and 89%), and F-Measure (ranging between 84% and 89%). While evaluating our tool developers of our study confirmed the usefulness of ARdoc in extracting important maintenance tasks for their mobile applications. Demo URL: https://youtu.be/Baf18V6sN8E Demo Web Page: http://www.ifi.uzh.ch/seal/people/panichella/tools/ARdoc.html

Rationale in development chat messages: an exploratory study
Chat messages of development teams play an increasinglysignificant role in software development, having replacedemails in some cases. Chat messages contain informationabout discussed issues, considered alternatives and argumentationleading to the decisions made during software development. These elements, defined as rationale, are invaluable duringsoftware evolution for documenting and reusing developmentknowledge. Rationale is also essential for coping with changesand for effective maintenance of the software system. However, exploiting the rationale hidden in the chat messages is challengingdue to the high volume of unstructured messages covering a widerange of topics. This work presents the results of an exploratorystudy examining the frequency of rationale in chat messages, the completeness of the available rationale and the potential ofautomatic techniques for rationale extraction. For this purpose, we apply content analysis and machine learning techniques onmore than 8,700 chat messages from three software developmentprojects. Our results show that chat messages are a rich source ofrationale and that machine learning is a promising technique fordetecting rationale and identifying different rationale elements.

An exploratory study of twitter messages about software applications
How do developers discuss rationale?
Developers make various decisions during software development. The rationale behind these decisions is of great importance during software evolution of long living software systems. However, current practices for documenting rationale often fall short and rationale remains hidden in the heads of developers or embedded in development artifacts. Further challenges are faced for capturing rationale in OSS projects; in which developers are geographically distributed and rely mostly on written communication channels to support and coordinate their activities. In this paper, we present an empirical study to understand how OSS developers discuss rationale in IRC channels and explore the possibility of automatic extraction of rationale elements by analyzing IRC messages of development teams. To achieve this, we manually analyzed 7,500 messages of three large OSS projects and identified all fine-grained elements of rationale. We evaluated various machine learning algorithms for automatically detecting and classifying rationale in IRC messages. Our results show that 1) rationale is discussed on average in 25% of IRC messages, 2) code committers contributed on average 54% of the discussed rationale, and 3) machine learning algorithms can detect rationale with 0.76 precision and 0.79 recall, and classify messages into finer-grained rationale elements with an average of 0.45 precision and 0.43 recall.

Which feature is unusable? Detecting usability and user experience issues from user reviews
Usability and user experience (UUX) strongly affect software quality and success. User reviews allow software users to report UUX issues. However, this information can be difficult to access due to the varying quality of the reviews, its large numbers and unstructured nature. In this work we propose an approach to automatically detect the UUX strengths and issues of software features according to user reviews. We use a collocation algorithm for extracting the features, lexical sentiment analysis for uncovering users' satisfaction about a particular feature and machine learning for detecting the specific UUX issues affecting the software application. Additionally, we present two visualizations of the results. An initial evaluation of the approach against human judgement obtained mixed results.

Retrieving diverse opinions from app reviews
Context: Users can have conflicting opinions and different experiences when using software and user reviews serve as a channel in which users can document their opinions and experiences. To develop and evolve software that is usable and relevant for a diverse group of users, different opinions and experiences need to be taken into account. Goal: In this paper we present DIVERSE, a feature and sentiment centric retrieval approach which automatically provides developers with a diverse sample of user reviews that is representative of the different opinions and experiences mentioned in the whole set of reviews. Results: We evaluated the diversity retrieval performance of our approach on reviews from seven apps from two different app stores. We compared the reviews retrieved by DIVERSE with a feature-based retrieval approach and found that on average DIVERSE outperforms the baseline approach. Additionally, a controlled experiment revealed that DIVERSE can help develop- ers save time when analyzing user reviews and was considered useful for detecting conflicting opinions and software evolution. Conclusions: DIVERSE can therefore help developers collect a comprehensive set of reviews and aid in the detection of conflicting opinions.

Automated requirements extraction for scientific software
User feedback in the app store: a cross-cultural study
App stores allow globally distributed users to submit user feedback, in the form of user reviews, about the apps they download. Previous research has found that many of these reviews contain valuable information for software evolution, such as bug reports or feature requests, and has designed approaches for automatically extracting this information. However, the diversity of the feedback submitted by users from diverse cultural backgrounds and the consequences this diversity might imply have not been studied so far. In this paper, we report on a cross-cultural study where we investigated cultural differences in app store reviews and identified correlations to cultural dimensions taken from a well-established cultural model. We analyzed 2,560 app reviews written by users from eight countries with diverse national culture. We contribute evidence about the influence of cultural factors on characteristics of app reviews. Our results also help developers of automated feedback analysis tools to avoid cultural bias when choosing their algorithms and the data for training and validating them.

React: An approach for capturing rationale in chat messages
Developers' chat messages are a rich source of rationale behind development decisions. Rationale comprises valuable knowledge during software evolution for understanding and maintaining the software system. However, developers resist explicit methods for rationale capturing in practice, due to their intrusiveness and cognitive overhead. Aim: Our primary goal is to help developers capture rationale in chat messages with low effort. Further, we seek to encourage the collaborative capturing of rationale in development teams. Method: In this paper, we present REACT, a lightweight approach for annotating chat messages that contain rationale. To evaluate the feasibility of REACT, we conducted two studies. In the first study, we evaluated the approach with eleven development teams during a short-term design task. In the second study, we evaluated the approach with one development team over a duration of two months. In addition, we distributed a questionnaire to both studies' participants. Results: Our results show that REACT is easily learned and used by developers. Furthermore, it encourages the collaborative capturing of rationale. Remarkably, the majority of participants do not perceive privacy as a barrier when capturing rationale from their informal communication. Conclusions: REACT is a first step towards enhancing rationale capturing in developers' chat messages.

Visualizing emotions in software development projects
Developers and managers need to be aware of the emotional climate of the projects they are involved to take corrective actions when necessary and to have a better understanding of the social factors affecting the project. With the growing trend of distributed teams and textual communication this type of awareness is more difficult to obtain and maintain. We propose to improve emotional climate awareness in software development projects by means of a visualization prototype which includes general and detailed views of the topics and emotions expressed in software project collaboration artifacts. We performed an initial case study in which the mailing list content of a software project was visualized. The study suggests that the length, frequency and emotion diversity of the exchanged content varies according to the project phase. However, a more extensive evaluation needs to be made.

Fave: Visualizing user feedback for software evolution
App users can submit feedback about downloaded apps by writing review comments and giving star ratings directly in the distribution platforms. Previous research has shown that this type of feedback contains important information for software evolution. However, in the case of the most popular apps, the amount of received feedback and its unstructured nature can produce difficulties in its analysis. We present an interactive user feedback visualization which displays app reviews from four different points of view: general, review based, feature based and topic-feature based. We conducted a study which visualized 2009 reviews from the Dropbox app available in the App Store. Participants considered the approach useful for software evolution tasks as they found it could aid developers and analysts get an overview of the most and least popular app features, and to prioritize their work. While using different strategies to find relevant information during the study, most participants came to the same conclusions regarding the user reviews and assigned tasks.

Prioritizing user feedback from twitter: A survey report
Twitter messages (tweets) contain important information for software and requirements evolution, such as feature requests, bug reports and feature shortcoming descriptions. For this reason, Twitter is an important source for crowd-based requirements engineering and software evolution. However, a manual analysis of this information is unfeasible due to the large number of tweets, its unstructured nature and varying quality. Therefore, automatic analysis techniques are needed for, e.g., summarizing, classifying and prioritizing tweets. In this work we present a survey with 84 software engineering practitioners and researchers that studies the tweet attributes that are most telling of tweet priority when performing software evolution tasks. We believe that our results can be used to implement mechanisms for prioritizing user feedback with social components. Thus, it can be helpful for enhancing crowd-based requirements engineering and software evolution.

DONE