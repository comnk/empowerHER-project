Artificial intelligence based anomaly detection of energy consumption in buildings: A review, current trends and new perspectives
FPGA realization of FIR filters by efficient and flexible systolization using distributed arithmetic
In this paper, we present the design optimization of one- and two-dimensional fully pipelined computing structures for area-delay-power-efficient implementation of finite-impulse-response (FIR) filter by systolic decomposition of distributed arithmetic (DA)-based inner-product computation. The systolic decomposition scheme is found to offer a flexible choice of the address length of the lookup tables (LUT) for DA-based computation to decide on suitable area time tradeoff. It is observed that by using smaller address lengths for DA-based computing units, it is possible to reduce the memory size, but on the other hand that leads to increase of adder complexity and the latency. For efficient DA-based realization of FIR filters of different orders, the flexible linear systolic design is implemented on a Xilinx Virtex-E XCV2000E FPGA using a hybrid combination of Handel-C and parameterizable VHDL cores. Various key performance metrics such as number of slices, maximum usable frequency, dynamic power consumption, energy density, and energy throughput are estimated for different filter orders and address lengths. Analysis of the results obtained indicate that performance metrics of the proposed implementation is broadly in line with theoretical expectations. It is found that the choice of address length yields the best of area-delay-power-efficient realizations of the FIR filter for various filter orders. Moreover, the proposed FPGA implementation is found to involve significantly less area-delay complexity compared with the existing DA-based implementations of FIR filter.

Semantic content-based image retrieval: A comprehensive study
FPGA implementations of fast Fourier transforms for real-time signal and image processing
Applications based on Fast Fourier Transform (FFT) such as signal and image processing require high computational power, plus the ability to experiment with algorithms. Reconfigurable hardware devices in the form of Field Programmable Gate Arrays (FPGAs) have been proposed as a way of obtaining high performance at an economical price. At present, however, users must program FPGAs at a very low level and have a detailed knowledge of the architecture of the device being used. To try to reconcile the dual requirements of high performance and ease of development, this paper reports on the design and realisation of a High Level framework for the implementation of 1-D and 2-D FFTs for real-time applications. Results show that the parallel implementation of 2-D FFT achieves virtually linear speed-up and real-time performance for large matrix sizes. Finally, an FPGA-based parametrisable environment based on the developed parallel 2-D FFT architecture is presented as a solution for frequency-domain image filtering application.

AI-big data analytics for building automation and management systems: a survey, actual challenges and future perspectives
Content-based image retrieval with compact deep convolutional features
Fully automated segmentation of oncological PET volumes using a combined multiscale and statistical model
The widespread application of positron emission tomography (PET) in clinical oncology has driven this imaging technology into a number of new research and clinical arenas. Increasing numbers of patient scans have led to an urgent need for efficient data handling and the development of new image analysis techniques to aid clinicians in the diagnosis of disease and planning of treatment. Automatic quantitative assessment of metabolic PET data is attractive and will certainly revolutionize the practice of functional imaging since it can lower variability across institutions and may enhance the consistency of image interpretation independent of reader experience. In this paper, a novel automated system for the segmentation of oncological PET data aiming at providing an accurate quantitative analysis tool is proposed. The initial step involves expectation maximization (EM)-based mixture modeling using a k-means clustering procedure, which varies voxel order for initialization. A multiscale Markov model is then used to refine this segmentation by modeling spatial correlations between neighboring image voxels. An experimental study using an anthropomorphic thorax phantom was conducted for quantitative evaluation of the performance of the proposed segmentation algorithm. The comparison of actual tumor volumes to the volumes calculated using different segmentation methodologies including standard k-means, spatial domain Markov Random Field Model (MRFM), and the new multiscale MRFM proposed in this paper showed that the latter dramatically reduces the relative error to less than 8% for small lesions (7 mm radii) and less than 3.5% for larger lesions (9 mm radii). The analysis of the resulting segmentations of clinical oncologic PET data seems to confirm that this methodology shows promise and can successfully segment patient lesions. For problematic images, this technique enables the identification of tumors situated very close to nearby high normal physiologic uptake. The use of this technique to estimate tumor volumes for assessment of response to therapy and to delineate treatment volumes for the purpose of combined PET/CT-based radiation therapy treatment planning is also discussed.

A survey of recommender systems for energy efficiency in buildings: Principles, challenges and prospects
Multiple comparator classifier framework for accelerometer-based fall detection and diagnostic
FPGA implementation of orthogonal matching pursuit for compressive sensing reconstruction
In this paper, we present a novel architecture based on field-programmable gate arrays (FPGAs) for the reconstruction of compressively sensed signal using the orthogonal matching pursuit (OMP) algorithm. We have analyzed the computational complexities and data dependence between different stages of OMP algorithm to design its architecture that provides higher throughput with less area consumption. Since the solution of least square problem involves a large part of the overall computation time, we have suggested a parallel low-complexity architecture for the solution of the linear system. We have further modeled the proposed design using Simulink and carried out the implementation on FPGA using Xilinx system generator tool. We have presented here a methodology to optimize both area and execution time in Simulink environment. The execution time of the proposed design is reduced by maximizing parallelism by appropriate level of unfolding, while the FPGA resources are reduced by sharing the hardware for matrix-vector multiplication across the data-dependent sections of the algorithm. The hardware implementation on the Virtex6 FPGA provides significantly superior performance in terms of resource utilization measured in the number of occupied slices, and maximum usable frequency compared with the existing implementations. Compared with the existing similar design, the proposed structure involves 328 more DSP48s, but it involves 25802 less slices and 1.85 times less computation time for signal reconstruction with N = 1024, K = 256, and m = 36, where N is the number of samples, K is the size of the measurement vector, and m is the sparsity. It also provides a higher peak signal-to-noise ratio value of 38.9 dB with a reconstruction time of 0.34 μs, which is twice faster than the existing design. In addition, we have presented a performance metric to implement the OMP algorithm in resource constrained FPGA for the better quality of signal reconstruction.

MLP neural network based gas classification system on Zynq SoC
Systems based on wireless gas sensor networks offer a powerful tool to observe and analyze data in complex environments over long monitoring periods. Since the reliability of sensors is very important in those systems, gas classification is a critical process within the gas safety precautions. A gas classification system has to react fast in order to take essential actions in the case of fault detection. This paper proposes a low latency real-time gas classification service system, which uses a multi-layer perceptron (MLP) artificial neural network to detect and classify the gas sensor data. An accurate MLP is developed to work with the data set obtained from an array of tin oxide (SnO2) gas sensor, based on convex micro hotplates. The overall system acquires the gas sensor data through radio-frequency identification (RFID), and processes the sensor data with the proposed MLP classifier implemented on a system on chip (SoC) platform from Xilinx. Hardware implementation of the classifier is optimized to achieve very low latency for real-time application. The proposed architecture has been implemented on a ZYNQ SoC using fixed-point format and the achieved results have shown that an accuracy of 97.4% has been obtained.

A novel approach for detecting anomalous energy consumption based on micro-moments and deep neural networks
Fall detection and human activity classification using wearable sensors and compressed sensing
Robust event-based non-intrusive appliance recognition using multi-scale wavelet packet tree and ensemble bagging tree
The emergence of explainability of intelligent systems: Delivering explainable and personalized recommendations for energy efficiency
The recent advances in artificial intelligence namely in machine learning and deep learning, have boosted the performance of intelligent systems in several ways. This gave rise to human expectations, but also created the need for a deeper understanding of how intelligent systems think and decide. The concept of explainability appeared, in the extent of explaining the internal system mechanics in human terms. Recommendation systems are intelligent systems that support human decision making, and as such, they have to be explainable to increase user trust and improve the acceptance of recommendations. In this study, we focus on a context‐aware recommendation system for energy efficiency and develop a mechanism for explainable and persuasive recommendations, which are personalized to user preferences and habits. The persuasive facts either emphasize on the economical saving prospects (Econ) or on a positive ecological impact (Eco) and explanations provide the reason for recommending an energy saving action. Based on a study conducted using a Telegram bot, different scenarios have been validated with actual data and human feedback. Current results show a total increase of 19% on the recommendation acceptance ratio when both economical and ecological persuasive facts are employed. This revolutionary approach on recommendation systems, demonstrates how intelligent recommendations can effectively encourage energy saving behavior.

Building power consumption datasets: Survey, taxonomy and future directions
Smart power consumption abnormality detection in buildings using micromoments and improved K‐nearest neighbors
Anomaly detection in energy consumption is a crucial step towards developing efficient energy saving systems, diminishing overall energy expenditure and reducing carbon emissions. Therefore, implementing powerful techniques to identify anomalous consumption in buildings and providing this information to end‐users and managers is of significant importance. Accordingly, two novel schemes are proposed in this paper; the first one is an unsupervised abnormality detection based on one‐class support vector machine, namely UAD‐OCSVM, in which abnormalities are extracted without the need of annotated data; the second is a supervised abnormality detection based on micromoments (SAD‐M2), which is implemented in the following steps: (i) normal and abnormal power consumptions are defined and assigned; (ii) a rule‐based algorithm is introduced to extract the micromoments representing the intent‐rich moments, in which the end‐users make decisions to consume energy; and (iii) an improved K‐nearest neighbors model is introduced to automatically classify consumption footprints as normal or abnormal. Empirical evaluation conducted in this framework under three different data sets demonstrates that SAD‐M2 achieves both a highest abnormality detection performance and real‐time processing capability with considerably lower computational cost in comparison with other machine learning methods. For instance, up to 99.71% accuracy and 99.77% F1 score have been achieved using a real‐world data set collected at the Qatar University energy lab.

Using artificial intelligence and data fusion for environmental monitoring: A review and future perspectives
A multispectral computer vision system for automatic grading of prostatic neoplasia
This paper introduces the application of multispectral imaging in quantitative pathology. The automated system aims to classify microscopic samples taken by needle biopsy for the purpose of prostate cancer diagnosis. The main contribution here is that instead of analysing conventional grey scale or RGB colour images, sixteen spectral bands have been used in the analysis. Four major classes have to be discriminated. To achieve that, the same feature vector, based on texture and structural measurements, was derived for each colour band. Principal component analysis has been used to reduce the dimensionality of the combination feature vector to a manageable size. Tests has been carried out using supervised Classical Linear Discrimination method and have shown that the use of multispectral information can significantly improve the classification performance when compared with the case where this information is not taken into consideration.

Blockchain-based recommender systems: Applications, challenges and future opportunities
DONE