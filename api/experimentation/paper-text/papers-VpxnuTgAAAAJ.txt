Thalamic regulation of switching between cortical representations enables cognitive flexibility
Predicting non-linear dynamics by stable local learning in a recurrent spiking neural network
The brain needs to predict how the body reacts to motor commands, but how a network of spiking neurons can learn non-linear body dynamics using local, online and stable learning rules is unclear. Here, we present a supervised learning scheme for the feedforward and recurrent connections in a network of heterogeneous spiking neurons. The error in the output is fed back through fixed random connections with a negative gain, causing the network to follow the desired dynamics. The rule for Feedback-based Online Local Learning Of Weights (FOLLOW) is local in the sense that weight changes depend on the presynaptic activity and the error signal projected onto the postsynaptic neuron. We provide examples of learning linear, non-linear and chaotic dynamics, as well as the dynamics of a two-link arm. Under reasonable approximations, we show, using the Lyapunov method, that FOLLOW learning is uniformly stable, with the error going to zero asymptotically.

Dynamical learning of dynamics
The ability of humans and animals to quickly adapt to novel tasks is difficult to reconcile with the standard paradigm of learning by slow synaptic weight modification. Here, we show that fixed-weight neural networks can learn to generate required dynamics by imitation. After appropriate weight pretraining, the networks quickly and dynamically adapt to learn new tasks and thereafter continue to achieve them without further teacher feedback. We explain this ability and illustrate it with a variety of target dynamics, ranging from oscillatory trajectories to driven and chaotic dynamical systems.

Bulbar microcircuit model predicts connectivity and roles of interneurons in odor coding
Stimulus encoding by primary sensory brain areas provides a data-rich context for understanding their circuit mechanisms. The vertebrate olfactory bulb is an input area having unusual two-layer dendro-dendritic connections whose roles in odor coding are unclear. To clarify these roles, we built a detailed compartmental model of the rat olfactory bulb that synthesizes a much wider range of experimental observations on bulbar physiology and response dynamics than has hitherto been modeled. We predict that superficial-layer inhibitory interneurons (periglomerular cells) linearize the input-output transformation of the principal neurons (mitral cells), unlike previous models of contrast enhancement. The linearization is required to replicate observed linear summation of mitral odor responses. Further, in our model, action-potentials back-propagate along lateral dendrites of mitral cells and activate deep-layer inhibitory interneurons (granule cells). Using this, we propose sparse, long-range inhibition between mitral cells, mediated by granule cells, to explain how the respiratory phases of odor responses of sister mitral cells can be sometimes decorrelated as observed, despite receiving similar receptor input. We also rule out some alternative mechanisms. In our mechanism, we predict that a few distant mitral cells receiving input from different receptors, inhibit sister mitral cells differentially, by activating disjoint subsets of granule cells. This differential inhibition is strong enough to decorrelate their firing rate phases, and not merely modulate their spike timing. Thus our well-constrained model suggests novel computational roles for the two most numerous classes of interneurons in the bulb.

Neurobench: Advancing neuromorphic computing through collaborative, fair and representative benchmarking
hindering effective evaluation of the advantages and strengths of neuromorphic methods compared to traditional deep-learning-based methods. This paper presents a collaborative effort, bringing together members from academia and the industry, to deﬁne benchmarks for neuromorphic computing: NeuroBench . The goals of NeuroBench are to be a collaborative, fair, and representative benchmark suite developed by the community, for the community. In this paper, we discuss the challenges associated with benchmarking neuromorphic solutions, and outline the key features of NeuroBench . We believe that NeuroBench will be a signiﬁcant step towards deﬁning standards that can unify the goals of neuromorphic computing and drive its technological progress. Please visit neurobench . ai for the latest updates on the benchmark tasks and metrics.

Non-linear motor control by local learning in spiking neural networks
Learning weights in a spiking neural network with hidden neurons, using local, stable and online rules, to control non-linear body dynamics is an open problem. Here, we employ a supervised scheme, Feedback-based Online Local Learning Of Weights (FOLLOW), to train a network of heterogeneous spiking neurons with hidden layers, to control a two-link arm so as to reproduce a desired state trajectory. The network first learns an inverse model of the non-linear dynamics, i.e. from state trajectory as input to the network, it learns to infer the continuous-time command that produced the trajectory. Connection weights are adjusted via a local plasticity rule that involves pre-synaptic firing and post-synaptic feedback of the error in the inferred command. We choose a network architecture, termed differential feedforward, that gives the lowest test error from different feedforward and recurrent architectures. The learned inverse model is then used to generate a continuous-time motor command to control the arm, given a desired trajectory.

Reservoir computing for temporal data classification using a dynamic solid electrolyte ZnO thin film transistor
The processing of sequential and temporal data is essential to computer vision and speech recognition, two of the most common applications of artificial intelligence (AI). Reservoir computing (RC) is a branch of AI that offers a highly efficient framework for processing temporal inputs at a low training cost compared to conventional Recurrent Neural Networks (RNNs). However, despite extensive effort, two-terminal memristor-based reservoirs have, until now, been implemented to process sequential data by reading their conductance states only once, at the end of the entire sequence. This method reduces the dimensionality, related to the number of signals from the reservoir and thereby lowers the overall performance of reservoir systems. Higher dimensionality facilitates the separation of originally inseparable inputs by reading out from a larger set of spatiotemporal features of inputs. Moreover, memristor-based reservoirs either use multiple pulse rates, fast or slow read (immediately or with a delay introduced after the end of the sequence), or excitatory pulses to enhance the dimensionality of reservoir states. This adds to the complexity of the reservoir system and reduces power efficiency. In this paper, we demonstrate the first reservoir computing system based on a dynamic three terminal solid electrolyte ZnO/Ta2O5 Thin-film Transistor fabricated at less than 100°C. The inherent nonlinearity and dynamic memory of the device lead to a rich separation property of reservoir states that results in, to our knowledge, the highest accuracy of 94.44%, using electronic charge-based system, for the classification of hand-written digits. This improvement is attributed to an increase in the dimensionality of the reservoir by reading the reservoir states after each pulse rather than at the end of the sequence. The third terminal enables a read operation in the off state, that is when no pulse is applied at the gate terminal, via a small read pulse at the drain. This fundamentally allows multiple read operations without increasing energy consumption, which is not possible in the conventional two-terminal memristor counterpart. Further, we have also shown that devices do not saturate even after multiple write pulses which demonstrates the device’s ability to process longer sequences.

Multi-Timescale memory dynamics extend task repertoire in a reinforcement learning network with Attention-Gated memory
The interplay of reinforcement learning and memory is at the core of several recent neural network models, such as the Attention-Gated MEmory Tagging (AuGMEnT) model. While successful at various animal learning tasks, we find that the AuGMEnT network is unable to cope with some hierarchical tasks, where higher-level stimuli have to be maintained over a long time, while lower-level stimuli need to be remembered and forgotten over a shorter timescale. To overcome this limitation, we introduce a hybrid AuGMEnT, with leaky (or short-timescale) and non-leaky (or long-timescale) memory units, that allows the exchange of low-level information while maintaining high-level one. We test the performance of the hybrid AuGMEnT network on two cognitive reference tasks, sequence prediction and 12AX.

Multiscale models in MOOSE: interoperability and standardization
New tests and clarification of some conceptual issues in the superposition of monochromatic light fields [6664-19]
The linear mathematics of Fourier composition and decomposition of monochromatic electromagnetic fields is supposed to have a direct realization in the physical world in the sense that we assume complete equivalence of reality as well as of physical effects when an arbitrary electromagnetic field is substituted physically with its Fourier components, and vice versa, in the same spatial region. In the simplest cases, two superposed light fields at frequencies &ohgr;1 and &ohgr;2 are supposed to be identical in their physical effects to a single field at the average frequency, amplitude modulated at half the difference frequency, in spite of the significant differences in the experimental arrangements needed to produce the two cases. This equivalence has been questioned and recently Lee and Roychoudhury1 cited experimental results on atomic resonance and Fabry-Perot filters to assert that there is no such equivalence. Considering the importance of such assertions for the foundations of physics in general, we have conducted a detailed analysis of the issue, and have conducted tests in which amplitude modulated field at resonant frequency, corresponding mathematically to a superposition of two monochromatic fields detuned equally away from the resonance, is applied to Rb atomic vapor, and also passed through a Fabry-Perot cavity. We conclude from the results of these experiments that there is complete physical equivalence, corresponding to the mathematical equivalence. We clarify several conceptual issues that have been raised about the superposition of light in this context.

Modelling novelty detection in the thalamocortical loop
In complex natural environments, sensory systems are constantly exposed to a large stream of inputs. Novel or rare stimuli, which are often associated with behaviorally important events, are typically processed differently than the steady sensory background, which has less relevance. Neural signatures of such differential processing, commonly referred to as novelty detection, have been identified on the level of EEG recordings as mismatch negativity and the level of single neurons as stimulus-specific adaptation. Here, we propose a multi-scale recurrent network with synaptic depression to explain how novelty detection can arise in the whisker-related part of the somatosensory thalamocortical loop. The architecture and dynamics of the model presume that neurons in cortical layer 6 adapt, via synaptic depression, specifically to a frequently presented stimulus, resulting in reduced population activity in the corresponding cortical column when compared with the population activity evoked by a rare stimulus. This difference in population activity is then projected from the cortex to the thalamus and amplified through the interaction between neurons of the primary and reticular nuclei of the thalamus, resulting in spindle-like, rhythmic oscillations. These differentially activated thalamic oscillations are forwarded to cortical layer 4 as a late secondary response that is specific to rare stimuli that violate a particular stimulus pattern. Model results show a strong analogy between this late single neuron activity and EEG-based mismatch negativity in terms of their common sensitivity to presentation context and timescales of response latency, as observed experimentally. Our results indicate that adaptation in L6 can establish the thalamocortical dynamics that produce signatures of SSA and MMN and suggest a mechanistic model of novelty detection that could generalize to other sensory modalities. Author summary Cortical sensory neurons have been shown to be capable of novelty detection, that is they respond more vigorously when a novel, unexpected stimulus is presented, and less so when the stimulus is part of a predictable sequence. However, the neural mechanism underlying this capability is not yet fully understood. Here, we developed a thalamocortical network model that accounts for novelty detection and reproduces physiologically observed neural response patterns in the somatosensory cortex. Specifically, our results demonstrate that the novelty signal arises from the complex recurrent interplay between thalamic neurons and cortical neurons in layers 4 and 6. This work therefore provides a concrete mechanism that can serve as a starting point for further investigating the neural circuit mechanisms underlying novelty detection.

Prediction error signals in anterior cingulate cortex drive task-switching
Task-switching is a fundamental cognitive ability that allows animals to update their knowledge of current rules or contexts. Detecting discrepancies between predicted and observed events is essential for this process. However, little is known about how the brain computes cognitive prediction-errors and whether neural prediction-error signals are causally related to task-switching behaviours. Here we trained mice to use a prediction-error to switch, in a single trial, between responding to the same stimuli using two distinct rules. Optogenetic silencing and un-silencing, together with widefield and two-photon calcium imaging revealed that the anterior cingulate cortex (ACC) was specifically required for this rapid task-switching, but only when it exhibited neural prediction-error signals. These prediction-error signals were projection-target dependent and were larger preceding successful behavioural transitions. An all-optical approach revealed a disinhibitory interneuron circuit required for successful prediction-error computation. These results reveal a circuit mechanism for computing prediction-errors and transitioning between distinct cognitive states.

Measuring Exploration in Reinforcement Learning via Optimal Transport in Policy Space
Exploration is the key ingredient of reinforcement learning (RL) that determines the speed and success of learning. Here, we quantify and compare the amount of exploration and learning accomplished by a Reinforcement Learning (RL) algorithm. Specifically, we propose a novel measure, named Exploration Index, that quantifies the relative effort of knowledge transfer (transferability) by an RL algorithm in comparison to supervised learning (SL) that transforms the initial data distribution of RL to the corresponding final data distribution. The comparison is established by formulating learning in RL as a sequence of SL tasks, and using optimal transport based metrics to compare the total path traversed by the RL and SL algorithms in the data distribution space. We perform extensive empirical analysis on various environments and with multiple algorithms to demonstrate that the exploration index yields insights about the exploration behaviour of any RL algorithm, and also allows us to compare the exploratory behaviours of different RL algorithms.

Reservoir Computing based on a Solid Electrolyte ZnO TFT: An attractive platform for flexible edge computing
Implementation of accurate neural network models in edge applications such as wearables is limited by the hardware platform due to constraints of power/area. We highlight novel concepts in reservoir computing that rely on a volatile three terminal solid electrolyte thin film synaptic transistor, whose conductance can be controlled by the gate and drain voltages to enhance the richness of the reservoir and operate in the off-state. The proposed approach achieves an accuracy of 94% in image processing, significantly higher than equivalent applications of reservoir computing based on two-terminal memristors, primarily because we avoid down-sampling by training the readout after every pulse.

A delay system reservoir based on a nano-ionic Solid Electrolyte FET*
BunDLe-Net: Neuronal Manifold Learning Meets Behaviour
Neuronal manifold learning techniques represent high-dimensional neuronal dynamics in low-dimensional embeddings to reveal the intrinsic structure of neuronal manifolds. A common goal of these techniques is to learn embeddings that allow a good reconstruction of the original data. We introduce a novel neuronal manifold learning technique, BunDLe-Net, that learns a low-dimensional Markovian embedding of the neuronal dynamics which pre-serves only those aspects of the neuronal dynamics that are relevant for a given behavioural context. In this way, BunDLe-Net eliminates neuronal dynamics that are irrelevant for decoding behaviour, effectively de-noising the data to reveal better the intricate relationships between neuronal dynamics and behaviour. We show that BunDLe-Net learns highly consistent manifolds across animals that reveal the building blocks of their neuronal manifolds on a variety of data sets, ranging from calcium imaging data recorded in the nematode C. elegans to spiking data from the rat hippocampus and primate somatosensory cortex.

NeuroBench: A Framework for Benchmarking Neuromorphic Computing Algorithms and Systems
Neuromorphic computing shows promise for advancing computing efficiency and capabilities of AI applications using brain-inspired principles. However, the neuromorphic research field currently lacks standardized benchmarks, making it difficult to accurately measure technological advancements, compare performance with conventional methods, and identify promising future research directions. Prior neuromorphic computing benchmark efforts have not seen widespread adoption due to a lack of inclusive, actionable, and iterative benchmark design and guidelines. To address these shortcomings, we present NeuroBench: a benchmark framework for neuromorphic computing algorithms and systems. NeuroBench is a collaboratively-designed effort from an open community of nearly 100 co-authors across over 50 institutions in industry and academia, aiming to provide a representative structure for standardizing the evaluation of neuromorphic approaches. The NeuroBench framework introduces a common set of tools and systematic methodology for inclusive benchmark measurement, delivering an objective reference framework for quantifying neuromorphic approaches in both hardware-independent (algorithm track) and hardware-dependent (system track) settings. In this article, we present initial performance baselines across various model architectures on the algorithm track and outline the system track benchmark tasks and guidelines. NeuroBench is intended to continually expand its benchmarks and features to foster and track the progress made by the research community.

Biophysical model of odor representation and processing in the rat olfactory bulb
Is there a dynamical cause of the spin-statistics connection?
Extant proofs of the spin-statistics connection (SSC) are kinematical. C S Unnikrishnan has suggested that a dynamical interaction leading to the SSC would involve spin and perforce gravity, the only known universal force. For the scattering of two identical particles, he considers [1] the interaction of their spins with the gravito-magnetic field generated by their scattering motion through cosmic matter-energy. There the direct and particles-exchanged scattering amplitudes accumulate different quantum phases which provide the relevant bosonic/fermionic sign between them without applying the ad hoc SSC rule. Here it is shown that the scattering probabilities given by the standard implementation of SSC in quantum mechanics are actually not obtained from the above interaction for most initial spin states of the scattering particles. Instead, an unrealized peculiar dynamical interaction is required. Further, a spin-gravito-magnetic interaction as above (with caveats) would result in a large unmeasured spin-orbit coupling type effect on atomic energy levels. A comparison with a typical rotation based proof is also provided.

Quantum phases due to cosmic gravity and the spin-statistics connection
Recently, it was proposed that the spin-statistics connection arises due to a quantum dynamical phase involving cosmic gravity (Unnikrishnan C S, gr-qc/0406043). There it was assumed that the gravitational quantum phase accumulated on the wavefunctions of each of two identical particles undergoing scattering in the presence of cosmic matter with the direction of their momentum changing by some angle is equivalent to the particles forward scattering with the entire universe rotating oppositely by the same angle. However, if one considers the gravitational phase accumulated by an electron in orbit to be analogous to that acquired by a scattering particle, the accumulated phase inferred from the fine-structure splitting in an atom is too small to explain the spin statistics connection. Though, the desirability of a dynamical proof of the spin-statistics connection remains.

DONE