A survey of clustering algorithms for big data: Taxonomy and empirical analysis
Clustering algorithms have emerged as an alternative powerful meta-learning tool to accurately analyze the massive volume of data generated by modern applications. In particular, their main goal is to categorize data into clusters such that objects are grouped in the same cluster when they are similar according to specific metrics. There is a vast body of knowledge in the area of clustering and there has been attempts to analyze and categorize them for a larger number of applications. However, one of the major issues in using clustering algorithms for big data that causes confusion amongst practitioners is the lack of consensus in the definition of their properties as well as a lack of formal categorization. With the intention of alleviating these problems, this paper introduces concepts and algorithms related to clustering, a concise survey of existing (clustering) algorithms as well as providing a comparison, both from a theoretical and an empirical perspective. From a theoretical perspective, we developed a categorizing framework based on the main properties pointed out in previous studies. Empirically, we conducted extensive experiments where we compared the most representative algorithm from each of the categories using a large number of real (big) data sets. The effectiveness of the candidate clustering algorithms is measured through a number of internal and external validity metrics, stability, runtime, and scalability tests. In addition, we highlighted the set of clustering algorithms that are the best performing for big data.

Product lifecycle management–from its history to its new role
This paper is a result of comprehensive consultation among the authors, with the scientists and leading actors in the area of PLM, which is a reference term for a list of phenomena currently ongoing in the industrial community. This paper discusses the pervasive concept of product lifecycle management (PLM), starting from its history to its constituent elements and its role in the current industry. The authors propose and elaborate their vision for the future steps of the PLM in terms of emerging issues and topics that industrial practitioners and researchers need to address.

A context-aware approach for long-term behavioural change detection and abnormality prediction in ambient assisted living
Information sharing and exchange in the context of product lifecycle management: Role of standards
Morphological analysis for product design
Supply chain management: a framework to characterize the collaborative strategies
The current intense competition forces enterprises to pay attention to supply chain collaboration with their upstream and downstream partners. Different collaborative strategies such as quick response (QR), efficient consumer response (ECR), vendor managed inventory (VMI) or collaborative planning, forecasting and replenishment (CPFR) have already been proposed. The key to ensuring that the supply chain partners are progressing on the right track of creating the best-in-class practice lays in their ability to choose the appropriate strategy. The current paper proposes a framework, based on analysis grids and graphical representations, which help to better characterize these strategies. The analysis grids use several characterization criteria to express the collaboration nature and its extent. For a better understanding, this framework is then applied to the CPFR strategy.

ISO 10303, the STEP standard for product data exchange, and its PLM capabilities
The international standard ISO 10303 (STEP) has been under development since 1984 and in use since 1994. It provides for the standardised exchange of product data. Initial parts of the standard were oriented towards data for specific life-cycle activities such as design and manufacturing, but a major expansion of scope has recently been achieved with the release for publication of ISO 10303-239, a STEP application protocol entitled "Product Life Cycle Support" (PLCS), which covers the entire history of a product from conceptual design to disposal. The first part of the paper gives an overview of the entire STEP standard as it currently exists, and the second part provides a more detailed description of the capabilities of the new PLCS component of STEP.

Open IoT ecosystem for sporting event management
By connecting devices, people, vehicles, and infrastructures everywhere in a city, governments and their partners can improve community well-being and other economic and financial aspects (e.g., cost and energy savings). Nonetheless, smart cities are complex ecosystems that comprise many different stakeholders (network operators, managed service providers, logistic centers, and so on), who must work together to provide the best services and unlock the commercial potential of the so-called Internet of Things (IoT). This is one of the major challenges that faces today’s smart city movement, and the emerging “API economy.” Indeed, while new smart connected objects hit the market every day, they mostly feed “vertical silos” (e.g., vertical apps, siloed apps, and so on) that are closed to the rest of the IoT, thus hampering developers to produce new added value across multiple platforms and/or application domains. Within this context, the contribution of this paper is twofold: 1) present the strategic vision and ambition of the EU to overcome this critical vertical silos’ issue and 2) introduce the first building blocks underlying an open IoT ecosystem developed as part of an EU (Horizon 2020) Project and a joint project initiative (IoT-EPI). The practicability of this ecosystem, along with a performance analysis, is carried out considering a proof-of-concept for enhanced sporting event management in the context of the forthcoming FIFA World Cup 2022 in Qatar.

The airport gate assignment problem: a survey
The airport gate assignment problem (AGAP) is one of the most important problems operations managers face daily. Many researches have been done to solve this problem and tackle its complexity. The objective of the task is assigning each flight (aircraft) to an available gate while maximizing both conveniences to passengers and the operational efficiency of airport. This objective requires a solution that provides the ability to change and update the gate assignment data on a real time basis. In this paper, we survey the state of the art of these problems and the various methods to obtain the solution. Our survey covers both theoretical and real AGAP with the description of mathematical formulations and resolution methods such as exact algorithms, heuristic algorithms, and metaheuristic algorithms. We also provide a research trend that can inspire researchers about new problems in this area.

Collaboration and integration through information technologies in supply chains
Supply chain management encompasses various processes including various conventional logistics activities, and various other processes These processes are supported – to a certain limit – by coordination and integration mechanisms which are long-term strategies that give competitive advantage through overall supply chain efficiency. Information technology, by the way of collecting, sharing and gathering data, exchanging information, optimising process through package software, is becoming one of the key developments and success of these collaboration strategies. This paper proposes a study to identify the methods used for collaborative works in the supply chain and focuses on some of its areas, as between a company and its suppliers (i.e., inventory sharing) and its customers (i.e., customer demand, forecasting), and also the integration of product information in the value chain.

Blockchain-of-blockchains: An interoperable blockchain platform for ensuring IoT data integrity in smart city
Multi-criteria decision making based on trust and reputation in supply chain
A novel architecture for tamper proof electronic health record management system using blockchain wrapper
In this paper, we present a novel architecture of blockchain-based tamper-proof electronic health record (EHR) management system. Recording electronic health data in cloud-based storage systems always pose a threat to information security. Intruders can delete or tamper EHR of patients, giving benefits to insurance companies or hiding medical malpractices (e.g. misdiagnosis and delayed diagnosis). A tamper-proof EHR management system is required that would essentially solve such issues. The blockchain is an emerging technology that can be adapted to develop a tamper-proof data management system. However, establishing a new blockchain based system replacing the existing system is expensive. In our proposed architecture, we introduce a wrapper layer integration mechanism, named as the blockchain handshaker, between the existing cloud-based EHR management system and public blockchain network to develop a tamper-proof health record management system. We implement a prototype to provide evidence on the feasibility of the proposed concept.

Sustainability performance measurement framework for supply chain management
Sustainability of supply chains has been recognised as a competitive indicator for business. The most widely used framework for implementing sustainability practices is the triple bottom line (TBL). However, the TBL is a holistic view for measuring sustainability performance. A good categorisation in each TBL dimension is one of the challenges in the sustainable supply chain management (sSCM) research field. Another challenge is dealing with a wide range of objectives, criteria and elements in the supply chain. A clear border of supply chain scope helps supply chains obtains a precise strategic direction and performance measurement system. This work fills these gaps by developing a conceptual framework, which transforms the TBL concept into three management levels of implementation by analysing the context of sustainable development and the engagement level of the supply chain. This framework can be applied to establish and construct sustainability metrics in supply chain management.

Susceptibility of twelve soft wheat varieties (Triticum aestivum) to Sitophilus granarius (L.)(Coleoptera: Curculionidae)
The aim of study is the effect of trophic medium of twelve soft wheat varieties on the biotic potential of S.granarius L. After 3 months of storage under laboratory conditions at 27 ± 2 ° C and 70 ± 5% rh, have reveals that the preferred varieties for development of this species are Hidhab, Mahon Demias, Arfort and Siete Ceros. This latest was found to be the most susceptible. Growth index and loss were highest with 2.08 and 3.27% respectively. Laboratory analysis of the main grain components of the different varieties suggested that the susceptibility of these varieties to S. granarius infestation may be attributed to the high content of protein and low content of carbohydrate compared to resistance varieties.

B2B relationship management: a framework to explore the impact of collaboration
This article aims to propose an integrated framework, based on two levels, able to characterise collaborative relation between two or more partners in a supply chain, evaluating their related performances. In the first level, related to the context point of view, the most common parameters, identified from a literature review, characterising a relationship between two partners, have been used to build an integrated analysis framework. The second level is related to the performance side and has been achieved through two main attributes: the perceived satisfaction of the relation and its perceived effectiveness. The implementation of the approach has been achieved through a survey of different companies, so as to propose a first analysis on how the characteristics of a relation impact its performance. A new dashboard is considered as an operative tool of the proposed approach, which allows to follow all the attributes which best characterise each relation type, as well as the sensitivity of the perceived performance for each attribute.

LSTM recurrent neural networks for cybersecurity named entity recognition
— The automated and timely conversion of cybersecurity information from unstructured online sources, such as blogs and articles to more formal representations has become a necessity for many applications in the domain nowadays. Named Entity Recognition (NER) is one of the early phases towards this goal. It involves the detection of the relevant domain entities, such as product, version, attack name, etc. in technical documents. Although generally considered a simple task in the information extraction field, it is quite challenging in some domains like cybersecurity because of the complex structure of its entities. The state of the art methods require time-consuming and labor intensive feature engineering that describes the properties of the entities, their context, domain knowledge, and linguistic characteristics. The model demonstrated in this paper is domain independent and does not rely on any features specific to the entities in the cybersecurity domain, hence does not require expert knowledge to perform feature engineering. The method used relies on a type of recurrent neural networks called Long Short-Term Memory (LSTM) and the Conditional Random Fields (CRFs) method. The results we obtained showed that this method outperforms the state of the art methods given an annotated corpus of a decent size.

Integration between MES and product lifecycle management
Today, within the global Product Lifecycle Management (PLM) approach, success of design, industrialization and production activities depends on the ability to improve interaction between information systems that handle such activities. Enterprises deploy mainly PLM system, Enterprise Resource Planning system (ERP) and Manufacturing Execution System (MES) in order to manage sufficient product-related information and provide better customer-products. This paper proposes a methodological approach to integrate product data generated during product design, industrialization and production. This involves the PLM and MES integration. Thus, the proposed approach aims to overcome the problem of data heterogeneity by proposing a mediation system resolving syntactic and semantic conflicts.

Information extraction of cybersecurity concepts: An LSTM approach
Extracting cybersecurity entities and the relationships between them from online textual resources such as articles, bulletins, and blogs and converting these resources into more structured and formal representations has important applications in cybersecurity research and is valuable for professional practitioners. Previous works to accomplish this task were mainly based on utilizing feature-based models. Feature-based models are time-consuming and need labor-intensive feature engineering to describe the properties of entities, domain knowledge, entity context, and linguistic characteristics. Therefore, to alleviate the need for feature engineering, we propose the usage of neural network models, specifically the long short-term memory (LSTM) models to accomplish the tasks of Named Entity Recognition (NER) and Relation Extraction (RE). We evaluated the proposed models on two tasks. The first task is performing NER and evaluating the results against the state-of-the-art Conditional Random Fields (CRFs) method. The second task is performing RE using three LSTM models and comparing their results to assess which model is more suitable for the domain of cybersecurity. The proposed models achieved competitive performance with less feature-engineering work. We demonstrate that exploiting neural network models in cybersecurity text mining is effective and practical.

Jointly identifying opinion mining elements and fuzzy measurement of opinion intensity to analyze product features
DONE