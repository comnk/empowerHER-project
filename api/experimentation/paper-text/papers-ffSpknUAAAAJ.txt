SpikeSegNet-a deep learning approach utilizing encoder-decoder network with hourglass for spike segmentation and counting in wheat plant from visual imaging
An efficient finger-knuckle-print based recognition system fusing sift and surf matching scores
Multiple texture information fusion for finger-knuckle-print authentication system
PVSNet: Palm vein authentication siamese network trained using triplet loss and adaptive hard mining by learning enforced domain specific features
Designing an end-to-end deep learning network to match the biometric features with limited training samples is an extremely challenging task. To address this problem, we propose a new way to design an end-to-end deep CNN framework i.e., PVSNet that works in two major steps: first, an encoder-decoder network is used to learn generative domain-specific features followed by a Siamese network in which convolutional layers are pre-trained in an unsupervised fashion as an autoencoder. The proposed model is trained via triplet loss function that is adjusted for learning feature embeddings in a way that minimizes the distance between embedding-pairs from the same subject and maximizes the distance with those from different subjects, with a margin. In particular, a triplet Siamese matching network using an adaptive margin based hard negative mining has been suggested. The hyper-parameters associated with the training strategy, like the adaptive margin, have been tuned to make the learning more effective on biometric datasets. In extensive experimentation, the proposed network outperforms most of the existing deep learning solutions on three type of typical vein datasets which clearly demonstrates the effectiveness of our proposed method.

Designing an accurate hand biometric based authentication system fusing finger knuckleprint and palmprint
Iris segmentation using improved hough transform
A comprehensive survey and deep learning-based approach for human recognition using ear biometric
VGR-net: A view invariant gait recognition network
Biometrie identification systems have become immensely popular and important because of their high reliability and efficiency. However person identification at a distance, still remains a challenging problem. Gait can be seen as an essential biometric feature for human recognition and identification. It can be easily acquired from a distance and does not require any user cooperation thus making it suitable for surveillance. But the task of recognizing an individual using gait can be adversely affected by varying view points making this task more and more challenging. Our proposed approach tackles this problem by identifying spatio-temporal features and performing extensive experimentation and training mechanism. In this paper, we propose a 3-D Convolution Deep Neural Network for person identification using gait under multiple view. It is a 2-stage network, in which we have a classification network that initially identifies the viewing point angle. After that another set of networks (one for each angle) has been trained to identify the person under a particular viewing angle. We have tested this network over CASIA-B publicly available database and have achieved state-of-the-art results. The proposed system is much more efficient in terms of time and space and performing better for almost all angles.

Deep metric learning for bioacoustic classification: Overcoming training data scarcity using dynamic triplet loss
Bioacoustic classification often suffers from the lack of labeled data. This hinders the effective utilization of state-of-the-art deep learning models in bioacoustics. To overcome this problem, the authors propose a deep metric learning-based framework that provides effective classification, even when only a small number of per-class training examples are available. The proposed framework utilizes a multiscale convolutional neural network and the proposed dynamic variant of the triplet loss to learn a transformation space where intra-class separation is minimized and inter-class separation is maximized by a dynamically increasing margin. The process of learning this transformation is known as deep metric learning. The triplet loss analyzes three examples (referred to as a triplet) at a time to perform deep metric learning. The number of possible triplets increases cubically with the dataset size, making triplet loss more suitable than the cross-entropy loss in data-scarce conditions. Experiments on three different publicly available datasets show that the proposed framework performs better than existing bioacoustic classification methods. Experimental results also demonstrate the superiority of dynamic triplet loss over cross-entropy loss in data-scarce conditions. Furthermore, unlike existing bioacoustic classification methods, the proposed framework has been extended to provide open-set classification.

PixISegNet: pixel‐level iris segmentation network using convolutional encoder–decoder with stacked hourglass bottleneck
In this paper, we present a new iris ROI segmentation algorithm using a deep convolutional neural network (NN) to achieve the state-of-the-art segmentation performance on well-known iris image data sets. The authors’ model surpasses the performance of state-of-the-art Iris DenseNet framework by applying several strategies, including multi-scale/ multi-orientation training, model training from scratch, and proper hyper-parameterisation of crucial parameters. The proposed PixISegNet consists of an autoencoder which primarily uses long and short skip connections and a stacked hourglass network between encoder and decoder. There is a continuous scale up–down in stacked hourglass networks, which helps in extracting features at multiple scales and robustly segments the iris even in an occluded environment. Furthermore, cross-entropy loss and content loss optimise the proposed model. The content loss considers the high-level features, thus operating at a different scale of abstraction, which compliments the cross-entropy loss, which considers pixel-to-pixel classification loss. Additionally, they have checked the robustness of the proposed network by rotating images to certain degrees with a change in the aspect ratio along with blurring and a change in contrast. Experimental results on the various iris characteristics demonstrate the superiority of the proposed method over state-of-the-art iris segmentation methods considered in this study. In order to demonstrate the network generalisation, they deploy a very stringent TOTA (i.e. train-once-test-all) strategy. Their proposed method achieves E 1 scores of 0.00672, 0.00916 and 0.00117 on UBIRIS-V2, IIT-D and CASIA V3.0 Interval data sets, respectively. Moreover, such a deep convolutional NN for segmentation when included in an end-to-end iris recognition system with a siamese based matching network will augment the performance of the siamese network.

DeepKnuckle: revealing the human identity
Single-sensor hand-vein multimodal biometric recognition using multiscale deep pyramidal approach
Localization of common carotid artery transverse section in B-mode ultrasound images using faster RCNN: a deep learning approach
3D face recognition using kinect
2D Face recognition systems bound to fail on images with varying pose angles and occlusions. Many pose invariant methods are proposed in recent years but they are still not able to achieve very good accuracies. So in order to achieve a better accuracy we need to extend algorithms over 3D faces. Due to the high cost involved in acquisition of 3D faces we developed our approach for low-cost and low-quality Microsoft Kinect Sensor and propose an algorithm to produce better results than existing 2D Face recognition techniques even after compromising on the quality of the images from the sensor. Our proposed algorithm is based on modified SURF descriptors on RGB images combined with various enhancements on automatically generated training images using Depth and Color images. We compare our results obtained with State Of The Art Techniques obtained on publicly available RGB-D Face databases. Our System obtained recognition rate of 98.07% on 30° CurtinFace Database, 89.28% on EURECOM Database, 98.00% on 15° Internal Database and 81.00% on 30° Internal Database.

Gait metric learning siamese network exploiting dual of spatio-temporal 3D-CNN intra and LSTM based inter gait-cycle-segment features
VStegNET: Video Steganography Network using Spatio-Temporal features and Micro-Bottleneck.
Steganography is the practice of hiding a secret message in a cover message such that the cover stays indiscernible after hiding and only the intended recipients can extract the secret from it. Traditional image steganography techniques hide the secret image into high-frequency regions of the cover images. These techniques typically result in lower embedding ratios and easy detection. In this paper, we propose VStegNET, a video steganography network that extracts spatio-temporal features using 3D-CNN and micro-bottleneck (Hourglass) which is the ﬁrst of its kind in the literature of video steganography. The proposed network hides M × N (RGB) secret video frames into same sized cover video frames. We have trained our model on UCF 101 action recognition video dataset and evaluated its performance using various quantitative metrics (APD, PSNR, and SSIM) and compared it with previous the state-of-the-art. Furthermore, we have also presented a detailed analysis, supporting the proposal’s superiority over image steganography models. Finally, several standard steganalysis tools like StegExpose, SRNET, etc. have been used to justify the steganographic capabilities of VStegNET.

A new distance measure for face recognition system
This paper proposes a new powerful distance measure called Normalized Unmatched Points (NUP). This measure can be used in a face recognition system to discriminate facial images. It works by counting the number of unmatched pixels between query and database images. A face recognition system has been proposed which makes use of this proposed distance measure for taking the decision on matching. This system has been tested on four publicly available databases, viz. ORL, YALE, BERN and CALTECH databases. Experimental results show that the proposed measure achieves recognition rates more than 98.66% for the first five likely matched faces. It is observed that the NUP distance measure performs better than other existing similar variants on these databases.

Finger knuckleprint based recognition system using feature tracking
Iris recognition using consistent corner optical flow
Hierarchical X-ray report generation via pathology tags and multi head attention
DONE