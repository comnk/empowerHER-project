Bartendr: a practical approach to energy-aware cellular data scheduling
Cellular radios consume more power and suffer reduced data rate when the signal is weak. According to our measurements, the communication energy per bit can be as much as 6x higher when the signal is weak than when it is strong. To realize energy savings, applications must preferentially communicate when the signal is strong, either by deferring non-urgent communication or by advancing anticipated communication to coincide with periods of strong signal. Allowing applications to perform such scheduling requires predicting signal strength, so that opportunities for energy-efficient communication can be anticipated. Furthermore, such prediction must be performed at little energy cost. In this paper, we make several contributions towards a practical system for energy-aware cellular data scheduling called Bartendr. First, we establish, via measurements, the relationship between signal strength and power consumption. Second, we show that location alone is not sufficient to predict signal strength and motivate the use of tracks to enable effective prediction. Finally, we develop energy-aware scheduling algorithms for different workloads - syncing and streaming - and evaluate these via simulation driven by traces obtained during actual drives, demonstrating energy savings of up to 60%. Our experiments have been performed on four cellular networks across two large metropolitan areas, one in India and the other in the U.S.

{PowerSpy}: Location Tracking Using Mobile Device Power Analysis
Modern mobile platforms like Android enable applications to read aggregate power usage on the phone. This information is considered harmless and reading it requires no user permission or notification. We show that by simply reading the phone's aggregate power consumption over a period of a few minutes an application can learn information about the user's location. Aggregate phone power consumption data is extremely noisy due to the multitude of components and applications that simultaneously consume power. Nevertheless, by using machine learning algorithms we are able to successfully infer the phone's location. We discuss several ways in which this privacy leak can be remedied.

An end-to-end measurement of certificate revocation in the web's PKI
Critical to the security of any public key infrastructure (PKI) is the ability to revoke previously issued certificates. While the overall SSL ecosystem is well-studied, the frequency with which certificates are revoked and the circumstances under which clients (e.g., browsers) check whether certificates are revoked are still not well-understood. In this paper, we take a close look at certificate revocations in the Web's PKI. Using 74 full IPv4 HTTPS scans, we find that a surprisingly large fraction (8%) of the certificates served have been revoked, and that obtaining certificate revocation information can often be expensive in terms of latency and bandwidth for clients. We then study the revocation checking behavior of 30 different combinations of web browsers and operating systems; we find that browsers often do not bother to check whether certificates are revoked (including mobile browsers, which uniformly never check). We also examine the CRLSet infrastructure built into Google Chrome for disseminating revocations; we find that CRLSet only covers 0.35% of all revocations. Overall, our results paint a bleak picture of the ability to effectively revoke certificates today.

Analysis of SSL certificate reissues and revocations in the wake of Heartbleed
Central to the secure operation of a public key infrastructure (PKI) is the ability to revoke certificates. While much of users' security rests on this process taking place quickly, in practice, revocation typically requires a human to decide to reissue a new certificate and revoke the old one. Thus, having a proper understanding of how often systems administrators reissue and revoke certificates is crucial to understanding the integrity of a PKI. Unfortunately, this is typically difficult to measure: while it is relatively easy to determine when a certificate is revoked, it is difficult to determine whether and when an administrator should have revoked. In this paper, we use a recent widespread security vulnerability as a natural experiment. Publicly announced in April 2014, the Heartbleed OpenSSL bug, potentially (and undetectably) revealed servers' private keys. Administrators of servers that were susceptible to Heartbleed should have revoked their certificates and reissued new ones, ideally as soon as the vulnerability was publicly announced. Using a set of all certificates advertised by the Alexa Top 1 Million domains over a period of six months, we explore the patterns of reissuing and revoking certificates in the wake of Heartbleed. We find that over 73% of vulnerable certificates had yet to be reissued and over 87% had yet to be revoked three weeks after Heartbleed was disclosed. Moreover, our results show a drastic decline in revocations on the weekends, even immediately following the Heartbleed announcement. These results are an important step in understanding the manual processes on which users rely for secure, authenticated communication.

Maranello: Practical Partial Packet Recovery for 802.11.
Partial packet recovery protocols attempt to repair corrupted packets instead of retransmitting them in their entirety. Recent approaches have used physical layer confidence estimates or additional error detection codes embedded in each transmission to identify corrupt bits, or have applied forward error correction to repair without such explicit knowledge. In contrast to these approaches, our goal is a practical design that simultaneously: (a) requires no extra bits in correct packets, (b) reduces recovery latency, except in rare instances, (c) remains compatible with existing 802.11 devices by obeying timing and backoff standards, and (d) can be incrementally deployed on widely available access points and wireless cards. 
 
In this paper, we design, implement, and evaluate Maranello, a novel partial packet recovery mechanism for 802.11. In Maranello, the receiver computes checksums over blocks in corrupt packets and bundles these checksums into a negative acknowledgment sent when the sender expects to receive an acknowledgment. The sender then retransmits only those blocks for which the checksum is incorrect, and repeats this partial retransmission until it receives an acknowledgment. Successful transmissions are not burdened by additional bits and the receiver needs not infer which bits were corrupted. We implemented Maranello using OpenFWWF (open source firmware for Broadcom wireless cards) and deployed it in a small testbed. We compare Maranello to alternative recovery protocols using a trace-driven simulation and to 802.11 using a live implementation under various channel conditions. To our knowledge, Maranello is the first partial packet recovery design to be implemented in commonly available firmware.

Pingin' in the rain
Residential Internet connections are susceptible to weather-caused outages: Lightning and wind cause local power failures, direct lightning strikes destroy equipment, and water in the atmosphere degrades satellite links. Outages caused by severe events such as fires and undersea cable cuts are often reported upon by operators and studied by researchers. In contrast, outages cause by ordinary weather are typically limited in scope, and because of their small scale, there has not been comparable effort to understand how weather affects everyday last-mile Internet connectivity. We design and deploy a measurement tool called ThunderPing that measures the connectivity of residential Inter- net hosts before, during, and after forecast periods of severe weather. ThunderPing uses weather alerts from the US National Weather Service to choose a set of residential host addresses to ping from several vantage points on the Internet. We then process this ping data to determine when hosts lose connectivity, completely or partially, and categorize whether these failures occur during periods of severe weather or when the skies are clear. In our preliminary results, we find that compared to clear weather, failures are four times as likely during thunderstorms and two times as likely during rain. We also find that the duration of weather induced outages is relatively small for a satellite provider we focused on.

Stratus: Energy-efficient mobile communication using cloud support
Cellular radio communication is a significant contributor to battery energy drain on smartphones, in some cases inflating the energy cost by a factor of 5 or more compared to the energy cost of the base device. Stratus is a system to reduce this energy consumption by leveraging cloud resources to make data communication on smartphones more efficient. Using a cloud-based proxy, Stratus employs optimizations that adapt an application's incoming and outgoing traffic to better match the energy characteristics of the radio interface. The optimizations include (a) aggregation to bunch up sporadic transmissions, (b) asymmetric dictionary-based compression to reduce the number of bits transmitted over the air, and (c) opportunistic scheduling to avoid communication during periods of poor signal reception. These optimizations can be used individually, or in combination, subject to an application's delay tolerance. For example, using our Stratus prototype, the aggregation and compression optimizations together achieve up to 50% energy savings for web browsing, while the aggregation and scheduling optimizations together achieve up to 35% energy savings for a media streaming application.

On the fidelity of 802.11 packet traces
CRAWDAD data set umd/sigcomm2008
Residential links under the weather
Weather is a leading threat to the stability of our vital infrastructure. Last-mile Internet is no exception. Yet, unlike other vital infrastructure, weather's effect on last-mile Internet outages is not well understood. This work is the first attempt to quantify the effect of weather on residential outages. Investigating outages in residential networks due to weather is challenging because residential Internet is heterogeneous: there are different media types, different protocols, and different providers, in varying contexts of different local climate and geography. Sensitivity to these different factors leads to narrow categories when estimating how weather affects these different links. To address these issues we perform a large-scale study looking at eight years of active outage measurements that were collected across the bulk of the last mile Internet infrastructure in the United States.

Evaluating physical-layer BLE location tracking attacks on mobile devices
Mobile devices increasingly function as wireless tracking beacons. Using the Bluetooth Low Energy (BLE) protocol, mobile devices such as smartphones and smartwatches continuously transmit beacons to inform passive listeners about device locations for applications such as digital contact tracing for COVID-19, and even finding lost devices. These applications use cryptographic anonymity that limit an adversary’s ability to use these beacons to stalk a user. However, attackers can bypass these defenses by fingerprinting the unique physical-layer imperfections in the transmissions of specific devices.We empirically demonstrate that there are several key challenges that can limit an attacker’s ability to find a stable physical layer identifier to uniquely identify mobile devices using BLE, including variations in the hardware design of BLE chipsets, transmission power levels, differences in thermal conditions, and limitations of inexpensive radios that can be widely deployed to capture raw physical-layer signals. We evaluated how much each of these factors limits accurate fingerprinting in a large-scale field study of hundreds of uncontrolled BLE devices, revealing that physical-layer identification is a viable, although sometimes unreliable, way for an attacker to track mobile devices.

Trufflehunter: cache snooping rare domains at large public DNS resolvers
This paper presents and evaluates Trufflehunter, a DNS cache snooping tool for estimating the prevalence of rare and sensitive Internet applications. Unlike previous efforts that have focused on small, misconfigured open DNS resolvers, Trufflehunter models the complex behavior of large multi-layer distributed caching infrastructures (e.g., such as Google Public DNS). In particular, using controlled experiments, we have inferred the caching strategies of the four most popular public DNS resolvers (Google Public DNS, Cloudflare Quad1, OpenDNS and Quad9). The large footprint of such resolvers presents an opportunity to observe rare domain usage, while preserving the privacy of the users accessing them. Using a controlled testbed, we evaluate how accurately Trufflehunter can estimate domain name usage across the U.S. Applying this technique in the wild, we provide a lower-bound estimate of the popularity of several rare and sensitive applications (most notably smartphone stalkerware) which are otherwise challenging to survey.

Atomix: A framework for deploying signal processing applications on wireless infrastructure
Multi-processor DSPs have become the platform of choice for wireless infrastructure. This trend presents an opportunity to enable faster and wider scale deployment of signal processing applications at scale. However, achieving the hardware-like performance required by signal processing applications requires interacting with bare metal features on the DSP. This makes it challenging to build modular applications. 
 
We present Atomix, a modular software framework for building applications on wireless infrastructure. We demonstrate that it is feasible to build modular DSP software by building the application entirely out of fixed-timing computations that we call atoms. We show that applications built in Atomix achieve hardware-like performance by building an 802.11a receiver that operates at high bandwidth and low latency. We also demonstrate that the modular structure of software built with Atomix makes it easy for programmers to deploy new signal processing applications. We demonstrate this by tailoring the 802.11a receiver to long-distance environments and adding RF localization to it.

RevCast: Fast, private certificate revocation over FM radio
The ability to revoke certificates is a fundamental feature of a public key infrastructure. However, certificate revocation systems are generally regarded as ineffective and potentially insecure: Some browsers bundle revocation updates with more general software updates, and may go hours, days, or indefinitely between updates; moreover, some operating systems make it difficult for users to demand recent revocation data. This paper argues that this sad state of affairs is an inexorable consequence of relying on unicast communication to distribute revocation information. We present RevCast, a broadcast system that disseminates revocation data in a timely and private manner. RevCast is not emulated broadcast over traditional Internet links, but rather a separate metropolitan-area wireless broadcast link; specifically, we have designed RevCast to operate over existing FM radio, although the principles apply to alternative implementations. We present the design, implementation, and initial deployment of RevCast on a 3 kW commercial radio station using the FM RDS protocol. With the use of two types of receivers (an RDS-to-LAN bridge that we have prototyped and an RDS-enabled smartphone), we show that, even at a low bitrate, RevCast is able to deliver complete and timely revocation information, anonymously, even for receivers who do not receive all packets all the time.

Visualizing real-time network resource usage
Phone power monitoring with battor
Wireless sensor networks (SNETs) consist of small battery-powered “motes” with limited computation and radio communication capabilities. Using SNETs, large-scale ad hoc sensor networks (ASNET) can be deployed among mobile patients, and, thus, can provide dynamic data query architecture to allow the medical specialists to monitor patients at any place via the web or cellular network. In case of an emergency, doctors and/or nurses will be contacted automatically through their handhelds or cellular phones. The paper describes the design of a proposed network that consists of sensor nodes at the first layer whose responsibility is to measure, collect and communicate readings to a microcontroller at the second layer. Deployed microcontrollers process incoming readings and report to a central system via a wireless interface and send SMS messages to the cellular phones of doctors and/or nurses in emergencies. The implemented network distinguishes between periodic readings and critical readings where higher priority is given for the latter. In this paper we design and implement a three-tier telecare system for tracking and monitoring patients and doctors using SNETs. The proposed system utilizes Wi-Fi interfaces as well as communication through GSM network. A large scale Wi-Fi based implementation has been modeled and evaluated. Introduction Increased interest in the field of telemedicine has been observed recently due to advancements in embedded computing systems that led to the emergence of wireless sensor networks (SNETs). A typical sensor network consists of a large number of sensor nodes (SNODEs) that are densely deployed either inside the phenomenon or at a close proximity to it. The sensor network topology may experience frequent changes, and, thus, the position of the SNODEs need not be engineered or pre-determined. Furthermore, in addition to being capable of sending the raw data directly to the nodes responsible for the fusion, SNODEs, with the help of the onboard processor, are also capable of locally carrying out simple computations and transmitting only the required and partially processed data. Moreover, sensor networks have self organizing and fault tolerant capabilities. Such capabilities make sensor networks suitable to many applications such as health, environmental, military, security, and home applications (Akyildiz 2002) In general, the main tasks of an SNODE are events detection, data processing and data transmission. Power consumption in an SNODE can be divided into three categories: sensing, communication and data processing. While sensing power depends on the nature of the application, periodic updates consume less power than persistent monitoring. Note that an SNODE is equipped with a limited power (Akyildiz 2002; Li 2001; Porret 2000; Rabaey 2000) where the SNODE operation is highly dependent on battery lifetime. Therefore, power conservation and power management is very critical. Akyildiz et. al. (Akyildiz 2002), presented a possible architecture of a sensor network. It consists of the sensor field that defines the collection of the scattered SNODEs, the sink, and the task manager node. Using a multihop infrastructureless architecture, the data collected from the scattered SNODEs are routed to the sink node, where it is communicated via Internet or satellite to the task manager node. In this paper we propose a design and present a case study of the use of an ad hoc sensor network (ASNET) to facilitate the monitoring of the health conditions of the patients. By deploying SNODEs with each patient and possibly SNODEs with doctors and/or nurses, the monitoring of the health conditions of the patients can be effectively achieved. Each SNODE deployed with the patient has a specific task such as reading blood pressure, temperature, and so on. The resulting mobile patient ASNET allows the tracking and the monitoring of patients and doctors inside and/or outside the hospital. More importantly, in the case of an emergency, doctors and/or nurses will be contacted automatically through their handheld personal digital assistants (PDAs) or cellular phones. Upon being contacted, the doctor/nurse will in turn issue a medical query to the specific mobile patient ASNET (Hu 2002; Hu 2003; Noury 2000; Ogawa 1998; Papadimitratos 2002). The implemented ASNET consists of three hierarchal layers as shown in Figure 1. The sensor nodes of the ASNET act as the first layer, and are responsible for measuring, collecting and communicating, via a wired or a wireless interface, readings to a microcontroller that makes up the second layer. Consequently, microcontrollers from different patients communicate with the third layer devices consisting of Warning and monitoring medical 18th National Computer Conference 2006 © Saudi Computer Society 1 either central computer or handheld PDAs/notebooks carried by doctors/nurses. In the case of an emergency, the patient microcontroller directly sends an SMS message to the cellular phones of doctors and/or nurses. An important feature of the implemented ASNET is that it distinguishes between periodic sensor readings and critical or event driven readings where higher priority is given for the latter. In section 2 we offer a brief background on the area of telemedicine to which our paper relates. Subsequently, in section 3 we discuss the details of our implementation by describing the hardware, architecture, software, and a pseudo code of the program used. In section 4 we evaluate the performance of the proposed architecture by means of a detailed analysis. Finally, we conclude our paper. Background Telemedicine is technology designed to play a significant mode of delivery and treatment, especially in the remote suburban areas. Advanced technologies have been developed to eliminate the barriers of distance. Many telehealth programs have been formulated in many countries such as USA, Canada, and other countries where successful telemedicine programs have been implemented (Jennett 2004; Singh 1976; Singh 2005). Telemedicine solutions can be extended to offer solutions even in suburban areas, where specialists are not available. In some countries, existing communication infrastructures are being used to transmit clinical data to areas where a group of specialists are available to provide advice and consultation (Jeutteur 1994; Singh 2005). One major advantage of telemedicine is that it reduces the cost of medical practice and brings expertise into remote areas (Burrow 1994; Singh 2005). Akay et. al. (Akay 1998)proposed an application that uses a multiuser, collaborative environment with multimodal human/machine communication in the dimensions of sight, sound, and touch. Users communicate with the application through a fusion agent by eye-tracking, speech, and microbeam pen. The conversational agent answers the user’s questions and detects human-related or semantic errors and notifies the user about the results of the image analysis. However, even though channel noise is an influential factor in this application, the authors did not study it. The study in (Woodward 2003) suggested a telemedicine system utilizing the Global System for Mobile communication (GSM) cellular network and the Public Service Telephone Network (PSTN) to hospital, however, the authors did not address how the data is gathered from patients. Furthermore, the application implemented in (Woodward 2003) provided limited data rate of 9.6 kbps. In contrast, a high bandwidth application such as the one developed in (Bates 2002; Rodriguez 2001) provided wireless multimedia access to medical information in which medical data is sent to a mobile phone for management of patients. The study concluded that the system is applicable in large city hospitals for light traffic scenarios and in suburban hospital areas. The system requires a high bandwidth, which is a major concern in wireless communication. In (Angood 2002; Satava 2000) a telemedicine project was developed to monitor climbers on Mount Everest. A satellite link was used to monitor the location, heart rate, skin temperature, etc. of the climbers. The study shows the applicability of telemedicine, through satellite, to harsh environments and concluded that other applications, such Figure 1. Three layers of implemented ASNET 2

Scheduling communications in a mobile device
The method of performing scheduling at the relay station and a relay station in a mobile communication network is disclosed. By defining a parameter for scheduling the downlink transmission of data stored in the buffer is being received scheduling information, the channel state information is received from the relay station associated with the device. The updated scheduling parameters are obtained based on the amount of data currently stored in the received scheduling information, the channel state information and buffer. Data stored in the buffer can be sent to the associated device based on the updated scheduling parameters. The channel state information may be transmitted to the base station or the intermediate relay station to provide feedback on the channel state. The channel state information may be quantized prior to transmission to reduce the volume of data transmitted over the network.

Detecting if LTE is the bottleneck with bursttracker
We present BurstTracker, the first tool that developers can use to detect if the LTE downlink is the bottleneck for their applications. BurstTracker is driven by our discovery that the proprietary LTE downlink schedulers running on LTE base stations allocate resources to users in a way that reveals if a user's downlink queue runs empty during a download. We demonstrate that BurstTracker works across Tier-1 cellular providers and across a variety of network conditions. We also present a case study that shows how application developers can use this tool in practice. Surprisingly, with BurstTracker, we find that the LTE downlink may not be the bottleneck for video streaming on several Tier-1 providers, even during peak hours at busy locations. Rather, transparent TCP middleboxes deployed by these providers lead to downlink underutilization, because they force Slow-Start Restart. With a simple workaround, we improve video streaming bitrate on busy LTE links by 35%.

{SweepSense}: Sensing 5 {GHz} in 5 Milliseconds with Low-cost Radios
Wireless transmissions occur intermittently across the entire spectrum. For example, WiFi and Bluetooth devices transmit frames across the 100 MHz-wide 2.4 GHz band, and LTE devices transmit frames between 700 MHz and 3.7 GHz). Today, only high-cost radios can sense across the spectrum with sufficient temporal resolution to observe these individual transmissions. 
 
We present "SweepSense", a low-cost radio architecture that senses the entire spectrum with high-temporal resolution by rapidly sweeping across it. Sweeping introduces new challenges for spectrum sensing: SweepSense radios only capture a small number of distorted samples of transmissions. To overcome this challenge, we correct the distortion with self-generated calibration data, and classify the protocol that originated each transmission with only a fraction of the transmission's samples. We demonstrate that SweepSense can accurately identify four protocols transmitting simultaneously in the 2.4 GHz unlicensed band. We also demonstrate that it can simultaneously monitor the load of several LTE base stations operating in disjoint bands.

Timeouts: Beware surprisingly high delay
Active probing techniques, such as ping, have been used to detect outages. When a previously responsive end host fails to respond to a probe, studies sometimes attempt to confirm the outage by retrying the ping or attempt to identify the location of the outage by using other tools such as traceroute. The latent problem, however, is, how long should one wait for a response to the ping? Too short a timeout risks confusing congestion or other delay with an outage. Too long a timeout may slow the process and prevent observing and diagnosing short-duration events, depending on the experiment's design. We believe that conventional timeouts for active probes are underestimates, and analyze data collected by Heidemann et al. in 2006--2015. We find that 5% of pings from 5% of addresses take more than 5 seconds. Put another way, for 5% of the responsive IP addresses probed by Heidemann, a false 5% loss rate would be inferred if using a timeout of 5 seconds. To arrive at this observation, we filtered artifacts of the data that could occur with too-long a timeout, including responses to probes sent to broadcast addresses. We also analyze ICMP data collected by Zmap in 2015 to find that around 5% of all responsive addresses observe a greater than one second round-trip time consistently. Further, the prevalence of high round trip time has been increasing and it is often associated with the first ping, perhaps due to negotiating a wireless connection. In addition, we find that the Autonomous Systems with the most high-latency addresses are typically cellular. This paper describes our analysis process and results that should encourage researchers to set longer timeouts when needed and report on timeout settings in the description of future measurements.

DONE