Substitutional Reality: Using the physical environment to design virtual reality experiences
Experiencing Virtual Reality in domestic and other uncontrolled settings is challenging due to the presence of physical objects and furniture that are not usually defined in the Virtual Environment. To address this challenge, we explore the concept of Substitutional Reality in the context of Virtual Reality: a class of Virtual Environments where every physical object surrounding a user is paired, with some degree of discrepancy, to a virtual counterpart. We present a model of potential substitutions and validate it in two user studies. In the first study we investigated factors that affect participants' suspension of disbelief and ease of use. We systematically altered the virtual representation of a physical object and recorded responses from 20 participants. The second study investigated users' levels of engagement as the physical proxy for a virtual object varied. From the results, we derive a set of guidelines for the design of future Substitutional Reality experiences.

Similarity-based forecasting with simultaneous previews: A river plot interface for time series forecasting
Time-series forecasting has a large number of applications. Users with a partial time series for auctions, new stock offerings, or industrial processes desire estimates of the future behavior. We present a data driven forecasting method and interface called similarity-based forecasting (SBF). A pattern matching search in an historical time series dataset produces a subset of curves similar to the partial time series. The forecast is displayed graphically as a river plot showing statistical information about the SBF subset. A forecasting preview interface allows users to interactively explore alternative pattern matching parameters and see multiple forecasts simultaneously. User testing with 8 users demonstrated advantages and led to improvements.

Evaluating immersive experiences during Covid-19 and beyond
The COVID-19 pandemic has disrupted our daily lives . The safety and well-being of people are paramount, and there is no exception for the human-computer interaction (HCI) field. Most universities and research labs have closed non-critical research labs. With that closure and the student populations having left campus, in-person user studies have been suspended for the foreseeable future. Experiments that involve the usage of specialized technology, such as virtual and augmented reality headsets, create additional challenges. While some head-mounted displays (HMDs) have become more affordable for consumers (e.g., Oculus Quest), there are still multiple constraints for researchers, including the expense of high-end HMDs (e.g., Microsoft Hololens), high-end graphics hardware, and specialized sensors, as well as ethical concerns around reusing equipment that comes in close contact with each participant and may be difficult to sterilize. These difficulties have led the extended reality (XR) community (which includes the virtual reality (VR) and augmented reality (AR) research communities) to ask how we can continue to practically and ethically run experiments under these circumstances. Here, we summarize the status of a community discussion of short-term, medium-term, and long-term measures to deal with the current COVID-19 situation and its potential longer-term impacts. In particular, we outline steps we are taking toward community support of distributed experiments. There are a number of reasons to look at a more distributed model of participant recruitment, including the generalizability of the work and potential access to target-specific, hard-to-reach user groups. We hope that this article will inform the first steps toward addressing the practical and ethical concerns for such studies [1]. There are currently no strong ethical guidelines

MobiSurf: Improving Co-located Collaboration through Integrating Mobile Devices and Interactive Surfaces
One of the most popular scenarios for advertising interactive surfaces in the home is their support for solving co-located collaborative tasks. Examples include joint planning of events (e.g., holidays) or deciding on a shared purchase (e.g., a present for a common friend). However, this usually implies that all interactions with information happen on the common display. This is in contrast to the current practices to use personal devices and further, most people's behavior to constantly switch between individual and group phases because people have differing search strategies, preferences, etc. We therefore investigated how the combination of personal devices and a simple way of exchanging information between these devices and an interactive surface changes the way people solve collaborative tasks compared to an existing approach of using personal devices. Our study results clearly indicate that the combination of personal and a shared device allows users to fluently switch between individual and group work phases and users take advantage of both device classes.

Virtual reality games for people using wheelchairs
Virtual Reality (VR) holds the promise of providing engaging embodied experiences, but little is known about how people with disabilities engage with it. We explore challenges and opportunities of VR gaming for wheelchair users. First, we present findings from a survey that received 25 responses and gives insights into wheelchair users' motives to (non-) engage with VR and their experiences. Drawing from this survey, we derive design implications which we tested through implementation and qualitative evaluation of three full-body VR game prototypes with 18 participants. Our results show that VR gaming engages wheelchair users, though nuanced consideration is required for the design of embodied immersive experiences for minority bodies, and we illustrate how designers can create meaningful, positive experiences.

Feet movement in desktop 3D interaction
In this paper we present an exploratory work on the use of foot movements to support fundamental 3D interaction tasks. Depth cameras such as the Microsoft Kinect are now able to track users' motion unobtrusively, making it possible to draw on the spatial context of gestures and movements to control 3D UIs. Whereas multitouch and mid-air hand gestures have been explored extensively for this purpose, little work has looked at how the same can be accomplished with the feet. We describe the interaction space of foot movements in a seated position and propose applications for such techniques in three-dimensional navigation, selection, manipulation and system control tasks in a 3D modelling context. We explore these applications in a user study and discuss the advantages and disadvantages of this modality for 3D UIs.

A virtual reality shopping experience using the apartment metaphor
In contrast to conventional retail stores, online shopping comes with many advantages, like unrestricted opening hours and is more focused on functionality. However, these pros often come at a cost of complex search and limited product visualization. Virtual Reality (VR) has the potential to create novel shopping experiences that combine the advantages of e-commerce sites and conventional stores. In this work, we propose a VR shop concept where product placement is not organized in shelves but through spatial placement in appropriate locations in an apartment environment. We thus investigated how the spatial arrangement of products in a non-retail environment affects the user, and how the actual shopping task can be supported in VR. In order to answer these questions, we designed two product selection and manipulation techniques (grabbing and pointing) and two VR shopping cart concepts (a realistic basket and an abstract one) and evaluated them in a user study. The results indicate that product interaction using pointing in combination with the abstract cart concept performs best with regard to error rate, user experience and workload. Overall, the proposed apartment metaphor provides excellent customer satisfaction, as well as a particularly high level of immersion and user experience, and it opens up new possibilities for VR shopping experiences that go far beyond mimicking real shop environments in VR.

Altering User Movement Behaviour in Virtual Environments
In immersive Virtual Reality systems, users tend to move in a Virtual Environment as they would in an analogous physical environment. In this work, we investigated how user behaviour is affected when the Virtual Environment differs from the physical space. We created two sets of four environments each, plus a virtual replica of the physical environment as a baseline. The first focused on aesthetic discrepancies, such as a water surface in place of solid ground. The second focused on mixing immaterial objects together with those paired to tangible objects. For example, barring an area with walls or obstacles. We designed a study where participants had to reach three waypoints laid out in such a way to prompt a decision on which path to follow based on the conflict between the mismatching visual stimuli and their awareness of the real layout of the room. We analysed their performances to determine whether their trajectories were altered significantly from the shortest route. Our results indicate that participants altered their trajectories in presence of surfaces representing higher walking difficulty (for example, water instead of grass). However, when the graphical appearance was found to be ambiguous, there was no significant trajectory alteration. The environments mixing immaterial with physical objects had the most impact on trajectories with a mean deviation from the shortest route of 60 cm against the 37 cm of environments with aesthetic alterations. The co-existance of paired and unpaired virtual objects was reported to support the idea that all objects participants saw were backed by physical props. From these results and our observations, we derive guidelines on how to alter user movement behaviour in Virtual Environments.

Substitutional reality: Towards a research agenda
In our previous work on Substitutional Reality, we presented an exploration of a class of Virtual Environments where every physical object surrounding the user is associated with appropriate virtual counterparts. Differently from “passive haptics”, Substitutional Reality assumes the existence of a discrepancy in the association. This previous work explored how far this mismatch can be pushed and its impact on the believability of the experience. In this paper we discuss three main research directions for Substitutional Reality. Firstly, the design space is largely unexplored as the initial investigation focused on the mismatch between real and virtual objects. Secondly, the development of systems enabling a dynamic substitution process represents a key challenge. Thirdly, we discuss the meta-design process of these experiences.

Comparing low cost input devices for interacting with 3D Virtual Environments
Interaction with 3D Virtual Environments has always suffered from a lack of widely available and low cost input devices. Recently, thanks to the diffusion of gaming systems such as the Microsoft XBox 360 or the Nintendo Wii, new input devices are on the market at a relatively cheap price. This paper describes a study whose aim is to compare input devices in order to identify effective alternatives for the mouse and keyboard in such settings where their use is not advisable or feasible, e.g. museums and other public areas. This study has been carried out using a 3D Virtual Environment in which the participants were required to perform three canonical 3D interaction tasks. Two different groups participated to the test: the first group was involved in a pilot study to check the test environment. The second group performed the test.

The VR Motion Tracker: visualising movement of non-participants in desktop virtual reality experiences
In this paper we present the VR Motion Tracker: a widget that informs users of VR applications of the movements of nonparticipants. The design of the widget is inspired by the the motion tracker used in the Alien film franchise. It uses a Kinect to detect other people in the room, besides the user of the VR application. Our system maps this information to a sphere placed within a triangular plane representing the Kinect’s field of view. When these non-participants move, the position of the sphere is updated, allowing the user to be aware of nearby movements. We performed a preliminary study where we presented nine participants with our widget design. We found that they considered the widget to be useful and not distracting. We discuss which features they found interesting, and other information and features they considered useful for a future version of this widget.

Investigating the effect of distractor interactivity for redirected walking in virtual reality
Due to the mismatch in size between a Virtual Environment and the physical space available, the use of alternative locomotion techniques becomes necessary. In small spaces, Redirected Walking methods provide limited benefits and approaches such as the use of distractors can provide an alternative. Distractors are virtual elements or characters that attempt to catch the attention of the user while the system subtly steers them away from physical boundaries. In this research we explicitly focused on understanding how different levels of interactivity affect user performance and behaviour. We developed three types of continuous redirecting distractors, with varying levels of interaction possibilities, called Looking, Touching, and Interacting. We compared them in a user study to a discrete reorientation technique, called Stop and Reset, in a task requiring users to traverse a 30 m path. While discrete reorientation is faster, continuous redirection through distractors was significantly less noticeable. Results suggest that more complex interaction is preferred and able to better captivate user attention for longer.

Propping up Virtual Reality with Haptic Proxies
Physical props serving as proxies for virtual objects (haptic proxies) offer a cheap, convenient, and compelling way of delivering a sense of touch in virtual reality (VR). To successfully use haptic proxies for VR, they have to be both similar to and colocated with their virtual counterparts. In this article, we introduce a taxonomy organizing techniques using haptic proxies for VR into eight categories based on when the techniques are deployed (offline or real-time), what reality is being manipulated (physical or virtual reality), and the purpose of the techniques (to affect object perception or the mapping between real and virtual objects). Finally, we discuss key advantages and limitations of the different categories of techniques.

Combining multimedia resources for an engaging experience of cultural heritage
ICT technologies have a great potential not only for preserving and increasing awareness about cultural heritage, but also for allowing people to better experience this huge legacy. Various application tools have already been developed which provide different types of multimedia resources, such as 3D representations of objects and places, videos, graphics, sounds, in order to augment the physical context by providing virtual, location-specific information, so that people can experience some aspects of ancient life which would otherwise be very difficult to figure out. The effort spent to create multimedia resources is considerable; therefore, it is worth reusing them to produce applications suited to other types of visitors. In this paper, we present our on-going work to provide tailored applications that support different types of visitors. Such applications are developed according to a model that describes how multimedia resources can be combined, also depending on the type of users and devices. Examples of these solutions are briefly illustrated.

The Space Bender: Supporting Natural Walking via Overt Manipulation of the Virtual Environment
Manipulating the appearance of a Virtual Environment to enable natural walking has so far focused on modifications that are intended to be unnoticed by users. In our research, we took a radically different approach by embracing the overt nature of the change. To explore this method, we designed the Space Bender, a natural walking technique for room-scale VR. It builds on the idea of overtly manipulating the Virtual Environment by "bending" the geometry whenever the user comes in proximity of a physical boundary. Our aim was to evaluate the feasibility of this approach in terms of performance and subjective feedback. We compared the Space Bender to two other similarly situated techniques: Stop and Reset and Teleportation, in a task requiring participants to traverse a 100 m path. Results show that the Space Bender was significantly faster than Stop and Reset, and preferred to the Teleportation technique, highlighting the potential of overt manipulation to facilitate natural walking.

Live: The human role in learning in immersive virtual environments
This work studies the role of a human instructor within an immersive VR lesson. Our system allows the instructor to perform “contact teaching” by demonstrating concepts through interaction with the environment, and the student to experiment with interaction prompts. We conducted a between-subjects user study with two groups of students: one experienced the VR lesson while immersed together with an instructor; the other experienced the same contents demonstrated through animation sequences simulating the actions that the instructor would take. Results show that the Two-User version received significantly higher scores than the Single-User version in terms of overall preference, clarity, and helpfulness of the explanations. When immersed together with an instructor, users were more inclined to engage and progress further with the interaction prompts, than when the instructor was absent. Based on the analysis of videos and interviews, we identified design recommendations for future immersive VR educational experiences.

Immersive Speculative Enactments: Bringing Future Scenarios and Technology to Life Using Virtual Reality
In this paper we present Immersive Speculative Enactments (ISEs), a novel concept that extends conventional Speculative Enactments to Virtual Reality. Through ISEs, participants are immersed in a speculative world depicted by the designers and can engage with it in its truest envisioned form. We explore this concept via four scenarios with increasing technological uncertainty: a glimpse in the daily life of the parent of a newborn baby; a Mixed Reality experience supporting hybrid classrooms; two wearable devices that present a pet’s emotional state and needs; and an enactment on the effect of communication delay across interplanetary distances. We discuss the concept of ISEs and contrast them to other forms of speculation, provide guidelines on how to design them, as well as reflecting on the challenges, limitations, and potential associated with the role of ISEs in the HCI discourse.

A Cross-Device Drag-and-Drop Technique
Many interactions naturally extend across smart-phones and devices with larger screens. Indeed, data might be received on the mobile but more conveniently processed with an application on a larger device, or vice versa. Such interactions require spontaneous data transfer from a source location on one screen to a target location on the other device. We introduce a cross-device Drag-and-Drop technique to facilitate these interactions involving multiple touchscreen devices, with minimal effort for the user. The technique is a two-handed gesture, where one hand is used to suitably align the mobile phone with the larger screen, while the other is used to select and drag an object between devices and choose which application should receive the data.

Exploring an architectural framework for human-building interaction via a semi-immersive cross-reality methodology
The vision of responsive architecture predicts that human experience can be evoked through the dynamic orchestration of spacedefining elements. Whereas recent studies have robotically actuated furniture for functional goals, little is known how this capability can be deployed meaningfully on an architectural scale. We thus evaluated the spatial impact of a responsive wall on the inhabitants of ordinary apartments. To maintain safety during the COVID-19 pandemic, we developed a novel remote, semi-immersive cross-reality simulation evaluation methodology. Based on the orchestration of three space-defining operations, we define a theoretical framework that suggests how the position of a responsive wall can be determined through five distinct architectural qualities. This framework thus proposes how human-building interaction (HBI) could complement its functional goals with augmenting the well-being of occupants in the physical as well as the virtual realm.CCS CONCEPTS •Human-centered computing $\rightarrow$Empirical studies in HCI.

Everyday proxy objects for virtual reality
Immersive virtual experiences are becoming ubiquitous in our daily lives. Besides visual and auditory feedback, other senses like haptics, smell and taste can enhance immersion in virtual environments. Most solutions presented in the past require specialized hardware to provide appropriate feedback. To mitigate this need, researchers conceptualized approaches leveraging everyday physical objects as proxies instead. Transferring these approaches to varying physical environments and conditions, however, poses significant challenges to a variety of disciplines such as HCI, VR, haptics, tracking, perceptual science, design, etc. This workshop will explore the integration of everyday items for multi-sensory feedback in virtual experiences and sets course for respective future research endeavors. Since the community still seems to lack a cohesive agenda for advancing this domain, the goal of this workshop is to bring together individuals interested in everyday proxy objects to review past work, build a unifying research agenda, share ongoing work, and encourage collaboration.

DONE