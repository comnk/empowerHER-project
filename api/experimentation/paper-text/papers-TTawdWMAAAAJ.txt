Sentiment analysis in Turkish media
In this paper, we propose a comparison of Lexicon based and Machine Learning based sentiment analysis methods on Turkish social media. We formed a lexicon based SA method using a sentimentally oriented Turkish lexicon. We form this lexicon with an English opinion lexicon (translated to Turkish), multi-words expressions, words with absence/presence suffixes and extra needed words for Turkish. We explore different pre-processing techniques considering the linguistic properties of Turkish. We apply lexicon based approach by summing up sentiment scores of terms (words, MWEs, abbreviations etc.) in the lexicon. On the other hand, we formed a baseline Machine Learning (ML) based method using different feature sets including word roots and n-grams with a bag of words representation method. We apply both approaches for binary (positive/negative) classification. To show the strength and shortcomings of these two approaches, we evaluate both of them on short (twitter dataset) and long (movie dataset) Turkish informal texts.

Computer analysis of the Turkmen language morphology
Machine translation between Turkic languages
Turkish named entity recognition with deep learning
Named Entity Recognition (NER) is an important task in Natural Language Processing, Data Mining and Information Extraction areas since 1990's. While NER is a succesfully solved problem in English, it is still a hot topic in agglutinative languages like Turkish, Czech, Finnish languages. With the scope of this study we focus on Bidirectional Long Short-Term Memory (BLSTM) neural network models to solve NER problem. We suggest a succesful implementation of Deep Bidirectional Long Short Term Memory (DBLSTM) which reaches %93.69 F1 score, which is state-of-the-art result for Named Entity Recognition in Turkish.

BLEU+: a Tool for Fine-Grained BLEU Computation.
We present a tool, BLEU+, which implements various extension to BLEU computation to allow for a better understanding of the translation performance, especially for morphologically complex languages. BLEU+ takes into account both closeness in morphological structure, closeness of the root words in the WordNet hierarchy while comparing tokens in the candidate and reference sentence. In addition to gauging performance at a finer level of granularity, BLEU+ also allows the computation of various upper bound oracle scores: comparing all tokens considering only the roots allows us to get an upper bound when all errors due to morphological structure are fixed, while comparing tokens in an error-tolerant way considering minor morpheme edit operations, allows us to get a (more realistic) upper bound when tokens that differ in morpheme insertions/deletions and substitutions are fixed. We use BLEU+ in the fine-grained evaluation of the output of our English-to-Turkish statistical MT system.

Rule Based Analysis of the Uyghur Nouns.
This paper describes the implementation of a rule-based analyzer for Uyghur (spoken in Sin Kiang, China) Nouns. We hope this paper will give some contribution for advanced studies to the Uyghur Language in Machine Translation and Natural Language Processing. Like all Turkic languages, the Uyghur Language is an agglutinative language that has productive inflectional and derivational suffixes. In this work, we implemented a finite state two-level morphological analyzer for the Uyghur Nouns by using Xerox Finite State Tools.

Machine learning based ticket classification in issue tracking systems
Due to the rise of usage of virtual systems, support ticket systems have come into prominence. Addressing the issue tickets to appropriate person or unit in the support team has critical importance in order to provide improved end user satisfaction while ensuring better allotment of support recourses. The assignment of help ticket to appropriate group is still manually performed. Especially at large organizations, the manual assignment is not applicable sufficiently. It is time consuming and requires human efforts. There may be mistakes due to human errors. Also resource consumption is carried out ineffectively because of the misaddressing. On the other hand, manual assignment increases the response time which result in end user satisfaction deterioration. Multiple-choice systems which provide the user to choose the related categories or unit within defined categories may seem like better, but the systems are not useful because of those users, especially new users which have never used the system before, usually have no idea about the related category or department. Also users do not want to fill long ticket forms which are needed to identify the issue. In this study, an extension to ITS for auto-addressing the issue ticket to the relevant person or unit in support team is proposed. In this system, bag of word approach, machine learning techniques and other algorithms which proven performance in text processing are used. The recommended method provides high quality user support and boosts end-user satisfaction. It reduces manual efforts and human errors while ensuring high service levels and improved end-user satisfaction.

Veri Madenciliğin Ve Demetleme
Karadeniz ve Hazar Denizi arasında dağlık bir yapıya sahip olan Kafkasya, Karadeniz’in kuzeydoğusunda bulunan Tamam Yarımadası’ndan, Hazar Denizi’nin batısındaki Apşeron Yarımadası’na kadar uzanan alana verilen isimdir. Antik Yakındoğu’nun en büyük kültür ve metalürjik bölgelerinden biri olan Kafkasya, Orta Tunç Çağı’ndan itibaren Antik Dönem metalciliği açısından oldukça önemli bir veri ortaya koymaktadır. Kafkasya bölgesinde metal üreticiliğine dair en erken kanıtların Erken Eneolitik (Kalkolitik) dönemden itibaren saptanabildiği anlaşılmaktadır. Bölgesinin en eski metal eserleri Orta Transkafkasya’daki yerleşimlerde ortaya çıkmıştır. Söz konusu bu metal eserler, Orta ve Doğu Transkafkasya’nın Şulaveri-Şomu Tepe Kültürü yerleşim tabakalarında tespit edilmiştir. Güneydoğu Gürcistan’da Kura-Khramis Didi Gora ve Arukhlo/Nakhiduri I ile Azerbaycan’ın batısındaki Gargalar Tepesi bu yerleşimlerden bir kısmıdır. Kafkasya’da ilk bakır metalürjisinin gelişimi için gerekli olan hammaddenin ana kaynağı olarak Orta Transkafkasya’nın güney bölgesi düşünülmektedir. Ancak bu bilgiyi doğrulayacak yeterli veriye ulaşılamamıştır. 
Antik kaynaklarda Kolhis Bölgesi içerisinde zikredilen Artvin ve çevresi, antik yazarlar tarafından “Altın Zengini Ülke” olarak zikredilmiştir. Kolhis’in tunç metalürjisi Çoruh Havzası, Abhazya ve Racha-Lechkhumi adlı bölgeler üzerinde incelenmiştir. Buralarda üretilen malların yerli halkın kullanımından başka komşu ülkelere ihracatı da yapılmaktaydı. Ayrıca Kolhis Bölgesi’nde zengin demir yatakları da bulunmaktaydı. Günümüz MTA raporlarına göre Artvin, madencilik açısından oldukça zengin olmasına rağmen arkeolojik ve yazılı belgelerin azlığı, bölgenin madencilik ve metal işlemeciliği sürecinin ana hatlarını ifade edilmesini güçleştirmiştir. Bu bölgenin bakır ve demir madeni yönünden zengin olduğunu bölgede yapılan kazılardan ziyade çeşitli buluntulardan anlamaktayız. 
Bu çalışmada Kafkasya’nın maden ve metal işlemeciliğinin arkeolojik ve yazılı kanıtlar ışığında açıklanması amaçlanmıştır. Arkeolojik araştırmaların sonuçlarından hâreketle bölgede madenciliğin ve metal işlemeciliğinin başlangıcından itibaren nasıl bir gelişim süreci geçirdiği tespit edilmeye çalışılmıştır.

Document categorization with modified statistical language models for agglutinative languages
In this paper, we investigate the document categorization task with statistical language models. Our study mainly focuses on categorization of documents in agglutinative languages. Due to the productive morphology of agglutinative languages, the number of word forms encountered in naturally occurring text is very large. From the language modeling perspective, a large vocabulary results in serious data sparseness problems. In order to cope with this drawback, previous studies in various application areas suggest modified language models based on different morphological units. It is reported that performance improvements can be achieved with these modified language models. In our document categorization experiments, we use standard word form based language models as well as other modified language models based on root words, root words and part-of-speech information, truncated word forms and character sequences. Additionally, to find an optimum parameter set, multiple tests are carried out with different la...

Metin sınıflandırma
Bu çalışmada makine öğrenmesi teknikleri ve konvolüsyonel sinir ağları (KSA) tabanlı bir derin öğrenme modeli kullanılarak iki farklı Türkçe metin veri kümesi sınıflandırılmıştır. Metin sınıflandırma çalışmasında Rastgele Orman (RO), Naive Bayes (NB), Destek Vektör Makineleri (DVM), K-En Yakın Komşu (KNN) Algoritmaları ve geliştirilen KSA tabanlı derin öğrenme modeli seçilen veri kümelerine uygulanmıştır. Türkçe dilinde seçilen veri kümeleri, metin ve sınıf adedi olarak birbirinden farklı yapıda tercih edilmiş böylece kelime vektör boyutunun aynı deney ortamında sınıflandırma başarısına etkisi araştırılmıştır. Kelime temsil yöntemi olarak Terim Frekansı-Ters Doküman Frekansı (TF-IDF) belirlenmiş olup, sınıflandırma işlemi öncesi veri kümelerine uygulanan durdurma kelimeleri filtreleme ve kök bulma önişlemlerinin de sınıflandırma sonuçlarına katkısı değerlendirilmiştir. Ayrıca kelime temsil vektörlerine öznitelik seçimi uygulanarak boyutları düşürülmüş, böylece nihai vektör boyutunun da sonuçlara etkisi araştırılmıştır. Bahsedilen tüm ön işlemlerin farklı birleşimleri uygulanarak ortaya çıkan kelime vektörlerinin sınıflandırması sonucunda doğruluk ve F1-skor değerleri karşılaştırılmıştır. Karşılaştırmalar her bir sınıflandırma algoritması özelinde ayrı tablolar halinde sunulmuştur. Ayrıca tüm algoritmaların birbiri ile karşılaştırmasını içeren tablolar oluşturularak sonuçlar analiz edilmiştir.

The effect of parallel corpus quality vs size in English-to-Turkish SMT
A parallel corpus plays an important role in statistical machine translation (SMT) systems. In this study, our aim is to figure out the effects of parallel corpus size and quality in the SMT. We develop a machine learning based classifier to classify parallel sentence pairs as high-quality or poor-quality. We applied this classifier to a parallel corpus containing 1 million parallel English-Turkish sentence pairs and obtained 600K high-quality parallel sentence pairs. We train multiple SMT systems with various sizes of entire raw parallel corpus and filtered highquality corpus and evaluate their performance. As expected, our experiments show that the size of parallel corpus is a major factor in translation performance. However, instead of extending corpus with all available “so-called” parallel data, a better translation performance and reduced time-complexity can be achieved with a smaller high-quality corpus using a quality filter.

Rule based tagging of the uyghur verbs
In this paper,carried research on the Uyghur verb,on this basis of artificially tagged verb stemming corpus,we studied the verb inflection formalization,and proposed the Uyghur verb categories inflectional suffx attaching frame.On this basis of artificially tagged verb stemming corpus,we collected suffx attaching rules collection,and build artificially corrected suffx attaching rules collection.Finally,we proposed Uyghur Verb stemming method based on artificially tagged verb stemming corpus,suffx attaching rules collection and verb categories inflectional suffx attaching frame,the accuracy of this method reached 84.15%.

A MT system from Turkmen to Turkish employing finite state and statistical methods
In this work, we present a MT system from Turkmen to Turkish. Our system exploits the similarity of the languages by using a modified version of direct translation method. However, the complex inflectional and derivational morphology of the Turkic languages necessitate special treatment for word-by-word translation model. We also employ morphology-aware multi-word processing and statistical disambiguation processes in our system. We believe that this approach is valid for most of the Turkic languages and the architecture implemented using FSTs can be easily extended to those languages.

Akraba ve bitişken diller arasında bilgisayarlı çeviri için karma bir model
Normalizing non-canonical Turkish texts using machine translation approaches
With the growth of the social web, user-generated text data has reached unprecedented sizes. Non-canonical text normalization provides a way to exploit this as a practical source of training data for language processing systems. The state of the art in Turkish text normalization is composed of a token level pipeline of modules, heavily dependent on external linguistic resources and manually defined rules. Instead, we propose a fully automated, context-aware machine translation approach with fewer stages of processing. Experiments with various implementations of our approach show that we are able to surpass the current best-performing system by a large margin.

A comparative study to determine the effective window size of Turkish word sense disambiguation systems
The impact of collocational features in Turkish Word Sense Disambiguation
Word Sense Disambiguation (WSD) is the task of choosing the most appropriate sense of a word having multiple senses in a given context. Collocational features acquired from the words in neighborship with the ambiguous word are one of the important knowledge sources in this area. This paper explores the effective sets of collocational features in Turkish in order to obtain better Turkish WSD systems. A lexical sample dataset of highly polysemous nouns and verbs has been prepared as the initial step of the work. Several supervised learning algorithms have been tested on this data by supplying different feature sets to select the best performing features for both nouns and verbs in Turkish. Also, we investigated the impact of several collocational features of polysemous words and evaluated the performance of several supervised machine learning algorithms.

Uygurcadan Türkçeye bilgisayarlı çeviri
Machine translation is a sub-field of Natural Language Processing which belongs to Artificial Intelligence. Generally, it is based on computer technology that uses software to translate one natural language to another. In the 1950s, the Georgetown experiment involved fully-automatic translation of over sixty Russian sentences into English (Hutchins, 2004) . The experiment was a great success and ushered in an era of substantial funding for machine-translation research. One of the main projects initiated by the US at that time was a machine translation system which converted Russian to English. This project continued from 1950 to 1960. In 1964, government sponsors of machine translation in the United States formed the Automatic Language Processing Advisory Committee (ALPAC) to examine the project's potential. In the famous 1966 report, ALPAC concluded that machine translation was slower, less accurate and twice as expensive as human translation, and that "there is no immediate or predictable prospect of useful machine translation" (Hutchins, 1995) . The effects of this report brought about the virtual end to machine translation research in the US for over a decade after its publication . As computer technology developed, high capacity and high speed computers were produced. Thus, the main restrictions of studying natural language were removed and machine translation gained the attention of the computer science community once again. Despite technologic advances and the advent of new methods, a general purpose for full automatic machine translation systems still does not exist. To date, few machine translation systems have been developed, furthermore, they may only be applied to restricted texts and some post-editing works (usually necessary after initial translations). The main reasons for these are the morphological, syntactical and lexical differences between different languages. In conclusion, translated texts remain inferior to higher quality translations. Recently, some machine translation systems designed for related languages, such as: Czech to Slovak, Spanish to Catalan, and Turkmen language to Turkish have been implemented; studies on them have proven successful translations can be produced efficiently. In this study, our aim was to implement a machine translation system between Uyghur language and Turkish. Uyghur language is an agglutinative language such as other Turkic languages (i.e. Turkmen, Kazakh, Kyrgyz, Uzbek and Azeri etc.). All Turkic languages belong to the Ural-Altaic language family and are characteristically agglutinative languages which have productive inflectional and derivational morphology. Most research about natural language processing and machine translation of Turkic languages focus on Turkish language. Mainly due to the fact that there is active ongoing research on the subject in Turkey, and they continue to produce valuable results. To date, machine translation systems implemented between Turkic languages has been scant, such as: Turkish to Azeri, Turkish to Crimean Tatar, Turkmen language to Turkish etc. Unfortunately, little computational research about Uygur languages exists. Turkic languages tend to have similar morphological structure and share some common word roots. The main shared properties include similar word order and syntactic structure. However, distinctions exist which prevent mutual intelligibility between these languages. In order to implement this translation system, we utilized a frame-work which is favored for translation between closely related agglutinative languages. Thus, we implemented a morphological analyzer for Uyghur language with XEROX's Finite State Transducers (FST) tools. In this morphological analyzer we considered general cases for Uyghur languages and tagged Uyghur words with the same tags that were used for tagging other Turkic languages words. Thus, it will be easy to integrate this system to other Turkic languages. In order to improve the system's performance, we implemented a rule based morphological disambiguator, additionally, a disambiguator for word senses. We have evaluated our system's performance using BLEU scores for 240 differently structured sentences. As a result, a system has been determined which may successfully translate intermediate level Uyghur language into Turkish. Keywords: Machine translation , Turkic languages, Uyghur language, Turkish .

Morpheus: A neural network for jointly learning contextual lemmatization and morphological tagging
In this study, we present Morpheus, a joint contextual lemmatizer and morphological tagger. Morpheus is based on a neural sequential architecture where inputs are the characters of the surface words in a sentence and the outputs are the minimum edit operations between surface words and their lemmata as well as the morphological tags assigned to the words. The experiments on the datasets in nearly 100 languages provided by SigMorphon 2019 Shared Task 2 organizers show that the performance of Morpheus is comparable to the state-of-the-art system in terms of lemmatization. In morphological tagging, on the other hand, Morpheus significantly outperforms the SigMorphon baseline. In our experiments, we also show that the neural encoder-decoder architecture trained to predict the minimum edit operations can produce considerably better results than the architecture trained to predict the characters in lemmata directly as in previous studies. According to the SigMorphon 2019 Shared Task 2 results, Morpheus has placed 3rd in lemmatization and reached the 9th place in morphological tagging among all participant teams.

A probabilistic mobile text entry system for agglutinative languages
In this work, a probabilistic mobile text entry system based on statistical language models is proposed. Mobile devices having limited keyboards usually produce ambiguous inputs due to multiple letter assignment to each key. Faster typing can be achieved by predicting the intended word which decreases the number of required keystrokes. Currently available methodologies mostly rely on dictionaries, which are impractical for agglutinative languages. The complex morphological structure of these languages gives rise to very high number of word forms that cannot be efficiently covered by any dictionary. The proposed system uses n-gram letter probabilities and K Best Viterbi decoding to generate a list of predictions. The dictionary based method and the proposed probabilistic system are evaluated against a typical agglutinative language, Turkish. The experimental results indicate that the proposed system outperforms the dictionary based method with a 33% improvement in performance.

DONE