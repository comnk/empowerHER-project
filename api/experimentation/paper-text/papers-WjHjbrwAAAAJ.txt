Noise in the nervous system
The artificial intelligence clinician learns optimal treatment strategies for sepsis in intensive care
Mathematics for machine learning
Machine learning is a way to study the algorithm and statistical model that is used by computer to perform a specific task through pattern and deduction [1]. It builds a mathematical model from a sample data which may come under either supervised or unsupervised learning. It is closely
 related to computational statistics which is an interface between statistics and computer science. Also, linear algebra and probability theory are two tools of mathematics which form the basis of machine learning. In general, statistics is a science concerned with collecting, analysing, interpreting
 the data. Data are the facts and figure that can be classified as either quantitative or qualitative. From the given set of data, we can predict the expected observation, difference between the outcome of two observations and how data look like which can help in better decision making process
 [2]. Descriptive and inferential statistics are the two methods of data analysis. Descriptive statistics summarize the raw data into information through which common expectation and variation of data can be taken. It also provides graphical methods that can be used to visualize the sample
 of data and qualitative understanding of observation whereas inferential statistics refers to drawing conclusions from data. Inferences are made under the framework of probability theory. So, understanding of data and interpretation of result are two important aspects of machine learning.
 In this paper, we have reviewed the different methods of ML, mathematics behind ML, its application in day to day life and future aspects.

Guidelines for reinforcement learning in healthcare
Ion-channel noise places limits on the miniaturization of the brain’s wiring
Stochastic simulations on the reliability of action potential propagation in thin axons
It is generally assumed that axons use action potentials (APs) to transmit information fast and reliably to synapses. Yet, the reliability of transmission along fibers below 0.5 μm diameter, such as cortical and cerebellar axons, is unknown. Using detailed models of rodent cortical and squid axons and stochastic simulations, we show how conduction along such thin axons is affected by the probabilistic nature of voltage-gated ion channels (channel noise). We identify four distinct effects that corrupt propagating spike trains in thin axons: spikes were added, deleted, jittered, or split into groups depending upon the temporal pattern of spikes. Additional APs may appear spontaneously; however, APs in general seldom fail (<1%). Spike timing is jittered on the order of milliseconds over distances of millimeters, as conduction velocity fluctuates in two ways. First, variability in the number of Na channels opening in the early rising phase of the AP cause propagation speed to fluctuate gradually. Second, a novel mode of AP propagation (stochastic microsaltatory conduction), where the AP leaps ahead toward spontaneously formed clusters of open Na channels, produces random discrete jumps in spike time reliability. The combined effect of these two mechanisms depends on the pattern of spikes. Our results show that axonal variability is a general problem and should be taken into account when considering both neural coding and the reliability of synaptic transmission in densely connected cortical networks, where small synapses are typically innervated by thin axons. In contrast we find that thicker axons above 0.5 μm diameter are reliable.

Acquisition of Paleolithic toolmaking abilities involves structural remodeling to inferior frontoparietal regions
The manipulative complexity of Lower Paleolithic stone toolmaking
Background Early stone tools provide direct evidence of human cognitive and behavioral evolution that is otherwise unavailable. Proper interpretation of these data requires a robust interpretive framework linking archaeological evidence to specific behavioral and cognitive actions. Methodology/Principal Findings Here we employ a data glove to record manual joint angles in a modern experimental toolmaker (the 4th author) replicating ancient tool forms in order to characterize and compare the manipulative complexity of two major Lower Paleolithic technologies (Oldowan and Acheulean). To this end we used a principled and general measure of behavioral complexity based on the statistics of joint movements. Conclusions/Significance This allowed us to confirm that previously observed differences in brain activation associated with Oldowan versus Acheulean technologies reflect higher-level behavior organization rather than lower-level differences in manipulative complexity. This conclusion is consistent with a scenario in which the earliest stages of human technological evolution depended on novel perceptual-motor capacities (such as the control of joint stiffness) whereas later developments increasingly relied on enhanced mechanisms for cognitive control. This further suggests possible links between toolmaking and language evolution.

The use of reinforcement learning algorithms to meet the challenges of an artificial pancreas
Blood glucose control, for example, in diabetes mellitus or severe illness, requires strict adherence to a protocol of food, insulin administration and exercise personalized to each patient. An artificial pancreas for automated treatment could boost quality of glucose control and patients’ independence. The components required for an artificial pancreas are: i) continuous glucose monitoring (CGM), ii) smart controllers and iii) insulin pumps delivering the optimal amount of insulin. In recent years, medical devices for CGM and insulin administration have undergone rapid progression and are now commercially available. Yet, clinically available devices still require regular patients’ or caregivers’ attention as they operate in open-loop control with frequent user intervention. Dosage-calculating algorithms are currently being studied in intensive care patients 1, for short overnight control to supplement conventional insulin delivery 2, and for short periods where patients rest and follow a prescribed food regime 3. Fully automated algorithms that can respond to the varying activity levels seen in outpatients, with unpredictable and unreported food intake, and which provide the necessary personalized control for individuals is currently beyond the state-of-the-art. Here, we review and discuss reinforcement learning algorithms, controlling insulin in a closed-loop to provide individual insulin dosing regimens that are reactive to the immediate needs of the patient.

Neurocognitive barriers to the embodiment of technology
Near optimal combination of sensory and motor uncertainty in time during a naturalistic perception-action task
Most behavioral tasks have time constraints for successful completion, such as catching a ball in flight. Many of these tasks require trading off the time allocated to perception and action, especially when only one of the two is possible at any time. In general, the longer we perceive, the smaller the uncertainty in perceptual estimates. However, a longer perception phase leaves less time for action, which results in less precise movements. Here we examine subjects catching a virtual ball. Critically, as soon as subjects began to move, the ball became invisible. We study how subjects trade-off sensory and movement uncertainty by deciding when to initiate their actions. We formulate this task in a probabilistic framework and show that subjects' decisions when to start moving are statistically near optimal given their individual sensory and motor uncertainties. Moreover, we accurately predict individual subject's task performance. Thus we show that subjects in a natural task are quantitatively aware of how sensory and motor variability depend on time and act so as to minimize overall task variability.

Evaluating reinforcement learning algorithms in observational health settings
Much attention has been devoted recently to the development of machine learning algorithms with the goal of improving treatment policies in healthcare. Reinforcement learning (RL) is a sub-field within machine learning that is concerned with learning how to make sequences of decisions so as to optimize long-term effects. Already, RL algorithms have been proposed to identify decision-making strategies for mechanical ventilation, sepsis management and treatment of schizophrenia. However, before implementing treatment policies learned by black-box algorithms in high-stakes clinical decision problems, special care must be taken in the evaluation of these policies. 
In this document, our goal is to expose some of the subtleties associated with evaluating RL algorithms in healthcare. We aim to provide a conceptual starting point for clinical and computational researchers to ask the right questions when designing and evaluating algorithms for new ways of treating patients. In the following, we describe how choices about how to summarize a history, variance of statistical estimators, and confounders in more ad-hoc measures can result in unreliable, even misleading estimates of the quality of a treatment policy. We also provide suggestions for mitigating these effects---for while there is much promise for mining observational health data to uncover better treatment policies, evaluation must be performed thoughtfully.

Internal states drive nutrient homeostasis by modulating exploration-exploitation trade-off
Internal states can deeply alter the behavior of animals. Which aspects of behavior change upon metabolic challenges and how these allow the animal to achieve nutrient homeostasis is poorly understood. We used an automated video tracking setup to characterize how amino acid and reproductive states interact to shape exploitation and exploration decisions taken by adult Drosophila melanogaster, to achieve nutritional homeostasis. We find that these two states have specific effects on the decisions to engage and leave proteinaceous food patches. Furthermore, the internal nutrient state defines the exploration-exploitation trade-off: nutrient deprived flies focus on specific patches while satiated flies explore more globally. Finally, we show that olfaction mediates the efficient recognition of yeast as an appropriate protein source and that octopamine is specifically required to mediate homeostatic postmating responses without affecting internal nutrient sensing. Internal states therefore modulate specific aspects of exploitation and exploration to change nutrient selection.

Ultra-low-cost 3D gaze estimation: an intuitive high information throughput compliment to direct brain–machine interfaces
Eye movements are highly correlated with motor intentions and are often retained by patients with serious motor deficiencies. Despite this, eye tracking is not widely used as control interface for movement in impaired patients due to poor signal interpretation and lack of control flexibility. We propose that tracking the gaze position in 3D rather than 2D provides a considerably richer signal for human machine interfaces by allowing direct interaction with the environment rather than via computer displays. We demonstrate here that by using mass-produced video-game hardware, it is possible to produce an ultra-low-cost binocular eye-tracker with comparable performance to commercial systems, yet 800 times cheaper. Our head-mounted system has 30 USD material costs and operates at over 120 Hz sampling rate with a 0.5–1 degree of visual angle resolution. We perform 2D and 3D gaze estimation, controlling a real-time volumetric cursor essential for driving complex user interfaces. Our approach yields an information throughput of 43 bits s−1, more than ten times that of invasive and semi-invasive brain–machine interfaces (BMIs) that are vastly more expensive. Unlike many BMIs our system yields effective real-time closed loop control of devices (10 ms latency), after just ten minutes of training, which we demonstrate through a novel BMI benchmark-–the control of the video arcade game ‘Pong’.

Improving sepsis treatment strategies by combining deep and kernel-based reinforcement learning
Sepsis is the leading cause of mortality in the ICU. It is challenging to manage because individual patients respond differently to treatment. Thus, tailoring treatment to the individual patient is essential for the best outcomes. In this paper, we take steps toward this goal by applying a mixture-of-experts framework to personalize sepsis treatment. The mixture model selectively alternates between neighbor-based (kernel) and deep reinforcement learning (DRL) experts depending on patient's current history. On a large retrospective cohort, this mixture-based approach outperforms physician, kernel only, and DRL-only experts.

Detecting knee osteoarthritis and its discriminating parameters using random forests
The Automatic Neuroscientist: A framework for optimizing experimental design with closed-loop real-time fMRI
The effect of cell size and channel density on neuronal information encoding and energy efficiency
Gaussian process autoregression for simultaneous proportional multi-modal prosthetic control with natural hand kinematics
Matching the dexterity, versatility, and robustness of the human hand is still an unachieved goal in bionics, robotics, and neural engineering. A major limitation for hand prosthetics lies in the challenges of reliably decoding user intention from muscle signals when controlling complex robotic hands. Most of the commercially available prosthetic hands use muscle-related signals to decode a finite number of predefined motions and some offer proportional control of open/close movements of the whole hand. Here, in contrast, we aim to offer users flexible control of individual joints of their artificial hand. We propose a novel framework for decoding neural information that enables a user to independently control 11 joints of the hand in a continuous manner—much like we control our natural hands. Toward this end, we instructed six able-bodied subjects to perform everyday object manipulation tasks combining both dynamic, free movements (e.g., grasping) and isometric force tasks (e.g., squeezing). We recorded the electromyographic and mechanomyographic activities of five extrinsic muscles of the hand in the forearm, while simultaneously monitoring 11 joints of hand and fingers using a sensorized data glove that tracked the joints of the hand. Instead of learning just a direct mapping from current muscle activity to intended hand movement, we formulated a novel autoregressive approach that combines the context of previous hand movements with instantaneous muscle activity to predict future hand movements. Specifically, we evaluated a linear vector autoregressive moving average model with exogenous inputs and a novel Gaussian process (<inline-formula> <tex-math notation="LaTeX">$\mathcal {GP}$ </tex-math></inline-formula>) autoregressive framework to learn the continuous mapping from hand joint dynamics and muscle activity to decode intended hand movement. Our <inline-formula> <tex-math notation="LaTeX">$\mathcal {GP}$ </tex-math></inline-formula> approach achieves high levels of performance (RMSE of 8°/s and <inline-formula> <tex-math notation="LaTeX">$\rho =0.79$ </tex-math></inline-formula>). Crucially, we use a small set of sensors that allows us to control a larger set of independently actuated degrees of freedom of a hand. This novel undersensored control is enabled through the combination of nonlinear autoregressive continuous mapping between muscle activity and joint angles. The system evaluates the muscle signals in the context of previous natural hand movements. This enables us to resolve ambiguities in situations, where muscle signals alone cannot determine the correct action as we evaluate the muscle signals in their context of natural hand movements. <inline-formula> <tex-math notation="LaTeX">$\mathcal {GP}$ </tex-math></inline-formula> autoregression is a particularly powerful approach which makes not only a prediction based on the context but also represents the associated uncertainty of its predictions, thus enabling the novel notion of risk-based control in neuroprosthetics. Our results suggest that <inline-formula> <tex-math notation="LaTeX">$\mathcal {GP}$ </tex-math></inline-formula> autoregressive approaches with exogenous inputs lend themselves for natural, intuitive, and continuous control in neurotechnology, with the particular focus on prosthetic restoration of natural limb function, where high dexterity is required for complex movements.

Dot-to-dot: Explainable hierarchical reinforcement learning for robotic manipulation
Robotic systems are ever more capable of automation and fulfilment of complex tasks, particularly with reliance on recent advances in intelligent systems, deep learning and artificial intelligence in general. However, as robots and humans come closer together in their interactions, the matter of interpretability, or explainability of robot decision-making processes for the human grows in importance. A successful interaction and collaboration would only be possible through mutual understanding of underlying representations of the environment and the task at hand. This is currently a challenge in deep learning systems. We present a hierarchical deep reinforcement learning system, consisting of a low-level agent handling the large actions/states space of a robotic system efficiently, by following the directives of a high-level agent which is learning the high-level dynamics of the environment and task. This high-level agent forms a representation of the world and task at hand that is interpretable for a human operator. The method, which we call Dot-to-Dot, is tested on a MuJoCo-based model of the Fetch Robotics Manipulator, as well as a Shadow Hand, to test its performance. Results show efficient learning of complex actions/states spaces by the low-level agent, and an interpretable representation of the task and decision-making process learned by the high-level agent.

DONE