Performance characterization in computer vision: A guide to best practices
Augmented reality applications for cultural heritage using Kinect
Algorithmic modelling for performance evaluation
Algorithmic modelling for performance evaluation
A switched model-based coder for video signals
The algorithmic architecture and performance of a video coder are described that switches between the model-based and H.261 modes, depending on image content. The switching criterion incorporates measures of both picture quality and bit rate. The model-based mode uses generalized cylindrical models and a 3D matching technique to estimate motion. The coder was tested with four different image sequences in CBR and VBR operational modes: the performance was generally superior, and in some cases significantly superior, to that of a free-running H.261 coder operating on the same sequences. The switched architecture represents a possible route for the integration of model-based coding with H.261 to give improved performance at very low bit rates. >

An algorithm for face and facial-feature location based on grey-scale information and facial geometry
We describe a two-stage algorithm for detecting human faces based on the grey-scale information of the input image and facial geometry. The first stage involves locating approximately the head boundaries and the facial features, the exact locations of which are determined in the second stage. The algorithm is evaluated on data sets and some characteristics of its performance are identified. As well as being of value for the feature location algorithm in particular, the approach is intended to illustrate how any vision technique may be characterized in an objective way.

Parallel entropic auto-thresholding
Performance characterization in computer vision a tutorial
This document provides a tutorial on performance characterization in computer vision. It explains why learning to characterize the performances of vision techniques is crucial to the disciplineâ€™s development. It describes the usual procedure for evaluating vision algorithms and its statistical basis. The use of a software tool, a so-called test harness, for performing such evaluations is described. The approach is illustrated on an example technique.

Spatial statistics of image features for performance comparison
When matching images for applications such as mosaicking and homography estimation, the distribution of features across the overlap region affects the accuracy of the result. This paper uses the spatial statistics of these features, measured by Ripley's K-function, to assess whether feature matches are clustered together or spread around the overlap region. A comparison of the performances of a dozen state-of-the-art feature detectors is then carried out using analysis of variance and a large image database. Results show that SFOP introduces significantly less aggregation than the other detectors tested. When the detectors are rank-ordered by this performance measure, the order is broadly similar to those obtained by other means, suggesting that the ordering reflects genuine performance differences. Experiments on stitching images into mosaics confirm that better coverage values yield better quality outputs.

Parallel pipeline implementation of wavelet transforms
Wavelet transforms have been one of the important signal processing developments in the last decade, especially for applications such as time-frequency analysis, data compression, segmentation and vision. Although several efficient implementations of wavelet transforms have been derived, their computational burden is still considerable. The paper describes two generic parallel implementations of wavelet transforms, based on the pipeline processor farming methodology, which have the potential to achieve real-time performance. Results show that the parallel implementation of the oversampled wavelet transform achieves virtually linear speedup, while the parallel implementation of the discrete wavelet transform (DWT) also outperforms the sequential version, provided that the filter order is large. The DWT parallelisation performance improves with increasing data length and filter order, while the frequency-domain implementation performance is independent of wavelet filter order. Parallel pipeline implementations are currently suitable for processing multidimensional images with data length at least 512 pixels.

Improved repeatability measures for evaluating performance of feature detectors
The most frequently employed measure for performance characterisation of local feature detectors is repeatability, but it has been observed that this does not necessarily mirror actual performance. Presented are improved repeatability formulations which correlate much better with the true performance of feature detectors. Comparative results for several state-of-the-art feature detectors are presented using these measures; it is found that Hessian-based detectors are generally superior at identifying features when images are subject to various geometric and photometric transformations.

What do we want from a wearable user interface?
Graphical user interfaces are widely regarded as being inappropriate for use on wearable computers. This paper outlines Sulawesi, a user interface framework for wearable computing. Some shortcomings in Sulawesi are analyzed. Two specific areas of improvement, a high-level user interface toolkit and contextual measurement and adaption, are reported upon. Together these contribute towards the development of a proactive personal assistant application, the authors' ultimate aim.

Evaluating optical-flow algorithms on a parallel machine
Measuring the coverage of interest point detectors
Sulawesi: A wearable application integration framework
This paper describes Sulawesi, a framework for developing applications for wearable computing that are capable of multi-modal interaction with the user. The design principles of the framework are described along with its main features, and some example applications that exploit the capabilities of the framework are outlined.

Rapid online analysis of local feature detectors and their complementarity
A vision system that can assess its own performance and take appropriate actions online to maximize its effectiveness would be a step towards achieving the long-cherished goal of imitating humans. This paper proposes a method for performing an online performance analysis of local feature detectors, the primary stage of many practical vision systems. It advocates the spatial distribution of local image features as a good performance indicator and presents a metric that can be calculated rapidly, concurs with human visual assessments and is complementary to existing offline measures such as repeatability. The metric is shown to provide a measure of complementarity for combinations of detectors, correctly reflecting the underlying principles of individual detectors. Qualitative results on well-established datasets for several state-of-the-art detectors are presented based on the proposed measure. Using a hypothesis testing approach and a newly-acquired, larger image database, statistically-significant performance differences are identified. Different detector pairs and triplets are examined quantitatively and the results provide a useful guideline for combining detectors in applications that require a reasonable spatial distribution of image features. A principled framework for combining feature detectors in these applications is also presented. Timing results reveal the potential of the metric for online applications.

Feature extraction and classification by genetic programming
Novel hardware algorithms for row-parallel integral image calculation
The integral image is an intermediate image representation that allows rapid calculation of rectangular features at constant speed, irrespective of filter size, and is particularly useful for multi-scale computer vision algorithms like Speeded-Up Robust Features (SURF). Although calculation of the integral image involves simple addition operations, the total number of operations is significant due to the generally large size of image data. Recursive equations allow considerable reduction in the required number of addition operations but require calculation of the integral image in a serial fashion. This is generally not desirable for real-time embedded vision systems with strict time limitations and low-powered but parallel hardware resources. With the objective of minimizing the hardware resources involved, this paper proposes two novel hardware algorithms based on decomposition of these recursive equations, allowing calculation of up to four integral image values in a row-parallel way with out significantly increasing the number of addition operations.

Agricultural produce grading by computer vision using genetic programming
An approach to generating task-specific computer vision systems from generic components using machine learning is presented. With this system, it is possible to learn both feature segmentation and classification from training data. This approach is applied to a disparate range of problems in the domain of agricultural produce grading: mango surface inspection and maturity evaluation, apple variety discrimination, wheat and barley classification and purple sticky rice grading. It is shown that shape, colour and texture features together produce more accurate classification results than fewer categories of feature, and that these evolved classifiers are competitive with neural networks and support vector machines.

Tracking methods for augmented reality
Augmented reality has been an active area ofresearch for the last two decades or so. This paper presents acomprehensive review of the recent literature on trackingmethods used in Augmented Reality applications, both forindoor and outdoor environments. After critical discussion ofthe methods used for tracking, the paper identifies limitations ofthe state-of-the-art techniques and suggests potential futuredirections to overcome the bottlenecks.

DONE