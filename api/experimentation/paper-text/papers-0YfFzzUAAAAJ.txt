Beware, your hands reveal your secrets!
Research on attacks which exploit video-based side-channels to decode text typed on a smartphone has traditionally assumed that the adversary is able to leverage some information from the screen display (say, a reflection of the screen or a low resolution video of the content typed on the screen). This paper introduces a new breed of side-channel attack on the PIN entry process on a smartphone which entirely relies on the spatio-temporal dynamics of the hands during typing to decode the typed text. Implemented on a dataset of 200 videos of the PIN entry process on an HTC One phone, we show, that the attack breaks an average of over 50% of the PINs on the first attempt and an average of over 85% of the PINs in ten attempts. Because the attack can be conducted in such a way not to raise suspicion (i.e., since the adversary does not have to direct the camera at the screen), we believe that it is very likely to be adopted by adversaries who seek to stealthily steal sensitive private information. As users conduct more and more of their computing transactions on mobile devices in the open, the paper calls for the community to take a closer look at the risks posed by the now ubiquitous camera-enabled devices.

Which verifiers work?: A benchmark evaluation of touch-based authentication algorithms
Despite the tremendous need for the evaluation of touch-based authentication as an extra security layer for mobile devices, the huge disparity in the experimental methodology used by different researchers makes it hard to determine how much research in this area has progressed. Critical variables such as the types of features and how they are pre-processed, the training and testing methodology and the performance evaluation metrics, to mention but a few, vary from one study to the next. Additionally, most datasets used for these evaluations are not openly accessible, making it impossible for researchers to carry out comparative analysis on the same data. This paper takes the first steps towards bridging this gap. We evaluate the performance of ten state-of-the-art touch-based authentication classification algorithms under a common experimental protocol, and present the associated benchmark dataset for the community to use. Using a series of statistical tests, we rigorously compare the performance of the algorithms, and also evaluate how the “failure to enroll” phenomena would impact overall system performance if users exceeding certain EERs were barred from using the system. Our results and benchmark dataset open the door to future research that will enable the community to better understand the potential of touch gestures as a biometric authentication modality.

Context-aware active authentication using smartphone accelerometer measurements
While body movement patterns recorded by a smartphone accelerometer are now well understood to be discriminative enough to separate users, little work has been done to address the question of if or how the position in which the phone is held affects user authentication. In this work, we show through a combination of supervised learning methods and statistical tests, that there are certain users for whom exploitation of information of how a phone is held drastically improves classification performance. We propose a two-stage authentication framework that identifies the location of the phone before performing authentication, and show its benefits based on a dataset of 30 users. Our work represents a first step towards bridging the gap between accelerometer-based authentication systems analyzed from the context of a laboratory environment and a real accelerometer-based authentication system in the wild where phone positioning cannot be assumed.

Continuous authentication of smartphone users by fusing typing, swiping, and phone movement patterns
We studied the fusion of three biometric authentication modalities, namely, swiping gestures, typing patterns and the phone movement patterns observed during typing or swiping. A web browser was customized to collect the data generated from the aforementioned modalities over four to seven days in an unconstrained environment. Several features were extracted by using sliding window mechanism for each modality and analyzed by using information gain, correlation, and symmetric uncertainty. Finally, five features from windows of continuous swipes, thirty features from windows of continuously typed letters, and nine features from corresponding phone movement patterns while swiping/typing were used to build the authentication system. We evaluated the performance of each modality and their fusion over a dataset of 28 users. The feature-level fusion of swiping and the corresponding phone movement patterns achieved an authentication accuracy of 93.33%, whereas, the score-level fusion of typing behaviors and the corresponding phone movement patterns achieved an authentication accuracy of 89.31 %.

When kids' toys breach mobile phone security
Touch-based verification --- the use of touch gestures (e.g., swiping, zooming, etc.) to authenticate users of touch screen devices --- has recently been widely evaluated for its potential to serve as a second layer of defense to the PIN lock mechanism. In all performance evaluations of touch-based authentication systems however, researchers have assumed naive (zero-effort) forgeries in which the attacker makes no effort to mimic a given gesture pattern. In this paper we demonstrate that a simple "Lego" robot driven by input gleaned from general population swiping statistics can generate forgeries that achieve alarmingly high penetration rates against touch-based authentication systems. Using the best classification algorithms in touch-based authentication, we rigorously explore the effect of the attack, finding that it increases the Equal Error Rates of the classifiers by between 339% and 1004% depending on parameters such as the failure-to-enroll threshold and the type of touch stroke generated by the robot. The paper calls into question the zero-effort impostor testing approach used to benchmark the performance of touch-based authentication systems.

Examining a large keystroke biometrics dataset for statistical-attack openings
Research on keystroke-based authentication has traditionally assumed human impostors who generate forgeries by physically typing on the keyboard. With bots now well understood to have the capacity to originate precisely timed keystroke sequences, this model of attack is likely to underestimate the threat facing a keystroke-based system in practice. In this work, we investigate how a keystroke-based authentication system would perform if it were subjected to synthetic attacks designed to mimic the typical user. To implement the attacks, we perform a rigorous statistical analysis on keystroke biometrics data collected over a 2-year period from more than 3000 users, and then use the observed statistical traits to design and launch algorithmic attacks against three state-of-the-art password-based keystroke verification systems.
 Relative to the zero-effort attacks typically used to test the performance of keystroke biometric systems, we show that our algorithmic attack increases the mean Equal Error Rates (EERs) of three high performance keystroke verifiers by between 28.6% and 84.4%. We also find that the impact of the attack is more pronounced when the keystroke profiles subjected to the attack are based on shorter strings, and that some users see considerably greater performance degradation under the attack than others. This article calls for a shift from the traditional zero-effort approach of testing the performance of password-based keystroke verifiers, to a more rigorous algorithmic approach that captures the threat posed by today’s bots.

Unsure how to authenticate on your vr headset? come on, use your head!
For security-sensitive Virtual Reality (VR) applications that require the end-user to enter authenticatioan credentials within the virtual space, a VR user's inability to see (potentially malicious entities in) the physical world can be discomforting, and in the worst case could potentially expose the VR user to visual attacks. In this paper, we show that the head, hand and (or) body movement patterns exhibited by a user freely interacting with a VR application contain user-specific information that can be leveraged for user authentication. For security-sensitive VR applications, we argue that such functionality can be used as an added layer of security that minimizes the need for entering the PIN. Based on a dataset of 23 users who interacted with our VR application for two sessions over a period of one month, we obtained mean equal error rates as low as 7% when we authenticated users based on their head and body movement patterns.

Wireless Sensor Networks
Toward robotic robbery on the touch screen
Despite the tremendous amount of research fronting the use of touch gestures as a mechanism of continuous authentication on smart phones, very little research has been conducted to evaluate how these systems could behave if attacked by sophisticated adversaries. In this article, we present two Lego-driven robotic attacks on touch-based authentication: a population statistics--driven attack and a user-tailored attack. The population statistics--driven attack is based on patterns gleaned from a large population of users, whereas the user-tailored attack is launched based on samples stolen from the victim. Both attacks are launched by a Lego robot that is trained on how to swipe on the touch screen. Using seven verification algorithms and a large dataset of users, we show that the attacks cause the system’s mean false acceptance rate (FAR) to increase by up to fivefold relative to the mean FAR seen under the standard zero-effort impostor attack. The article demonstrates the threat that robots pose to touch-based authentication and provides compelling evidence as to why the zero-effort attack should cease to be used as the benchmark for touch-based authentication systems.

Gearbox fault diagnostics using deep learning with simulated data
Transmission components are prone to fatigue damage due to high and intermittent loading cycles, that cause premature failure of gearboxes. Recently, several vibration-based diagnostics approaches using Machine Learning (ML) and Deep Learning (DL) algorithms have been proposed to identify gearboxes faults. However, most of them rely on a large amount of training data collection from physical experiments, which is often associated with high costs. This paper offers an ML and DL classification performance comparison of several algorithms to diagnose faults in a gearbox based on realistic simulated vibration data. A dynamic model of a single-stage gearbox was developed to generate data for different health conditions. Generated datasets were fed to ML and DL algorithms and accuracy results were compared. Results revealed the superiority of Convolutional Neural Network compared to other classifiers. This research contributes to the prevention of catastrophic failures in gearboxes by early crack detection and maintenance schedule optimization.

Handwriting watcher: A mechanism for smartwatch-driven handwriting authentication
Despite decades of research on automated handwriting authentication, there is yet to emerge an automated handwriting authentication application that breaks into the mainstream. In this paper, we argue that the burgeoning wearables market holds the key to a practical handwriting authentication app. With potential applications in online education, standardized testing and mobile banking, we present Handwriting Watcher, a mechanism which leverages a wrist-worn sensor-enabled device to authenticate a user's free handwriting. Through experiments capturing a wide range of writing scenarios, we show Handwriting Watcher attains mean error rates as low as 6.56% across the population. Our work represents a promising step towards a market-ready, generalized handwriting authentication system.

Transforming animals in a cyber-behavioral biometric menagerie with frog-boiling attacks
While recent research has demonstrated how frequent updating of users' templates can enhance the performance of a biometric system, there has not been much work devoted to studying the effects of attacks against template update mechanisms. In this work, we present an attack which stealthily leverages the template update scheme of a keystroke verification system to poison users' templates. Using a publicly accessible dataset and some of the best performing individual and fusion verifiers in keystroke authentication, we show how the attack increases the error rates of the verifiers as it transforms groups of well performing users into ill performing users. In our experiments, depending on the template towards which the attack is made to converge, equal error rates of verifiers increased from between 9.9% and 18.9% to between 19.1% and 63.6% as a result of the attack. Results demonstrated in this paper call for research on new biometric sample attestation and validation techniques to augment template update mechanisms.

Using global knowledge of users' typing traits to attack keystroke biometrics templates
Research in the field of keystroke dynamics (KD) has traditionally assumed impostor attacks to be originated by humans. However, recent studies have revealed that bots and various categories of malware have the capacity to implement intelligently crafted synthetic attacks against KD systems. In this paper we make a large-scale study of human typing traits, and then use the general observed statistical trends to train a tool that breaks password-KD templates. Our aim is to investigate how a synthetic attack designed with general knowledge about users' typing habits would perform against a password-KD co-authentication system in practice. Our initial results indicate that in the wake of synthetic impostor attacks, the incorporation of KD into regular password-based systems may not necessarily lessen the burden of users having to maintain strong passwords for guaranteed security.

fNIRS: A new modality for brain activity-based biometric authentication
There is a rapidly increasing amount of research on the use of brain activity patterns as a basis for biometric user verification. The vast majority of this research is based on Electroencephalogram (EEG), a technology which measures the electrical activity along the scalp. In this paper, we evaluate Functional Near-Infrared Spectroscopy (fNIRS) as an alternative approach to brain activity-based user authentication. fNIRS is centered around the measurement of light absorbed by blood and, compared to EEG, has a higher signal-to-noise ratio, is more suited for use during normal working conditions, and has a much higher spatial resolution which enables targeted measurements of specific brain regions. Based on a dataset of 50 users that was analysed using an SVM and a Naïve Bayes classifier, we show fNIRS to respectively give EERs of 0.036 and 0.046 when using our best channel configuration. Further, we present some results on the areas of the brain which demonstrated highest discriminative power. Our findings indicate that fNIRS has significant promise as a biometric authentication modality.

Scan-based evaluation of continuous keystroke authentication systems
For biometric modalities in which error rates are typically high--including behavioral biometrics, such as keystroke dynamics--temporal information associated with the occurrence of errors might help answer questions regarding performance evaluation.

Wearables-driven freeform handwriting authentication
With the ubiquity of handwriting in everyday tasks, it is surprising that existing avenues for handwriting authentication remain largely out of reach for the average individual or organization. Current solutions often rely on expensive or specialized equipment, and most existing research focuses on signatures rather than freeform handwriting. This limits the applicability of such technology to a narrow range of scenarios. In this paper, we argue that wearable devices might make handwriting authentication scalable and affordable. We design and evaluate two wearables-driven freeform handwriting authentication systems, one centered on a deep neural network and the other using human-engineered features. Our authentication systems are thoroughly tested across three writing experiments (involving 53 participants) that were carefully mapped to typical writing scenarios. We show the best performing configuration to attain an equal error rate of 5.51%, suggesting the potential of this modality for use in a multi-modal authentication system. To evaluate how our authentication systems perform against attacks by determined attackers, we developed and evaluated two impostor attacks that correspond to highly likely attack vectors. We then show that certain authentication system configurations are resistant to the attack. This paper represents an important step toward consumer ready wearables-driven freeform handwriting authentication.

Your substance abuse disorder is an open secret! Gleaning sensitive personal information from templates in an EEG-based authentication system
Given the task of designing an authentication system that uses brain waves as input, researchers typically focus on the sole objective of maximizing authentication accuracy. In this paper we challenge this common wisdom and argue that because brain waves encode a lot of other (potentially sensitive) information about the user, this single-pronged, privacy-agnostic approach can have significant privacy implications. Based on a publicly accessible dataset, we rigorously analyze two EEG-based authentication systems built in accordance with this philosophy and show that such designs could potentially divulge more of the users sensitive personal information than that regarding the intended authentication functionality. The paper argues for privacy-aware designs for systems which take brain signals as input.

Machine learning in crack size estimation of a spur gear pair using simulated vibration data
Professional development for rural stem teachers on data science and cybersecurity: A university and school districts' partnership
Defensive charging: Mitigating power side-channel attacks on charging smartphones
Mobile devices are increasingly relied upon in user's daily lives. This dependence supports a growing network of mobile device charging hubs in public spaces such as airports. Unfortunately, the public nature of these hubs make them vulnerable to tampering. By embedding illicit power meters in the charging stations an attacker can launch power side-channel attacks aimed at inferring user activity on smartphones (e.g., web browsing or typing patterns). In this paper, we present three power side-channel attacks that can be launched by an adversary during the phone charging process. Such attacks use machine learning to identify unique patterns hidden in the measured current draw and infer information about a user's activity. To defend against these attacks, we design and rigorously evaluate two defense mechanisms, a hardware-based and software-based solution. The defenses randomly perturb the current drawn during charging thereby masking the unique patterns of the user's activities. Our experiments show that the two defenses force each one of the attacks to perform no better than random guessing. In practice, the user would only need to choose one of the defensive mechanisms to protect themselves against intrusions involving power draw analysis.

DONE